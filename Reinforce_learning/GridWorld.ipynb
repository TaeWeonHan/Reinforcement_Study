{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUYz6XkxGAmN"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "* [INE4105] Industrial Artificial Intelligence @Hanyang University ERICA\n",
        "* Instructor: Yosep Oh (yosepoh@hanyang.ac.kr)\n",
        "* Week12: Lab session (Reinforcement Learning: GridWorld)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sATMgk1pGgtb"
      },
      "source": [
        "# Step 1: Preliminaries  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTsxtE77FQwE",
        "outputId": "3f8cf3de-be48-4651-ec0c-b4ef0278b76b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium<0.30,>=0.28.1 (from stable-baselines3[extra])\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.8.0.76)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.6.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.15.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.7.1)\n",
            "Collecting shimmy[atari]~=1.3.0 (from stable-baselines3[extra])\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (9.4.0)\n",
            "Collecting autorom[accept-rom-license]~=0.6.1 (from stable-baselines3[extra])\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra])\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0->stable-baselines3[extra])\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.16.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]) (6.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446661 sha256=60151c67a334cb7d1dfdd751b9e1ef3f0f66e7b461a09a03f19b0283d346cecf\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: farama-notifications, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, ale-py, shimmy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, AutoROM.accept-rom-license, autorom, nvidia-cusolver-cu12, stable-baselines3\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 farama-notifications-0.0.4 gymnasium-0.29.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 shimmy-1.3.0 stable-baselines3-2.3.2\n"
          ]
        }
      ],
      "source": [
        "# Install Stable Baseline 3\n",
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlZBe3EoFTiZ"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWmK8WXfGmer"
      },
      "source": [
        "# Step 2: Define the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UatJxp5JGoTU"
      },
      "outputs": [],
      "source": [
        "class GridWorldEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        # Initialize the GridWorld environment\n",
        "        super(GridWorldEnv, self).__init__()\n",
        "        self.grid_size = 8  # Define the size of the grid\n",
        "        self.action_space = spaces.Discrete(4)  # Define the action space: 4 possible actions\n",
        "        self.observation_space = spaces.Box(low=0, high=self.grid_size-1, shape=(2,), dtype=np.int32)  # Define the observation space\n",
        "        self.reset()  # Reset the environment\n",
        "\n",
        "    def step(self, action):\n",
        "        # Execute the action\n",
        "        if action == 0:\n",
        "            self.move_left()\n",
        "        elif action == 1:\n",
        "            self.move_up()\n",
        "        elif action == 2:\n",
        "            self.move_right()\n",
        "        elif action == 3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1 # Reward is -1 if the agent moves\n",
        "        done = self.is_done()  # Check if the episode is done\n",
        "        return np.array([self.x, self.y], dtype=np.int32), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the agent's position to the start\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        return np.array([self.x, self.y], dtype=np.int32)\n",
        "\n",
        "    def move_right(self):\n",
        "        # Move the agent to the right\n",
        "        self.y = min(self.y + 1, self.grid_size - 1)\n",
        "\n",
        "    def move_left(self):\n",
        "        # Move the agent to the left\n",
        "        self.y = max(self.y - 1, 0)\n",
        "\n",
        "    def move_up(self):\n",
        "        # Move the agent up\n",
        "        self.x = max(self.x - 1, 0)\n",
        "\n",
        "    def move_down(self):\n",
        "        # Move the agent down\n",
        "        self.x = min(self.x + 1, self.grid_size - 1)\n",
        "\n",
        "    def is_done(self):\n",
        "        # Check if the agent has reached the goal\n",
        "        return self.x == self.grid_size - 1 and self.y == self.grid_size - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VEoxbNINE50"
      },
      "source": [
        "- GridWorldEnv 클래스: 간단한 GridWorld 환경을 정의합니다. 이 환경은 4x4 그리드로 구성되어 있으며, 에이전트는 좌표 (0, 0)에서 시작하여 (3, 3) 목표 지점에 도달하려고 합니다.\n",
        "- action_space: 에이전트가 취할 수 있는 4가지 행동(왼쪽, 위, 오른쪽, 아래)을 정의합니다.\n",
        "- observation_space: 에이전트의 위치를 나타내는 2차원 좌표 (x, y)입니다.\n",
        "- step 메서드: 주어진 행동을 실행하고, 새로운 상태, 보상, 에피소드 종료 여부를 반환합니다.\n",
        "- reset 메서드: 에이전트의 위치를 초기화합니다.\n",
        "- move_ 메서드*: 에이전트의 위치를 업데이트합니다.\n",
        "- is_done 메서드: 에이전트가 목표 지점에 도달했는지 확인합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "298Kn_lCJmBt"
      },
      "source": [
        "# Step 3: Define the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYkdOfs9HpQD",
        "outputId": "a87e2e59-1a7a-4132-acf0-ab6ca1ccf951"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Initialize the GridWorld environment\n",
        "env = GridWorldEnv()\n",
        "\n",
        "# Build a DQN model\n",
        "model = DQN('MlpPolicy', env, verbose=0, exploration_fraction=0.5, exploration_final_eps=0.01, learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtSWEcMzNUJ4"
      },
      "source": [
        "- env = GridWorldEnv(): GridWorld 환경을 초기화합니다.\n",
        "- model = DQN(...): DQN 모델을 초기화합니다.\n",
        "- 'MlpPolicy': 다층 퍼셉트론(MLP) 정책을 사용합니다.\n",
        "- env: 앞서 정의한 GridWorld 환경입니다.\n",
        "- verbose=0: 학습 과정의 출력을 생략합니다.\n",
        "- exploration_fraction=0.5: 탐험 비율을 50%로 설정합니다. 초기 학습 단계에서 무작위 행동을 많이 취합니다.\n",
        "- exploration_final_eps=0.01: 탐험 비율의 최종 값을 0.01로 설정합니다. 학습 후반에는 무작위 행동을 거의 하지 않습니다.\n",
        "- learning_rate=0.01: 학습률을 0.01로 설정합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuYAE_IhJqxQ"
      },
      "source": [
        "# Step 4: Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_YdwviTH8cW",
        "outputId": "f071ee4b-8d17-4e81-cd34-b603869e96ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 1, Total Reward: 50, Total Reward: -50\n",
            "Episode: 2, Total Reward: 50, Total Reward: -50\n",
            "Episode: 3, Total Reward: 50, Total Reward: -50\n",
            "Episode: 4, Total Reward: 50, Total Reward: -50\n",
            "Episode: 5, Total Reward: 50, Total Reward: -50\n",
            "Episode: 6, Total Reward: 50, Total Reward: -50\n",
            "Episode: 7, Total Reward: 50, Total Reward: -50\n",
            "Episode: 8, Total Reward: 50, Total Reward: -50\n",
            "Episode: 9, Total Reward: 50, Total Reward: -50\n",
            "Episode: 10, Total Reward: 50, Total Reward: -50\n",
            "Episode: 11, Total Reward: 50, Total Reward: -50\n",
            "Episode: 12, Total Reward: 50, Total Reward: -50\n",
            "Episode: 13, Total Reward: 50, Total Reward: -50\n",
            "Episode: 14, Total Reward: 50, Total Reward: -50\n",
            "Episode: 15, Total Reward: 50, Total Reward: -50\n",
            "Episode: 16, Total Reward: 50, Total Reward: -50\n",
            "Episode: 17, Total Reward: 50, Total Reward: -50\n",
            "Episode: 18, Total Reward: 50, Total Reward: -50\n",
            "Episode: 19, Total Reward: 50, Total Reward: -50\n",
            "Episode: 20, Total Reward: 50, Total Reward: -50\n",
            "Episode: 21, Total Reward: 50, Total Reward: -50\n",
            "Episode: 22, Total Reward: 50, Total Reward: -50\n",
            "Episode: 23, Total Reward: 50, Total Reward: -50\n",
            "Episode: 24, Total Reward: 50, Total Reward: -50\n",
            "Episode: 25, Total Reward: 50, Total Reward: -50\n",
            "Episode: 26, Total Reward: 50, Total Reward: -50\n",
            "Episode: 27, Total Reward: 50, Total Reward: -50\n",
            "Episode: 28, Total Reward: 50, Total Reward: -50\n",
            "Episode: 29, Total Reward: 50, Total Reward: -50\n",
            "Episode: 30, Total Reward: 50, Total Reward: -50\n",
            "Episode: 31, Total Reward: 50, Total Reward: -50\n",
            "Episode: 32, Total Reward: 50, Total Reward: -50\n",
            "Episode: 33, Total Reward: 50, Total Reward: -50\n",
            "Episode: 34, Total Reward: 50, Total Reward: -50\n",
            "Episode: 35, Total Reward: 50, Total Reward: -50\n",
            "Episode: 36, Total Reward: 50, Total Reward: -50\n",
            "Episode: 37, Total Reward: 50, Total Reward: -50\n",
            "Episode: 38, Total Reward: 50, Total Reward: -50\n",
            "Episode: 39, Total Reward: 50, Total Reward: -50\n",
            "Episode: 40, Total Reward: 50, Total Reward: -50\n",
            "Episode: 41, Total Reward: 50, Total Reward: -50\n",
            "Episode: 42, Total Reward: 50, Total Reward: -50\n",
            "Episode: 43, Total Reward: 50, Total Reward: -50\n",
            "Episode: 44, Total Reward: 50, Total Reward: -50\n",
            "Episode: 45, Total Reward: 50, Total Reward: -50\n",
            "Episode: 46, Total Reward: 50, Total Reward: -50\n",
            "Episode: 47, Total Reward: 50, Total Reward: -50\n",
            "Episode: 48, Total Reward: 50, Total Reward: -50\n",
            "Episode: 49, Total Reward: 50, Total Reward: -50\n",
            "Episode: 50, Total Reward: 50, Total Reward: -50\n",
            "Episode: 51, Total Reward: 50, Total Reward: -50\n",
            "Episode: 52, Total Reward: 50, Total Reward: -50\n",
            "Episode: 53, Total Reward: 50, Total Reward: -50\n",
            "Episode: 54, Total Reward: 50, Total Reward: -50\n",
            "Episode: 55, Total Reward: 50, Total Reward: -50\n",
            "Episode: 56, Total Reward: 50, Total Reward: -50\n",
            "Episode: 57, Total Reward: 50, Total Reward: -50\n",
            "Episode: 58, Total Reward: 50, Total Reward: -50\n",
            "Episode: 59, Total Reward: 50, Total Reward: -50\n",
            "Episode: 60, Total Reward: 50, Total Reward: -50\n",
            "Episode: 61, Total Reward: 50, Total Reward: -50\n",
            "Episode: 62, Total Reward: 50, Total Reward: -50\n",
            "Episode: 63, Total Reward: 50, Total Reward: -50\n",
            "Episode: 64, Total Reward: 50, Total Reward: -50\n",
            "Episode: 65, Total Reward: 50, Total Reward: -50\n",
            "Episode: 66, Total Reward: 50, Total Reward: -50\n",
            "Episode: 67, Total Reward: 50, Total Reward: -50\n",
            "Episode: 68, Total Reward: 50, Total Reward: -50\n",
            "Episode: 69, Total Reward: 50, Total Reward: -50\n",
            "Episode: 70, Total Reward: 50, Total Reward: -50\n",
            "Episode: 71, Total Reward: 50, Total Reward: -50\n",
            "Episode: 72, Total Reward: 50, Total Reward: -50\n",
            "Episode: 73, Total Reward: 50, Total Reward: -50\n",
            "Episode: 74, Total Reward: 50, Total Reward: -50\n",
            "Episode: 75, Total Reward: 50, Total Reward: -50\n",
            "Episode: 76, Total Reward: 50, Total Reward: -50\n",
            "Episode: 77, Total Reward: 50, Total Reward: -50\n",
            "Episode: 78, Total Reward: 50, Total Reward: -50\n",
            "Episode: 79, Total Reward: 50, Total Reward: -50\n",
            "Episode: 80, Total Reward: 50, Total Reward: -50\n",
            "Episode: 81, Total Reward: 50, Total Reward: -50\n",
            "Episode: 82, Total Reward: 50, Total Reward: -50\n",
            "Episode: 83, Total Reward: 50, Total Reward: -50\n",
            "Episode: 84, Total Reward: 50, Total Reward: -50\n",
            "Episode: 85, Total Reward: 50, Total Reward: -50\n",
            "Episode: 86, Total Reward: 50, Total Reward: -50\n",
            "Episode: 87, Total Reward: 50, Total Reward: -50\n",
            "Episode: 88, Total Reward: 50, Total Reward: -50\n",
            "Episode: 89, Total Reward: 50, Total Reward: -50\n",
            "Episode: 90, Total Reward: 50, Total Reward: -50\n",
            "Episode: 91, Total Reward: 50, Total Reward: -50\n",
            "Episode: 92, Total Reward: 50, Total Reward: -50\n",
            "Episode: 93, Total Reward: 50, Total Reward: -50\n",
            "Episode: 94, Total Reward: 50, Total Reward: -50\n",
            "Episode: 95, Total Reward: 50, Total Reward: -50\n",
            "Episode: 96, Total Reward: 50, Total Reward: -50\n",
            "Episode: 97, Total Reward: 50, Total Reward: -50\n",
            "Episode: 98, Total Reward: 50, Total Reward: -50\n",
            "Episode: 99, Total Reward: 50, Total Reward: -50\n",
            "Episode: 100, Total Reward: 50, Total Reward: -50\n",
            "Episode: 101, Total Reward: 50, Total Reward: -50\n",
            "Episode: 102, Total Reward: 50, Total Reward: -50\n",
            "Episode: 103, Total Reward: 50, Total Reward: -50\n",
            "Episode: 104, Total Reward: 50, Total Reward: -50\n",
            "Episode: 105, Total Reward: 50, Total Reward: -50\n",
            "Episode: 106, Total Reward: 50, Total Reward: -50\n",
            "Episode: 107, Total Reward: 50, Total Reward: -50\n",
            "Episode: 108, Total Reward: 50, Total Reward: -50\n",
            "Episode: 109, Total Reward: 50, Total Reward: -50\n",
            "Episode: 110, Total Reward: 50, Total Reward: -50\n",
            "Episode: 111, Total Reward: 50, Total Reward: -50\n",
            "Episode: 112, Total Reward: 50, Total Reward: -50\n",
            "Episode: 113, Total Reward: 50, Total Reward: -50\n",
            "Episode: 114, Total Reward: 50, Total Reward: -50\n",
            "Episode: 115, Total Reward: 50, Total Reward: -50\n",
            "Episode: 116, Total Reward: 50, Total Reward: -50\n",
            "Episode: 117, Total Reward: 50, Total Reward: -50\n",
            "Episode: 118, Total Reward: 50, Total Reward: -50\n",
            "Episode: 119, Total Reward: 14, Total Reward: -14\n",
            "Episode: 120, Total Reward: 50, Total Reward: -50\n",
            "Episode: 121, Total Reward: 50, Total Reward: -50\n",
            "Episode: 122, Total Reward: 50, Total Reward: -50\n",
            "Episode: 123, Total Reward: 50, Total Reward: -50\n",
            "Episode: 124, Total Reward: 50, Total Reward: -50\n",
            "Episode: 125, Total Reward: 50, Total Reward: -50\n",
            "Episode: 126, Total Reward: 50, Total Reward: -50\n",
            "Episode: 127, Total Reward: 50, Total Reward: -50\n",
            "Episode: 128, Total Reward: 50, Total Reward: -50\n",
            "Episode: 129, Total Reward: 14, Total Reward: -14\n",
            "Episode: 130, Total Reward: 50, Total Reward: -50\n",
            "Episode: 131, Total Reward: 50, Total Reward: -50\n",
            "Episode: 132, Total Reward: 50, Total Reward: -50\n",
            "Episode: 133, Total Reward: 50, Total Reward: -50\n",
            "Episode: 134, Total Reward: 50, Total Reward: -50\n",
            "Episode: 135, Total Reward: 50, Total Reward: -50\n",
            "Episode: 136, Total Reward: 50, Total Reward: -50\n",
            "Episode: 137, Total Reward: 50, Total Reward: -50\n",
            "Episode: 138, Total Reward: 50, Total Reward: -50\n",
            "Episode: 139, Total Reward: 50, Total Reward: -50\n",
            "Episode: 140, Total Reward: 50, Total Reward: -50\n",
            "Episode: 141, Total Reward: 50, Total Reward: -50\n",
            "Episode: 142, Total Reward: 50, Total Reward: -50\n",
            "Episode: 143, Total Reward: 50, Total Reward: -50\n",
            "Episode: 144, Total Reward: 50, Total Reward: -50\n",
            "Episode: 145, Total Reward: 50, Total Reward: -50\n",
            "Episode: 146, Total Reward: 50, Total Reward: -50\n",
            "Episode: 147, Total Reward: 50, Total Reward: -50\n",
            "Episode: 148, Total Reward: 50, Total Reward: -50\n",
            "Episode: 149, Total Reward: 50, Total Reward: -50\n",
            "Episode: 150, Total Reward: 50, Total Reward: -50\n",
            "Episode: 151, Total Reward: 50, Total Reward: -50\n",
            "Episode: 152, Total Reward: 50, Total Reward: -50\n",
            "Episode: 153, Total Reward: 50, Total Reward: -50\n",
            "Episode: 154, Total Reward: 50, Total Reward: -50\n",
            "Episode: 155, Total Reward: 50, Total Reward: -50\n",
            "Episode: 156, Total Reward: 50, Total Reward: -50\n",
            "Episode: 157, Total Reward: 50, Total Reward: -50\n",
            "Episode: 158, Total Reward: 50, Total Reward: -50\n",
            "Episode: 159, Total Reward: 14, Total Reward: -14\n",
            "Episode: 160, Total Reward: 50, Total Reward: -50\n",
            "Episode: 161, Total Reward: 50, Total Reward: -50\n",
            "Episode: 162, Total Reward: 50, Total Reward: -50\n",
            "Episode: 163, Total Reward: 50, Total Reward: -50\n",
            "Episode: 164, Total Reward: 50, Total Reward: -50\n",
            "Episode: 165, Total Reward: 14, Total Reward: -14\n",
            "Episode: 166, Total Reward: 41, Total Reward: -41\n",
            "Episode: 167, Total Reward: 50, Total Reward: -50\n",
            "Episode: 168, Total Reward: 50, Total Reward: -50\n",
            "Episode: 169, Total Reward: 50, Total Reward: -50\n",
            "Episode: 170, Total Reward: 14, Total Reward: -14\n",
            "Episode: 171, Total Reward: 50, Total Reward: -50\n",
            "Episode: 172, Total Reward: 50, Total Reward: -50\n",
            "Episode: 173, Total Reward: 50, Total Reward: -50\n",
            "Episode: 174, Total Reward: 50, Total Reward: -50\n",
            "Episode: 175, Total Reward: 50, Total Reward: -50\n",
            "Episode: 176, Total Reward: 14, Total Reward: -14\n",
            "Episode: 177, Total Reward: 50, Total Reward: -50\n",
            "Episode: 178, Total Reward: 50, Total Reward: -50\n",
            "Episode: 179, Total Reward: 50, Total Reward: -50\n",
            "Episode: 180, Total Reward: 14, Total Reward: -14\n",
            "Episode: 181, Total Reward: 50, Total Reward: -50\n",
            "Episode: 182, Total Reward: 50, Total Reward: -50\n",
            "Episode: 183, Total Reward: 50, Total Reward: -50\n",
            "Episode: 184, Total Reward: 50, Total Reward: -50\n",
            "Episode: 185, Total Reward: 50, Total Reward: -50\n",
            "Episode: 186, Total Reward: 50, Total Reward: -50\n",
            "Episode: 187, Total Reward: 14, Total Reward: -14\n",
            "Episode: 188, Total Reward: 14, Total Reward: -14\n",
            "Episode: 189, Total Reward: 14, Total Reward: -14\n",
            "Episode: 190, Total Reward: 14, Total Reward: -14\n",
            "Episode: 191, Total Reward: 50, Total Reward: -50\n",
            "Episode: 192, Total Reward: 19, Total Reward: -19\n",
            "Episode: 193, Total Reward: 50, Total Reward: -50\n",
            "Episode: 194, Total Reward: 50, Total Reward: -50\n",
            "Episode: 195, Total Reward: 50, Total Reward: -50\n",
            "Episode: 196, Total Reward: 14, Total Reward: -14\n",
            "Episode: 197, Total Reward: 14, Total Reward: -14\n",
            "Episode: 198, Total Reward: 14, Total Reward: -14\n",
            "Episode: 199, Total Reward: 14, Total Reward: -14\n",
            "Episode: 200, Total Reward: 14, Total Reward: -14\n",
            "Episode: 201, Total Reward: 50, Total Reward: -50\n",
            "Episode: 202, Total Reward: 50, Total Reward: -50\n",
            "Episode: 203, Total Reward: 50, Total Reward: -50\n",
            "Episode: 204, Total Reward: 14, Total Reward: -14\n",
            "Episode: 205, Total Reward: 14, Total Reward: -14\n",
            "Episode: 206, Total Reward: 14, Total Reward: -14\n",
            "Episode: 207, Total Reward: 14, Total Reward: -14\n",
            "Episode: 208, Total Reward: 50, Total Reward: -50\n",
            "Episode: 209, Total Reward: 14, Total Reward: -14\n",
            "Episode: 210, Total Reward: 14, Total Reward: -14\n",
            "Episode: 211, Total Reward: 16, Total Reward: -16\n",
            "Episode: 212, Total Reward: 50, Total Reward: -50\n",
            "Episode: 213, Total Reward: 50, Total Reward: -50\n",
            "Episode: 214, Total Reward: 50, Total Reward: -50\n",
            "Episode: 215, Total Reward: 14, Total Reward: -14\n",
            "Episode: 216, Total Reward: 50, Total Reward: -50\n",
            "Episode: 217, Total Reward: 14, Total Reward: -14\n",
            "Episode: 218, Total Reward: 50, Total Reward: -50\n",
            "Episode: 219, Total Reward: 50, Total Reward: -50\n",
            "Episode: 220, Total Reward: 50, Total Reward: -50\n",
            "Episode: 221, Total Reward: 50, Total Reward: -50\n",
            "Episode: 222, Total Reward: 50, Total Reward: -50\n",
            "Episode: 223, Total Reward: 14, Total Reward: -14\n",
            "Episode: 224, Total Reward: 50, Total Reward: -50\n",
            "Episode: 225, Total Reward: 50, Total Reward: -50\n",
            "Episode: 226, Total Reward: 50, Total Reward: -50\n",
            "Episode: 227, Total Reward: 50, Total Reward: -50\n",
            "Episode: 228, Total Reward: 50, Total Reward: -50\n",
            "Episode: 229, Total Reward: 50, Total Reward: -50\n",
            "Episode: 230, Total Reward: 50, Total Reward: -50\n",
            "Episode: 231, Total Reward: 50, Total Reward: -50\n",
            "Episode: 232, Total Reward: 50, Total Reward: -50\n",
            "Episode: 233, Total Reward: 50, Total Reward: -50\n",
            "Episode: 234, Total Reward: 50, Total Reward: -50\n",
            "Episode: 235, Total Reward: 14, Total Reward: -14\n",
            "Episode: 236, Total Reward: 14, Total Reward: -14\n",
            "Episode: 237, Total Reward: 50, Total Reward: -50\n",
            "Episode: 238, Total Reward: 50, Total Reward: -50\n",
            "Episode: 239, Total Reward: 14, Total Reward: -14\n",
            "Episode: 240, Total Reward: 50, Total Reward: -50\n",
            "Episode: 241, Total Reward: 15, Total Reward: -15\n",
            "Episode: 242, Total Reward: 50, Total Reward: -50\n",
            "Episode: 243, Total Reward: 50, Total Reward: -50\n",
            "Episode: 244, Total Reward: 50, Total Reward: -50\n",
            "Episode: 245, Total Reward: 50, Total Reward: -50\n",
            "Episode: 246, Total Reward: 50, Total Reward: -50\n",
            "Episode: 247, Total Reward: 50, Total Reward: -50\n",
            "Episode: 248, Total Reward: 14, Total Reward: -14\n",
            "Episode: 249, Total Reward: 50, Total Reward: -50\n",
            "Episode: 250, Total Reward: 50, Total Reward: -50\n",
            "Episode: 251, Total Reward: 14, Total Reward: -14\n",
            "Episode: 252, Total Reward: 50, Total Reward: -50\n",
            "Episode: 253, Total Reward: 50, Total Reward: -50\n",
            "Episode: 254, Total Reward: 50, Total Reward: -50\n",
            "Episode: 255, Total Reward: 14, Total Reward: -14\n",
            "Episode: 256, Total Reward: 14, Total Reward: -14\n",
            "Episode: 257, Total Reward: 50, Total Reward: -50\n",
            "Episode: 258, Total Reward: 14, Total Reward: -14\n",
            "Episode: 259, Total Reward: 14, Total Reward: -14\n",
            "Episode: 260, Total Reward: 50, Total Reward: -50\n",
            "Episode: 261, Total Reward: 14, Total Reward: -14\n",
            "Episode: 262, Total Reward: 15, Total Reward: -15\n",
            "Episode: 263, Total Reward: 50, Total Reward: -50\n",
            "Episode: 264, Total Reward: 50, Total Reward: -50\n",
            "Episode: 265, Total Reward: 50, Total Reward: -50\n",
            "Episode: 266, Total Reward: 50, Total Reward: -50\n",
            "Episode: 267, Total Reward: 14, Total Reward: -14\n",
            "Episode: 268, Total Reward: 14, Total Reward: -14\n",
            "Episode: 269, Total Reward: 50, Total Reward: -50\n",
            "Episode: 270, Total Reward: 50, Total Reward: -50\n",
            "Episode: 271, Total Reward: 28, Total Reward: -28\n",
            "Episode: 272, Total Reward: 50, Total Reward: -50\n",
            "Episode: 273, Total Reward: 50, Total Reward: -50\n",
            "Episode: 274, Total Reward: 50, Total Reward: -50\n",
            "Episode: 275, Total Reward: 50, Total Reward: -50\n",
            "Episode: 276, Total Reward: 50, Total Reward: -50\n",
            "Episode: 277, Total Reward: 50, Total Reward: -50\n",
            "Episode: 278, Total Reward: 14, Total Reward: -14\n",
            "Episode: 279, Total Reward: 50, Total Reward: -50\n",
            "Episode: 280, Total Reward: 50, Total Reward: -50\n",
            "Episode: 281, Total Reward: 50, Total Reward: -50\n",
            "Episode: 282, Total Reward: 50, Total Reward: -50\n",
            "Episode: 283, Total Reward: 50, Total Reward: -50\n",
            "Episode: 284, Total Reward: 50, Total Reward: -50\n",
            "Episode: 285, Total Reward: 50, Total Reward: -50\n",
            "Episode: 286, Total Reward: 50, Total Reward: -50\n",
            "Episode: 287, Total Reward: 50, Total Reward: -50\n",
            "Episode: 288, Total Reward: 50, Total Reward: -50\n",
            "Episode: 289, Total Reward: 14, Total Reward: -14\n",
            "Episode: 290, Total Reward: 50, Total Reward: -50\n",
            "Episode: 291, Total Reward: 50, Total Reward: -50\n",
            "Episode: 292, Total Reward: 50, Total Reward: -50\n",
            "Episode: 293, Total Reward: 14, Total Reward: -14\n",
            "Episode: 294, Total Reward: 50, Total Reward: -50\n",
            "Episode: 295, Total Reward: 50, Total Reward: -50\n",
            "Episode: 296, Total Reward: 50, Total Reward: -50\n",
            "Episode: 297, Total Reward: 50, Total Reward: -50\n",
            "Episode: 298, Total Reward: 50, Total Reward: -50\n",
            "Episode: 299, Total Reward: 14, Total Reward: -14\n",
            "Episode: 300, Total Reward: 14, Total Reward: -14\n",
            "Episode: 301, Total Reward: 14, Total Reward: -14\n",
            "Episode: 302, Total Reward: 50, Total Reward: -50\n",
            "Episode: 303, Total Reward: 50, Total Reward: -50\n",
            "Episode: 304, Total Reward: 50, Total Reward: -50\n",
            "Episode: 305, Total Reward: 50, Total Reward: -50\n",
            "Episode: 306, Total Reward: 16, Total Reward: -16\n",
            "Episode: 307, Total Reward: 50, Total Reward: -50\n",
            "Episode: 308, Total Reward: 50, Total Reward: -50\n",
            "Episode: 309, Total Reward: 50, Total Reward: -50\n",
            "Episode: 310, Total Reward: 50, Total Reward: -50\n",
            "Episode: 311, Total Reward: 50, Total Reward: -50\n",
            "Episode: 312, Total Reward: 50, Total Reward: -50\n",
            "Episode: 313, Total Reward: 50, Total Reward: -50\n",
            "Episode: 314, Total Reward: 14, Total Reward: -14\n",
            "Episode: 315, Total Reward: 50, Total Reward: -50\n",
            "Episode: 316, Total Reward: 50, Total Reward: -50\n",
            "Episode: 317, Total Reward: 50, Total Reward: -50\n",
            "Episode: 318, Total Reward: 50, Total Reward: -50\n",
            "Episode: 319, Total Reward: 50, Total Reward: -50\n",
            "Episode: 320, Total Reward: 14, Total Reward: -14\n",
            "Episode: 321, Total Reward: 50, Total Reward: -50\n",
            "Episode: 322, Total Reward: 14, Total Reward: -14\n",
            "Episode: 323, Total Reward: 14, Total Reward: -14\n",
            "Episode: 324, Total Reward: 50, Total Reward: -50\n",
            "Episode: 325, Total Reward: 50, Total Reward: -50\n",
            "Episode: 326, Total Reward: 50, Total Reward: -50\n",
            "Episode: 327, Total Reward: 50, Total Reward: -50\n",
            "Episode: 328, Total Reward: 14, Total Reward: -14\n",
            "Episode: 329, Total Reward: 50, Total Reward: -50\n",
            "Episode: 330, Total Reward: 50, Total Reward: -50\n",
            "Episode: 331, Total Reward: 50, Total Reward: -50\n",
            "Episode: 332, Total Reward: 50, Total Reward: -50\n",
            "Episode: 333, Total Reward: 50, Total Reward: -50\n",
            "Episode: 334, Total Reward: 14, Total Reward: -14\n",
            "Episode: 335, Total Reward: 14, Total Reward: -14\n",
            "Episode: 336, Total Reward: 50, Total Reward: -50\n",
            "Episode: 337, Total Reward: 50, Total Reward: -50\n",
            "Episode: 338, Total Reward: 14, Total Reward: -14\n",
            "Episode: 339, Total Reward: 50, Total Reward: -50\n",
            "Episode: 340, Total Reward: 50, Total Reward: -50\n",
            "Episode: 341, Total Reward: 14, Total Reward: -14\n",
            "Episode: 342, Total Reward: 50, Total Reward: -50\n",
            "Episode: 343, Total Reward: 14, Total Reward: -14\n",
            "Episode: 344, Total Reward: 50, Total Reward: -50\n",
            "Episode: 345, Total Reward: 50, Total Reward: -50\n",
            "Episode: 346, Total Reward: 50, Total Reward: -50\n",
            "Episode: 347, Total Reward: 50, Total Reward: -50\n",
            "Episode: 348, Total Reward: 50, Total Reward: -50\n",
            "Episode: 349, Total Reward: 50, Total Reward: -50\n",
            "Episode: 350, Total Reward: 14, Total Reward: -14\n",
            "Episode: 351, Total Reward: 50, Total Reward: -50\n",
            "Episode: 352, Total Reward: 50, Total Reward: -50\n",
            "Episode: 353, Total Reward: 50, Total Reward: -50\n",
            "Episode: 354, Total Reward: 50, Total Reward: -50\n",
            "Episode: 355, Total Reward: 50, Total Reward: -50\n",
            "Episode: 356, Total Reward: 50, Total Reward: -50\n",
            "Episode: 357, Total Reward: 50, Total Reward: -50\n",
            "Episode: 358, Total Reward: 50, Total Reward: -50\n",
            "Episode: 359, Total Reward: 50, Total Reward: -50\n",
            "Episode: 360, Total Reward: 50, Total Reward: -50\n",
            "Episode: 361, Total Reward: 50, Total Reward: -50\n",
            "Episode: 362, Total Reward: 50, Total Reward: -50\n",
            "Episode: 363, Total Reward: 50, Total Reward: -50\n",
            "Episode: 364, Total Reward: 50, Total Reward: -50\n",
            "Episode: 365, Total Reward: 50, Total Reward: -50\n",
            "Episode: 366, Total Reward: 50, Total Reward: -50\n",
            "Episode: 367, Total Reward: 30, Total Reward: -30\n",
            "Episode: 368, Total Reward: 14, Total Reward: -14\n",
            "Episode: 369, Total Reward: 50, Total Reward: -50\n",
            "Episode: 370, Total Reward: 50, Total Reward: -50\n",
            "Episode: 371, Total Reward: 14, Total Reward: -14\n",
            "Episode: 372, Total Reward: 50, Total Reward: -50\n",
            "Episode: 373, Total Reward: 50, Total Reward: -50\n",
            "Episode: 374, Total Reward: 50, Total Reward: -50\n",
            "Episode: 375, Total Reward: 50, Total Reward: -50\n",
            "Episode: 376, Total Reward: 50, Total Reward: -50\n",
            "Episode: 377, Total Reward: 50, Total Reward: -50\n",
            "Episode: 378, Total Reward: 50, Total Reward: -50\n",
            "Episode: 379, Total Reward: 50, Total Reward: -50\n",
            "Episode: 380, Total Reward: 14, Total Reward: -14\n",
            "Episode: 381, Total Reward: 50, Total Reward: -50\n",
            "Episode: 382, Total Reward: 43, Total Reward: -43\n",
            "Episode: 383, Total Reward: 14, Total Reward: -14\n",
            "Episode: 384, Total Reward: 50, Total Reward: -50\n",
            "Episode: 385, Total Reward: 14, Total Reward: -14\n",
            "Episode: 386, Total Reward: 50, Total Reward: -50\n",
            "Episode: 387, Total Reward: 50, Total Reward: -50\n",
            "Episode: 388, Total Reward: 50, Total Reward: -50\n",
            "Episode: 389, Total Reward: 50, Total Reward: -50\n",
            "Episode: 390, Total Reward: 50, Total Reward: -50\n",
            "Episode: 391, Total Reward: 50, Total Reward: -50\n",
            "Episode: 392, Total Reward: 50, Total Reward: -50\n",
            "Episode: 393, Total Reward: 50, Total Reward: -50\n",
            "Episode: 394, Total Reward: 50, Total Reward: -50\n",
            "Episode: 395, Total Reward: 50, Total Reward: -50\n",
            "Episode: 396, Total Reward: 50, Total Reward: -50\n",
            "Episode: 397, Total Reward: 50, Total Reward: -50\n",
            "Episode: 398, Total Reward: 14, Total Reward: -14\n",
            "Episode: 399, Total Reward: 14, Total Reward: -14\n",
            "Episode: 400, Total Reward: 50, Total Reward: -50\n",
            "Episode: 401, Total Reward: 50, Total Reward: -50\n",
            "Episode: 402, Total Reward: 50, Total Reward: -50\n",
            "Episode: 403, Total Reward: 50, Total Reward: -50\n",
            "Episode: 404, Total Reward: 50, Total Reward: -50\n",
            "Episode: 405, Total Reward: 16, Total Reward: -16\n",
            "Episode: 406, Total Reward: 14, Total Reward: -14\n",
            "Episode: 407, Total Reward: 14, Total Reward: -14\n",
            "Episode: 408, Total Reward: 50, Total Reward: -50\n",
            "Episode: 409, Total Reward: 50, Total Reward: -50\n",
            "Episode: 410, Total Reward: 50, Total Reward: -50\n",
            "Episode: 411, Total Reward: 50, Total Reward: -50\n",
            "Episode: 412, Total Reward: 50, Total Reward: -50\n",
            "Episode: 413, Total Reward: 50, Total Reward: -50\n",
            "Episode: 414, Total Reward: 50, Total Reward: -50\n",
            "Episode: 415, Total Reward: 50, Total Reward: -50\n",
            "Episode: 416, Total Reward: 50, Total Reward: -50\n",
            "Episode: 417, Total Reward: 14, Total Reward: -14\n",
            "Episode: 418, Total Reward: 50, Total Reward: -50\n",
            "Episode: 419, Total Reward: 50, Total Reward: -50\n",
            "Episode: 420, Total Reward: 50, Total Reward: -50\n",
            "Episode: 421, Total Reward: 50, Total Reward: -50\n",
            "Episode: 422, Total Reward: 14, Total Reward: -14\n",
            "Episode: 423, Total Reward: 14, Total Reward: -14\n",
            "Episode: 424, Total Reward: 50, Total Reward: -50\n",
            "Episode: 425, Total Reward: 14, Total Reward: -14\n",
            "Episode: 426, Total Reward: 50, Total Reward: -50\n",
            "Episode: 427, Total Reward: 50, Total Reward: -50\n",
            "Episode: 428, Total Reward: 50, Total Reward: -50\n",
            "Episode: 429, Total Reward: 50, Total Reward: -50\n",
            "Episode: 430, Total Reward: 50, Total Reward: -50\n",
            "Episode: 431, Total Reward: 50, Total Reward: -50\n",
            "Episode: 432, Total Reward: 14, Total Reward: -14\n",
            "Episode: 433, Total Reward: 50, Total Reward: -50\n",
            "Episode: 434, Total Reward: 50, Total Reward: -50\n",
            "Episode: 435, Total Reward: 50, Total Reward: -50\n",
            "Episode: 436, Total Reward: 50, Total Reward: -50\n",
            "Episode: 437, Total Reward: 50, Total Reward: -50\n",
            "Episode: 438, Total Reward: 50, Total Reward: -50\n",
            "Episode: 439, Total Reward: 50, Total Reward: -50\n",
            "Episode: 440, Total Reward: 50, Total Reward: -50\n",
            "Episode: 441, Total Reward: 50, Total Reward: -50\n",
            "Episode: 442, Total Reward: 16, Total Reward: -16\n",
            "Episode: 443, Total Reward: 50, Total Reward: -50\n",
            "Episode: 444, Total Reward: 50, Total Reward: -50\n",
            "Episode: 445, Total Reward: 50, Total Reward: -50\n",
            "Episode: 446, Total Reward: 14, Total Reward: -14\n",
            "Episode: 447, Total Reward: 50, Total Reward: -50\n",
            "Episode: 448, Total Reward: 50, Total Reward: -50\n",
            "Episode: 449, Total Reward: 50, Total Reward: -50\n",
            "Episode: 450, Total Reward: 14, Total Reward: -14\n",
            "Episode: 451, Total Reward: 50, Total Reward: -50\n",
            "Episode: 452, Total Reward: 50, Total Reward: -50\n",
            "Episode: 453, Total Reward: 14, Total Reward: -14\n",
            "Episode: 454, Total Reward: 50, Total Reward: -50\n",
            "Episode: 455, Total Reward: 50, Total Reward: -50\n",
            "Episode: 456, Total Reward: 50, Total Reward: -50\n",
            "Episode: 457, Total Reward: 50, Total Reward: -50\n",
            "Episode: 458, Total Reward: 50, Total Reward: -50\n",
            "Episode: 459, Total Reward: 50, Total Reward: -50\n",
            "Episode: 460, Total Reward: 50, Total Reward: -50\n",
            "Episode: 461, Total Reward: 50, Total Reward: -50\n",
            "Episode: 462, Total Reward: 14, Total Reward: -14\n",
            "Episode: 463, Total Reward: 14, Total Reward: -14\n",
            "Episode: 464, Total Reward: 50, Total Reward: -50\n",
            "Episode: 465, Total Reward: 14, Total Reward: -14\n",
            "Episode: 466, Total Reward: 50, Total Reward: -50\n",
            "Episode: 467, Total Reward: 50, Total Reward: -50\n",
            "Episode: 468, Total Reward: 50, Total Reward: -50\n",
            "Episode: 469, Total Reward: 50, Total Reward: -50\n",
            "Episode: 470, Total Reward: 50, Total Reward: -50\n",
            "Episode: 471, Total Reward: 50, Total Reward: -50\n",
            "Episode: 472, Total Reward: 14, Total Reward: -14\n",
            "Episode: 473, Total Reward: 50, Total Reward: -50\n",
            "Episode: 474, Total Reward: 50, Total Reward: -50\n",
            "Episode: 475, Total Reward: 50, Total Reward: -50\n",
            "Episode: 476, Total Reward: 50, Total Reward: -50\n",
            "Episode: 477, Total Reward: 50, Total Reward: -50\n",
            "Episode: 478, Total Reward: 50, Total Reward: -50\n",
            "Episode: 479, Total Reward: 50, Total Reward: -50\n",
            "Episode: 480, Total Reward: 14, Total Reward: -14\n",
            "Episode: 481, Total Reward: 14, Total Reward: -14\n",
            "Episode: 482, Total Reward: 50, Total Reward: -50\n",
            "Episode: 483, Total Reward: 50, Total Reward: -50\n",
            "Episode: 484, Total Reward: 14, Total Reward: -14\n",
            "Episode: 485, Total Reward: 50, Total Reward: -50\n",
            "Episode: 486, Total Reward: 50, Total Reward: -50\n",
            "Episode: 487, Total Reward: 14, Total Reward: -14\n",
            "Episode: 488, Total Reward: 50, Total Reward: -50\n",
            "Episode: 489, Total Reward: 14, Total Reward: -14\n",
            "Episode: 490, Total Reward: 50, Total Reward: -50\n",
            "Episode: 491, Total Reward: 50, Total Reward: -50\n",
            "Episode: 492, Total Reward: 14, Total Reward: -14\n",
            "Episode: 493, Total Reward: 50, Total Reward: -50\n",
            "Episode: 494, Total Reward: 50, Total Reward: -50\n",
            "Episode: 495, Total Reward: 50, Total Reward: -50\n",
            "Episode: 496, Total Reward: 14, Total Reward: -14\n",
            "Episode: 497, Total Reward: 50, Total Reward: -50\n",
            "Episode: 498, Total Reward: 50, Total Reward: -50\n",
            "Episode: 499, Total Reward: 50, Total Reward: -50\n",
            "Episode: 500, Total Reward: 14, Total Reward: -14\n",
            "Episode: 501, Total Reward: 50, Total Reward: -50\n",
            "Episode: 502, Total Reward: 50, Total Reward: -50\n",
            "Episode: 503, Total Reward: 14, Total Reward: -14\n",
            "Episode: 504, Total Reward: 50, Total Reward: -50\n",
            "Episode: 505, Total Reward: 50, Total Reward: -50\n",
            "Episode: 506, Total Reward: 50, Total Reward: -50\n",
            "Episode: 507, Total Reward: 50, Total Reward: -50\n",
            "Episode: 508, Total Reward: 50, Total Reward: -50\n",
            "Episode: 509, Total Reward: 50, Total Reward: -50\n",
            "Episode: 510, Total Reward: 50, Total Reward: -50\n",
            "Episode: 511, Total Reward: 14, Total Reward: -14\n",
            "Episode: 512, Total Reward: 50, Total Reward: -50\n",
            "Episode: 513, Total Reward: 50, Total Reward: -50\n",
            "Episode: 514, Total Reward: 50, Total Reward: -50\n",
            "Episode: 515, Total Reward: 50, Total Reward: -50\n",
            "Episode: 516, Total Reward: 50, Total Reward: -50\n",
            "Episode: 517, Total Reward: 50, Total Reward: -50\n",
            "Episode: 518, Total Reward: 50, Total Reward: -50\n",
            "Episode: 519, Total Reward: 50, Total Reward: -50\n",
            "Episode: 520, Total Reward: 14, Total Reward: -14\n",
            "Episode: 521, Total Reward: 14, Total Reward: -14\n",
            "Episode: 522, Total Reward: 50, Total Reward: -50\n",
            "Episode: 523, Total Reward: 50, Total Reward: -50\n",
            "Episode: 524, Total Reward: 50, Total Reward: -50\n",
            "Episode: 525, Total Reward: 50, Total Reward: -50\n",
            "Episode: 526, Total Reward: 14, Total Reward: -14\n",
            "Episode: 527, Total Reward: 50, Total Reward: -50\n",
            "Episode: 528, Total Reward: 50, Total Reward: -50\n",
            "Episode: 529, Total Reward: 50, Total Reward: -50\n",
            "Episode: 530, Total Reward: 14, Total Reward: -14\n",
            "Episode: 531, Total Reward: 50, Total Reward: -50\n",
            "Episode: 532, Total Reward: 14, Total Reward: -14\n",
            "Episode: 533, Total Reward: 50, Total Reward: -50\n",
            "Episode: 534, Total Reward: 14, Total Reward: -14\n",
            "Episode: 535, Total Reward: 50, Total Reward: -50\n",
            "Episode: 536, Total Reward: 50, Total Reward: -50\n",
            "Episode: 537, Total Reward: 14, Total Reward: -14\n",
            "Episode: 538, Total Reward: 50, Total Reward: -50\n",
            "Episode: 539, Total Reward: 14, Total Reward: -14\n",
            "Episode: 540, Total Reward: 50, Total Reward: -50\n",
            "Episode: 541, Total Reward: 50, Total Reward: -50\n",
            "Episode: 542, Total Reward: 50, Total Reward: -50\n",
            "Episode: 543, Total Reward: 50, Total Reward: -50\n",
            "Episode: 544, Total Reward: 50, Total Reward: -50\n",
            "Episode: 545, Total Reward: 50, Total Reward: -50\n",
            "Episode: 546, Total Reward: 50, Total Reward: -50\n",
            "Episode: 547, Total Reward: 14, Total Reward: -14\n",
            "Episode: 548, Total Reward: 50, Total Reward: -50\n",
            "Episode: 549, Total Reward: 14, Total Reward: -14\n",
            "Episode: 550, Total Reward: 50, Total Reward: -50\n",
            "Episode: 551, Total Reward: 50, Total Reward: -50\n",
            "Episode: 552, Total Reward: 50, Total Reward: -50\n",
            "Episode: 553, Total Reward: 50, Total Reward: -50\n",
            "Episode: 554, Total Reward: 50, Total Reward: -50\n",
            "Episode: 555, Total Reward: 50, Total Reward: -50\n",
            "Episode: 556, Total Reward: 50, Total Reward: -50\n",
            "Episode: 557, Total Reward: 50, Total Reward: -50\n",
            "Episode: 558, Total Reward: 50, Total Reward: -50\n",
            "Episode: 559, Total Reward: 14, Total Reward: -14\n",
            "Episode: 560, Total Reward: 14, Total Reward: -14\n",
            "Episode: 561, Total Reward: 14, Total Reward: -14\n",
            "Episode: 562, Total Reward: 50, Total Reward: -50\n",
            "Episode: 563, Total Reward: 14, Total Reward: -14\n",
            "Episode: 564, Total Reward: 50, Total Reward: -50\n",
            "Episode: 565, Total Reward: 14, Total Reward: -14\n",
            "Episode: 566, Total Reward: 14, Total Reward: -14\n",
            "Episode: 567, Total Reward: 50, Total Reward: -50\n",
            "Episode: 568, Total Reward: 14, Total Reward: -14\n",
            "Episode: 569, Total Reward: 16, Total Reward: -16\n",
            "Episode: 570, Total Reward: 50, Total Reward: -50\n",
            "Episode: 571, Total Reward: 16, Total Reward: -16\n",
            "Episode: 572, Total Reward: 14, Total Reward: -14\n",
            "Episode: 573, Total Reward: 14, Total Reward: -14\n",
            "Episode: 574, Total Reward: 14, Total Reward: -14\n",
            "Episode: 575, Total Reward: 14, Total Reward: -14\n",
            "Episode: 576, Total Reward: 14, Total Reward: -14\n",
            "Episode: 577, Total Reward: 50, Total Reward: -50\n",
            "Episode: 578, Total Reward: 14, Total Reward: -14\n",
            "Episode: 579, Total Reward: 50, Total Reward: -50\n",
            "Episode: 580, Total Reward: 50, Total Reward: -50\n",
            "Episode: 581, Total Reward: 14, Total Reward: -14\n",
            "Episode: 582, Total Reward: 14, Total Reward: -14\n",
            "Episode: 583, Total Reward: 50, Total Reward: -50\n",
            "Episode: 584, Total Reward: 50, Total Reward: -50\n",
            "Episode: 585, Total Reward: 50, Total Reward: -50\n",
            "Episode: 586, Total Reward: 14, Total Reward: -14\n",
            "Episode: 587, Total Reward: 50, Total Reward: -50\n",
            "Episode: 588, Total Reward: 14, Total Reward: -14\n",
            "Episode: 589, Total Reward: 50, Total Reward: -50\n",
            "Episode: 590, Total Reward: 14, Total Reward: -14\n",
            "Episode: 591, Total Reward: 14, Total Reward: -14\n",
            "Episode: 592, Total Reward: 14, Total Reward: -14\n",
            "Episode: 593, Total Reward: 14, Total Reward: -14\n",
            "Episode: 594, Total Reward: 14, Total Reward: -14\n",
            "Episode: 595, Total Reward: 50, Total Reward: -50\n",
            "Episode: 596, Total Reward: 50, Total Reward: -50\n",
            "Episode: 597, Total Reward: 14, Total Reward: -14\n",
            "Episode: 598, Total Reward: 14, Total Reward: -14\n",
            "Episode: 599, Total Reward: 14, Total Reward: -14\n",
            "Episode: 600, Total Reward: 50, Total Reward: -50\n",
            "Episode: 601, Total Reward: 50, Total Reward: -50\n",
            "Episode: 602, Total Reward: 14, Total Reward: -14\n",
            "Episode: 603, Total Reward: 14, Total Reward: -14\n",
            "Episode: 604, Total Reward: 50, Total Reward: -50\n",
            "Episode: 605, Total Reward: 50, Total Reward: -50\n",
            "Episode: 606, Total Reward: 15, Total Reward: -15\n",
            "Episode: 607, Total Reward: 50, Total Reward: -50\n",
            "Episode: 608, Total Reward: 50, Total Reward: -50\n",
            "Episode: 609, Total Reward: 50, Total Reward: -50\n",
            "Episode: 610, Total Reward: 50, Total Reward: -50\n",
            "Episode: 611, Total Reward: 14, Total Reward: -14\n",
            "Episode: 612, Total Reward: 14, Total Reward: -14\n",
            "Episode: 613, Total Reward: 50, Total Reward: -50\n",
            "Episode: 614, Total Reward: 14, Total Reward: -14\n",
            "Episode: 615, Total Reward: 50, Total Reward: -50\n",
            "Episode: 616, Total Reward: 50, Total Reward: -50\n",
            "Episode: 617, Total Reward: 14, Total Reward: -14\n",
            "Episode: 618, Total Reward: 14, Total Reward: -14\n",
            "Episode: 619, Total Reward: 14, Total Reward: -14\n",
            "Episode: 620, Total Reward: 15, Total Reward: -15\n",
            "Episode: 621, Total Reward: 50, Total Reward: -50\n",
            "Episode: 622, Total Reward: 14, Total Reward: -14\n",
            "Episode: 623, Total Reward: 50, Total Reward: -50\n",
            "Episode: 624, Total Reward: 14, Total Reward: -14\n",
            "Episode: 625, Total Reward: 14, Total Reward: -14\n",
            "Episode: 626, Total Reward: 14, Total Reward: -14\n",
            "Episode: 627, Total Reward: 50, Total Reward: -50\n",
            "Episode: 628, Total Reward: 14, Total Reward: -14\n",
            "Episode: 629, Total Reward: 16, Total Reward: -16\n",
            "Episode: 630, Total Reward: 14, Total Reward: -14\n",
            "Episode: 631, Total Reward: 14, Total Reward: -14\n",
            "Episode: 632, Total Reward: 50, Total Reward: -50\n",
            "Episode: 633, Total Reward: 14, Total Reward: -14\n",
            "Episode: 634, Total Reward: 50, Total Reward: -50\n",
            "Episode: 635, Total Reward: 14, Total Reward: -14\n",
            "Episode: 636, Total Reward: 14, Total Reward: -14\n",
            "Episode: 637, Total Reward: 14, Total Reward: -14\n",
            "Episode: 638, Total Reward: 14, Total Reward: -14\n",
            "Episode: 639, Total Reward: 14, Total Reward: -14\n",
            "Episode: 640, Total Reward: 50, Total Reward: -50\n",
            "Episode: 641, Total Reward: 50, Total Reward: -50\n",
            "Episode: 642, Total Reward: 14, Total Reward: -14\n",
            "Episode: 643, Total Reward: 50, Total Reward: -50\n",
            "Episode: 644, Total Reward: 14, Total Reward: -14\n",
            "Episode: 645, Total Reward: 14, Total Reward: -14\n",
            "Episode: 646, Total Reward: 14, Total Reward: -14\n",
            "Episode: 647, Total Reward: 14, Total Reward: -14\n",
            "Episode: 648, Total Reward: 14, Total Reward: -14\n",
            "Episode: 649, Total Reward: 14, Total Reward: -14\n",
            "Episode: 650, Total Reward: 14, Total Reward: -14\n",
            "Episode: 651, Total Reward: 50, Total Reward: -50\n",
            "Episode: 652, Total Reward: 14, Total Reward: -14\n",
            "Episode: 653, Total Reward: 45, Total Reward: -45\n",
            "Episode: 654, Total Reward: 14, Total Reward: -14\n",
            "Episode: 655, Total Reward: 50, Total Reward: -50\n",
            "Episode: 656, Total Reward: 50, Total Reward: -50\n",
            "Episode: 657, Total Reward: 16, Total Reward: -16\n",
            "Episode: 658, Total Reward: 14, Total Reward: -14\n",
            "Episode: 659, Total Reward: 14, Total Reward: -14\n",
            "Episode: 660, Total Reward: 14, Total Reward: -14\n",
            "Episode: 661, Total Reward: 50, Total Reward: -50\n",
            "Episode: 662, Total Reward: 14, Total Reward: -14\n",
            "Episode: 663, Total Reward: 50, Total Reward: -50\n",
            "Episode: 664, Total Reward: 50, Total Reward: -50\n",
            "Episode: 665, Total Reward: 14, Total Reward: -14\n",
            "Episode: 666, Total Reward: 14, Total Reward: -14\n",
            "Episode: 667, Total Reward: 50, Total Reward: -50\n",
            "Episode: 668, Total Reward: 50, Total Reward: -50\n",
            "Episode: 669, Total Reward: 14, Total Reward: -14\n",
            "Episode: 670, Total Reward: 14, Total Reward: -14\n",
            "Episode: 671, Total Reward: 14, Total Reward: -14\n",
            "Episode: 672, Total Reward: 14, Total Reward: -14\n",
            "Episode: 673, Total Reward: 50, Total Reward: -50\n",
            "Episode: 674, Total Reward: 17, Total Reward: -17\n",
            "Episode: 675, Total Reward: 14, Total Reward: -14\n",
            "Episode: 676, Total Reward: 14, Total Reward: -14\n",
            "Episode: 677, Total Reward: 14, Total Reward: -14\n",
            "Episode: 678, Total Reward: 50, Total Reward: -50\n",
            "Episode: 679, Total Reward: 14, Total Reward: -14\n",
            "Episode: 680, Total Reward: 50, Total Reward: -50\n",
            "Episode: 681, Total Reward: 50, Total Reward: -50\n",
            "Episode: 682, Total Reward: 50, Total Reward: -50\n",
            "Episode: 683, Total Reward: 14, Total Reward: -14\n",
            "Episode: 684, Total Reward: 14, Total Reward: -14\n",
            "Episode: 685, Total Reward: 14, Total Reward: -14\n",
            "Episode: 686, Total Reward: 14, Total Reward: -14\n",
            "Episode: 687, Total Reward: 14, Total Reward: -14\n",
            "Episode: 688, Total Reward: 14, Total Reward: -14\n",
            "Episode: 689, Total Reward: 14, Total Reward: -14\n",
            "Episode: 690, Total Reward: 50, Total Reward: -50\n",
            "Episode: 691, Total Reward: 14, Total Reward: -14\n",
            "Episode: 692, Total Reward: 50, Total Reward: -50\n",
            "Episode: 693, Total Reward: 50, Total Reward: -50\n",
            "Episode: 694, Total Reward: 14, Total Reward: -14\n",
            "Episode: 695, Total Reward: 15, Total Reward: -15\n",
            "Episode: 696, Total Reward: 50, Total Reward: -50\n",
            "Episode: 697, Total Reward: 16, Total Reward: -16\n",
            "Episode: 698, Total Reward: 14, Total Reward: -14\n",
            "Episode: 699, Total Reward: 50, Total Reward: -50\n",
            "Episode: 700, Total Reward: 14, Total Reward: -14\n",
            "Episode: 701, Total Reward: 50, Total Reward: -50\n",
            "Episode: 702, Total Reward: 50, Total Reward: -50\n",
            "Episode: 703, Total Reward: 14, Total Reward: -14\n",
            "Episode: 704, Total Reward: 50, Total Reward: -50\n",
            "Episode: 705, Total Reward: 14, Total Reward: -14\n",
            "Episode: 706, Total Reward: 14, Total Reward: -14\n",
            "Episode: 707, Total Reward: 16, Total Reward: -16\n",
            "Episode: 708, Total Reward: 14, Total Reward: -14\n",
            "Episode: 709, Total Reward: 14, Total Reward: -14\n",
            "Episode: 710, Total Reward: 14, Total Reward: -14\n",
            "Episode: 711, Total Reward: 50, Total Reward: -50\n",
            "Episode: 712, Total Reward: 50, Total Reward: -50\n",
            "Episode: 713, Total Reward: 14, Total Reward: -14\n",
            "Episode: 714, Total Reward: 14, Total Reward: -14\n",
            "Episode: 715, Total Reward: 16, Total Reward: -16\n",
            "Episode: 716, Total Reward: 14, Total Reward: -14\n",
            "Episode: 717, Total Reward: 14, Total Reward: -14\n",
            "Episode: 718, Total Reward: 14, Total Reward: -14\n",
            "Episode: 719, Total Reward: 14, Total Reward: -14\n",
            "Episode: 720, Total Reward: 50, Total Reward: -50\n",
            "Episode: 721, Total Reward: 14, Total Reward: -14\n",
            "Episode: 722, Total Reward: 50, Total Reward: -50\n",
            "Episode: 723, Total Reward: 15, Total Reward: -15\n",
            "Episode: 724, Total Reward: 14, Total Reward: -14\n",
            "Episode: 725, Total Reward: 50, Total Reward: -50\n",
            "Episode: 726, Total Reward: 14, Total Reward: -14\n",
            "Episode: 727, Total Reward: 14, Total Reward: -14\n",
            "Episode: 728, Total Reward: 14, Total Reward: -14\n",
            "Episode: 729, Total Reward: 35, Total Reward: -35\n",
            "Episode: 730, Total Reward: 14, Total Reward: -14\n",
            "Episode: 731, Total Reward: 14, Total Reward: -14\n",
            "Episode: 732, Total Reward: 50, Total Reward: -50\n",
            "Episode: 733, Total Reward: 14, Total Reward: -14\n",
            "Episode: 734, Total Reward: 14, Total Reward: -14\n",
            "Episode: 735, Total Reward: 14, Total Reward: -14\n",
            "Episode: 736, Total Reward: 50, Total Reward: -50\n",
            "Episode: 737, Total Reward: 14, Total Reward: -14\n",
            "Episode: 738, Total Reward: 14, Total Reward: -14\n",
            "Episode: 739, Total Reward: 50, Total Reward: -50\n",
            "Episode: 740, Total Reward: 14, Total Reward: -14\n",
            "Episode: 741, Total Reward: 14, Total Reward: -14\n",
            "Episode: 742, Total Reward: 14, Total Reward: -14\n",
            "Episode: 743, Total Reward: 14, Total Reward: -14\n",
            "Episode: 744, Total Reward: 14, Total Reward: -14\n",
            "Episode: 745, Total Reward: 14, Total Reward: -14\n",
            "Episode: 746, Total Reward: 14, Total Reward: -14\n",
            "Episode: 747, Total Reward: 14, Total Reward: -14\n",
            "Episode: 748, Total Reward: 14, Total Reward: -14\n",
            "Episode: 749, Total Reward: 14, Total Reward: -14\n",
            "Episode: 750, Total Reward: 14, Total Reward: -14\n",
            "Episode: 751, Total Reward: 50, Total Reward: -50\n",
            "Episode: 752, Total Reward: 14, Total Reward: -14\n",
            "Episode: 753, Total Reward: 14, Total Reward: -14\n",
            "Episode: 754, Total Reward: 50, Total Reward: -50\n",
            "Episode: 755, Total Reward: 16, Total Reward: -16\n",
            "Episode: 756, Total Reward: 16, Total Reward: -16\n",
            "Episode: 757, Total Reward: 14, Total Reward: -14\n",
            "Episode: 758, Total Reward: 14, Total Reward: -14\n",
            "Episode: 759, Total Reward: 14, Total Reward: -14\n",
            "Episode: 760, Total Reward: 19, Total Reward: -19\n",
            "Episode: 761, Total Reward: 14, Total Reward: -14\n",
            "Episode: 762, Total Reward: 50, Total Reward: -50\n",
            "Episode: 763, Total Reward: 50, Total Reward: -50\n",
            "Episode: 764, Total Reward: 14, Total Reward: -14\n",
            "Episode: 765, Total Reward: 50, Total Reward: -50\n",
            "Episode: 766, Total Reward: 50, Total Reward: -50\n",
            "Episode: 767, Total Reward: 14, Total Reward: -14\n",
            "Episode: 768, Total Reward: 14, Total Reward: -14\n",
            "Episode: 769, Total Reward: 14, Total Reward: -14\n",
            "Episode: 770, Total Reward: 50, Total Reward: -50\n",
            "Episode: 771, Total Reward: 50, Total Reward: -50\n",
            "Episode: 772, Total Reward: 14, Total Reward: -14\n",
            "Episode: 773, Total Reward: 14, Total Reward: -14\n",
            "Episode: 774, Total Reward: 14, Total Reward: -14\n",
            "Episode: 775, Total Reward: 50, Total Reward: -50\n",
            "Episode: 776, Total Reward: 14, Total Reward: -14\n",
            "Episode: 777, Total Reward: 14, Total Reward: -14\n",
            "Episode: 778, Total Reward: 50, Total Reward: -50\n",
            "Episode: 779, Total Reward: 14, Total Reward: -14\n",
            "Episode: 780, Total Reward: 50, Total Reward: -50\n",
            "Episode: 781, Total Reward: 50, Total Reward: -50\n",
            "Episode: 782, Total Reward: 14, Total Reward: -14\n",
            "Episode: 783, Total Reward: 50, Total Reward: -50\n",
            "Episode: 784, Total Reward: 50, Total Reward: -50\n",
            "Episode: 785, Total Reward: 14, Total Reward: -14\n",
            "Episode: 786, Total Reward: 14, Total Reward: -14\n",
            "Episode: 787, Total Reward: 50, Total Reward: -50\n",
            "Episode: 788, Total Reward: 50, Total Reward: -50\n",
            "Episode: 789, Total Reward: 50, Total Reward: -50\n",
            "Episode: 790, Total Reward: 14, Total Reward: -14\n",
            "Episode: 791, Total Reward: 14, Total Reward: -14\n",
            "Episode: 792, Total Reward: 14, Total Reward: -14\n",
            "Episode: 793, Total Reward: 50, Total Reward: -50\n",
            "Episode: 794, Total Reward: 50, Total Reward: -50\n",
            "Episode: 795, Total Reward: 50, Total Reward: -50\n",
            "Episode: 796, Total Reward: 14, Total Reward: -14\n",
            "Episode: 797, Total Reward: 50, Total Reward: -50\n",
            "Episode: 798, Total Reward: 14, Total Reward: -14\n",
            "Episode: 799, Total Reward: 14, Total Reward: -14\n",
            "Episode: 800, Total Reward: 14, Total Reward: -14\n",
            "Episode: 801, Total Reward: 50, Total Reward: -50\n",
            "Episode: 802, Total Reward: 14, Total Reward: -14\n",
            "Episode: 803, Total Reward: 50, Total Reward: -50\n",
            "Episode: 804, Total Reward: 14, Total Reward: -14\n",
            "Episode: 805, Total Reward: 14, Total Reward: -14\n",
            "Episode: 806, Total Reward: 14, Total Reward: -14\n",
            "Episode: 807, Total Reward: 14, Total Reward: -14\n",
            "Episode: 808, Total Reward: 16, Total Reward: -16\n",
            "Episode: 809, Total Reward: 50, Total Reward: -50\n",
            "Episode: 810, Total Reward: 14, Total Reward: -14\n",
            "Episode: 811, Total Reward: 14, Total Reward: -14\n",
            "Episode: 812, Total Reward: 16, Total Reward: -16\n",
            "Episode: 813, Total Reward: 14, Total Reward: -14\n",
            "Episode: 814, Total Reward: 14, Total Reward: -14\n",
            "Episode: 815, Total Reward: 14, Total Reward: -14\n",
            "Episode: 816, Total Reward: 50, Total Reward: -50\n",
            "Episode: 817, Total Reward: 14, Total Reward: -14\n",
            "Episode: 818, Total Reward: 50, Total Reward: -50\n",
            "Episode: 819, Total Reward: 14, Total Reward: -14\n",
            "Episode: 820, Total Reward: 14, Total Reward: -14\n",
            "Episode: 821, Total Reward: 14, Total Reward: -14\n",
            "Episode: 822, Total Reward: 14, Total Reward: -14\n",
            "Episode: 823, Total Reward: 20, Total Reward: -20\n",
            "Episode: 824, Total Reward: 50, Total Reward: -50\n",
            "Episode: 825, Total Reward: 14, Total Reward: -14\n",
            "Episode: 826, Total Reward: 14, Total Reward: -14\n",
            "Episode: 827, Total Reward: 14, Total Reward: -14\n",
            "Episode: 828, Total Reward: 14, Total Reward: -14\n",
            "Episode: 829, Total Reward: 14, Total Reward: -14\n",
            "Episode: 830, Total Reward: 16, Total Reward: -16\n",
            "Episode: 831, Total Reward: 14, Total Reward: -14\n",
            "Episode: 832, Total Reward: 14, Total Reward: -14\n",
            "Episode: 833, Total Reward: 14, Total Reward: -14\n",
            "Episode: 834, Total Reward: 14, Total Reward: -14\n",
            "Episode: 835, Total Reward: 14, Total Reward: -14\n",
            "Episode: 836, Total Reward: 50, Total Reward: -50\n",
            "Episode: 837, Total Reward: 50, Total Reward: -50\n",
            "Episode: 838, Total Reward: 14, Total Reward: -14\n",
            "Episode: 839, Total Reward: 14, Total Reward: -14\n",
            "Episode: 840, Total Reward: 14, Total Reward: -14\n",
            "Episode: 841, Total Reward: 50, Total Reward: -50\n",
            "Episode: 842, Total Reward: 50, Total Reward: -50\n",
            "Episode: 843, Total Reward: 14, Total Reward: -14\n",
            "Episode: 844, Total Reward: 14, Total Reward: -14\n",
            "Episode: 845, Total Reward: 50, Total Reward: -50\n",
            "Episode: 846, Total Reward: 50, Total Reward: -50\n",
            "Episode: 847, Total Reward: 14, Total Reward: -14\n",
            "Episode: 848, Total Reward: 14, Total Reward: -14\n",
            "Episode: 849, Total Reward: 50, Total Reward: -50\n",
            "Episode: 850, Total Reward: 14, Total Reward: -14\n",
            "Episode: 851, Total Reward: 14, Total Reward: -14\n",
            "Episode: 852, Total Reward: 14, Total Reward: -14\n",
            "Episode: 853, Total Reward: 14, Total Reward: -14\n",
            "Episode: 854, Total Reward: 14, Total Reward: -14\n",
            "Episode: 855, Total Reward: 14, Total Reward: -14\n",
            "Episode: 856, Total Reward: 14, Total Reward: -14\n",
            "Episode: 857, Total Reward: 14, Total Reward: -14\n",
            "Episode: 858, Total Reward: 14, Total Reward: -14\n",
            "Episode: 859, Total Reward: 14, Total Reward: -14\n",
            "Episode: 860, Total Reward: 14, Total Reward: -14\n",
            "Episode: 861, Total Reward: 14, Total Reward: -14\n",
            "Episode: 862, Total Reward: 14, Total Reward: -14\n",
            "Episode: 863, Total Reward: 14, Total Reward: -14\n",
            "Episode: 864, Total Reward: 14, Total Reward: -14\n",
            "Episode: 865, Total Reward: 14, Total Reward: -14\n",
            "Episode: 866, Total Reward: 14, Total Reward: -14\n",
            "Episode: 867, Total Reward: 14, Total Reward: -14\n",
            "Episode: 868, Total Reward: 14, Total Reward: -14\n",
            "Episode: 869, Total Reward: 50, Total Reward: -50\n",
            "Episode: 870, Total Reward: 14, Total Reward: -14\n",
            "Episode: 871, Total Reward: 14, Total Reward: -14\n",
            "Episode: 872, Total Reward: 14, Total Reward: -14\n",
            "Episode: 873, Total Reward: 14, Total Reward: -14\n",
            "Episode: 874, Total Reward: 14, Total Reward: -14\n",
            "Episode: 875, Total Reward: 14, Total Reward: -14\n",
            "Episode: 876, Total Reward: 14, Total Reward: -14\n",
            "Episode: 877, Total Reward: 14, Total Reward: -14\n",
            "Episode: 878, Total Reward: 14, Total Reward: -14\n",
            "Episode: 879, Total Reward: 14, Total Reward: -14\n",
            "Episode: 880, Total Reward: 15, Total Reward: -15\n",
            "Episode: 881, Total Reward: 50, Total Reward: -50\n",
            "Episode: 882, Total Reward: 14, Total Reward: -14\n",
            "Episode: 883, Total Reward: 14, Total Reward: -14\n",
            "Episode: 884, Total Reward: 14, Total Reward: -14\n",
            "Episode: 885, Total Reward: 50, Total Reward: -50\n",
            "Episode: 886, Total Reward: 14, Total Reward: -14\n",
            "Episode: 887, Total Reward: 14, Total Reward: -14\n",
            "Episode: 888, Total Reward: 14, Total Reward: -14\n",
            "Episode: 889, Total Reward: 50, Total Reward: -50\n",
            "Episode: 890, Total Reward: 14, Total Reward: -14\n",
            "Episode: 891, Total Reward: 14, Total Reward: -14\n",
            "Episode: 892, Total Reward: 14, Total Reward: -14\n",
            "Episode: 893, Total Reward: 50, Total Reward: -50\n",
            "Episode: 894, Total Reward: 14, Total Reward: -14\n",
            "Episode: 895, Total Reward: 50, Total Reward: -50\n",
            "Episode: 896, Total Reward: 14, Total Reward: -14\n",
            "Episode: 897, Total Reward: 14, Total Reward: -14\n",
            "Episode: 898, Total Reward: 14, Total Reward: -14\n",
            "Episode: 899, Total Reward: 14, Total Reward: -14\n",
            "Episode: 900, Total Reward: 14, Total Reward: -14\n",
            "Episode: 901, Total Reward: 14, Total Reward: -14\n",
            "Episode: 902, Total Reward: 14, Total Reward: -14\n",
            "Episode: 903, Total Reward: 50, Total Reward: -50\n",
            "Episode: 904, Total Reward: 50, Total Reward: -50\n",
            "Episode: 905, Total Reward: 14, Total Reward: -14\n",
            "Episode: 906, Total Reward: 50, Total Reward: -50\n",
            "Episode: 907, Total Reward: 14, Total Reward: -14\n",
            "Episode: 908, Total Reward: 14, Total Reward: -14\n",
            "Episode: 909, Total Reward: 14, Total Reward: -14\n",
            "Episode: 910, Total Reward: 14, Total Reward: -14\n",
            "Episode: 911, Total Reward: 14, Total Reward: -14\n",
            "Episode: 912, Total Reward: 14, Total Reward: -14\n",
            "Episode: 913, Total Reward: 14, Total Reward: -14\n",
            "Episode: 914, Total Reward: 14, Total Reward: -14\n",
            "Episode: 915, Total Reward: 50, Total Reward: -50\n",
            "Episode: 916, Total Reward: 14, Total Reward: -14\n",
            "Episode: 917, Total Reward: 50, Total Reward: -50\n",
            "Episode: 918, Total Reward: 14, Total Reward: -14\n",
            "Episode: 919, Total Reward: 14, Total Reward: -14\n",
            "Episode: 920, Total Reward: 14, Total Reward: -14\n",
            "Episode: 921, Total Reward: 50, Total Reward: -50\n",
            "Episode: 922, Total Reward: 14, Total Reward: -14\n",
            "Episode: 923, Total Reward: 14, Total Reward: -14\n",
            "Episode: 924, Total Reward: 16, Total Reward: -16\n",
            "Episode: 925, Total Reward: 14, Total Reward: -14\n",
            "Episode: 926, Total Reward: 14, Total Reward: -14\n",
            "Episode: 927, Total Reward: 14, Total Reward: -14\n",
            "Episode: 928, Total Reward: 14, Total Reward: -14\n",
            "Episode: 929, Total Reward: 14, Total Reward: -14\n",
            "Episode: 930, Total Reward: 50, Total Reward: -50\n",
            "Episode: 931, Total Reward: 14, Total Reward: -14\n",
            "Episode: 932, Total Reward: 14, Total Reward: -14\n",
            "Episode: 933, Total Reward: 14, Total Reward: -14\n",
            "Episode: 934, Total Reward: 14, Total Reward: -14\n",
            "Episode: 935, Total Reward: 15, Total Reward: -15\n",
            "Episode: 936, Total Reward: 14, Total Reward: -14\n",
            "Episode: 937, Total Reward: 14, Total Reward: -14\n",
            "Episode: 938, Total Reward: 14, Total Reward: -14\n",
            "Episode: 939, Total Reward: 14, Total Reward: -14\n",
            "Episode: 940, Total Reward: 14, Total Reward: -14\n",
            "Episode: 941, Total Reward: 14, Total Reward: -14\n",
            "Episode: 942, Total Reward: 14, Total Reward: -14\n",
            "Episode: 943, Total Reward: 14, Total Reward: -14\n",
            "Episode: 944, Total Reward: 14, Total Reward: -14\n",
            "Episode: 945, Total Reward: 14, Total Reward: -14\n",
            "Episode: 946, Total Reward: 14, Total Reward: -14\n",
            "Episode: 947, Total Reward: 14, Total Reward: -14\n",
            "Episode: 948, Total Reward: 14, Total Reward: -14\n",
            "Episode: 949, Total Reward: 14, Total Reward: -14\n",
            "Episode: 950, Total Reward: 14, Total Reward: -14\n",
            "Episode: 951, Total Reward: 14, Total Reward: -14\n",
            "Episode: 952, Total Reward: 14, Total Reward: -14\n",
            "Episode: 953, Total Reward: 14, Total Reward: -14\n",
            "Episode: 954, Total Reward: 14, Total Reward: -14\n",
            "Episode: 955, Total Reward: 14, Total Reward: -14\n",
            "Episode: 956, Total Reward: 14, Total Reward: -14\n",
            "Episode: 957, Total Reward: 14, Total Reward: -14\n",
            "Episode: 958, Total Reward: 14, Total Reward: -14\n",
            "Episode: 959, Total Reward: 14, Total Reward: -14\n",
            "Episode: 960, Total Reward: 14, Total Reward: -14\n",
            "Episode: 961, Total Reward: 14, Total Reward: -14\n",
            "Episode: 962, Total Reward: 14, Total Reward: -14\n",
            "Episode: 963, Total Reward: 14, Total Reward: -14\n",
            "Episode: 964, Total Reward: 14, Total Reward: -14\n",
            "Episode: 965, Total Reward: 14, Total Reward: -14\n",
            "Episode: 966, Total Reward: 14, Total Reward: -14\n",
            "Episode: 967, Total Reward: 14, Total Reward: -14\n",
            "Episode: 968, Total Reward: 14, Total Reward: -14\n",
            "Episode: 969, Total Reward: 16, Total Reward: -16\n",
            "Episode: 970, Total Reward: 14, Total Reward: -14\n",
            "Episode: 971, Total Reward: 14, Total Reward: -14\n",
            "Episode: 972, Total Reward: 14, Total Reward: -14\n",
            "Episode: 973, Total Reward: 14, Total Reward: -14\n",
            "Episode: 974, Total Reward: 14, Total Reward: -14\n",
            "Episode: 975, Total Reward: 14, Total Reward: -14\n",
            "Episode: 976, Total Reward: 14, Total Reward: -14\n",
            "Episode: 977, Total Reward: 15, Total Reward: -15\n",
            "Episode: 978, Total Reward: 14, Total Reward: -14\n",
            "Episode: 979, Total Reward: 15, Total Reward: -15\n",
            "Episode: 980, Total Reward: 16, Total Reward: -16\n",
            "Episode: 981, Total Reward: 14, Total Reward: -14\n",
            "Episode: 982, Total Reward: 14, Total Reward: -14\n",
            "Episode: 983, Total Reward: 14, Total Reward: -14\n",
            "Episode: 984, Total Reward: 14, Total Reward: -14\n",
            "Episode: 985, Total Reward: 14, Total Reward: -14\n",
            "Episode: 986, Total Reward: 16, Total Reward: -16\n",
            "Episode: 987, Total Reward: 14, Total Reward: -14\n",
            "Episode: 988, Total Reward: 14, Total Reward: -14\n",
            "Episode: 989, Total Reward: 14, Total Reward: -14\n",
            "Episode: 990, Total Reward: 14, Total Reward: -14\n",
            "Episode: 991, Total Reward: 14, Total Reward: -14\n",
            "Episode: 992, Total Reward: 14, Total Reward: -14\n",
            "Episode: 993, Total Reward: 14, Total Reward: -14\n",
            "Episode: 994, Total Reward: 14, Total Reward: -14\n",
            "Episode: 995, Total Reward: 14, Total Reward: -14\n",
            "Episode: 996, Total Reward: 14, Total Reward: -14\n",
            "Episode: 997, Total Reward: 14, Total Reward: -14\n",
            "Episode: 998, Total Reward: 16, Total Reward: -16\n",
            "Episode: 999, Total Reward: 16, Total Reward: -16\n",
            "Episode: 1000, Total Reward: 14, Total Reward: -14\n"
          ]
        }
      ],
      "source": [
        "# Train the DQN agent\n",
        "episode_rewards = []  # List to store rewards for each episode\n",
        "first_episode_path = []  # List to store the path of the first episode\n",
        "last_episode_path = []  # List to store the path of the last episode\n",
        "\n",
        "max_steps_per_episode = 50  # Maximum number of steps per episode\n",
        "num_episodes = 1000  # Total number of episodes\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    obs = env.reset()  # Reset the environment at the start of each episode\n",
        "    total_rewards = 0  # Initialize total rewards for the episode\n",
        "    done = False  # Initialize the done flag\n",
        "    action_count = 0  # Initialize action count for the episode\n",
        "    episode_path = [tuple(obs)]  # Initialize the path for the episode\n",
        "\n",
        "    while not done and action_count < max_steps_per_episode:\n",
        "        action, _ = model.predict(obs, deterministic=False)  # Predict the next action using the DQN model\n",
        "        obs, reward, done, _ = env.step(action)  # Execute the action in the environment\n",
        "        total_rewards += reward  # Accumulate the reward\n",
        "        action_count += 1  # Increment the action count\n",
        "        episode_path.append(tuple(obs))  # Append the current position to the path\n",
        "    print(f\"Episode: {episode + 1}, Total Reward: {action_count}, Total Reward: {total_rewards}\")\n",
        "\n",
        "    # Store total rewards per episode\n",
        "    episode_rewards.append(total_rewards)\n",
        "\n",
        "    # Store the path of the first episode\n",
        "    if episode == 0:\n",
        "        first_episode_path = episode_path\n",
        "\n",
        "    # Store the path of the last episode\n",
        "    if episode == num_episodes - 1:\n",
        "        last_episode_path = episode_path\n",
        "\n",
        "    # Update the model after each episode\n",
        "    model.learn(total_timesteps=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhMWPshYNmTg"
      },
      "source": [
        "- episode_rewards: 각 에피소드에서 받은 총 보상을 저장하는 리스트입니다.\n",
        "- first_episode_path: 첫 번째 에피소드에서 에이전트가 이동한 경로를 저장하는 리스트입니다.\n",
        "- last_episode_path: 마지막 에피소드에서 에이전트가 이동한 경로를 저장하는 리스트입니다.\n",
        "- max_steps_per_episode = 50: 각 에피소드에서 최대 50 스텝까지만 수행하도록 설정합니다.\n",
        "- num_episodes = 1000: 총 1000개의 에피소드를 수행합니다.\n",
        "\n",
        "- obs = env.reset(): 환경을 초기화하고 초기 관측값을 가져옵니다.\n",
        "- while not done and action_count < max_steps_per_episode: 에피소드가 끝나지 않고 최대 스텝 수를 넘지 않을 때까지 반복합니다.\n",
        "- action, _ = model.predict(obs, deterministic=False): 현재 상태에서 모델을 사용하여 다음 행동을 예측합니다.\n",
        "- obs, reward, done, _ = env.step(action): 예측된 행동을 환경에 적용하여 새로운 상태, 보상, 종료 여부를 가져옵니다.\n",
        "- total_rewards += reward: 총 보상에 현재 보상을 추가합니다.\n",
        "- action_count += 1: 스텝 수를 증가시킵니다.\n",
        "- episode_path.append(tuple(obs)): 현재 상태를 경로에 추가합니다.\n",
        "- episode_rewards.append(total_rewards): 총 보상을 저장합니다.\n",
        "- if episode == 0: first_episode_path = episode_path: 첫 번째 에피소드의 경로를 저장합니다.\n",
        "- if episode == num_episodes - 1: last_episode_path = episode_path: 마지막 에피소드의 경로를 저장합니다.\n",
        "- model.learn(total_timesteps=200): 모델을 업데이트합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYnhZ_IvIrAD"
      },
      "source": [
        "# Step 5: Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "pyFqs7VbIpu3",
        "outputId": "1bbe6ef6-86cb-4bc1-98a5-c5fbfee7ac1d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAHHCAYAAAC/R1LgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACD/ElEQVR4nO2deXwURfr/P5NjJicJ5CAc4UaQG4MgCCgLcuhXvqyiPwU1QYRVceVUQX+grCIqige6qOuC6PIT5PBYV5QoqOACohIUORTkvkSucOaa+v0RM0nP9Mz0UdVdPfO8fUVmeqqfeqq6p+uZeuqpx8UYYyAIgiAIgogCYuxWgCAIgiAIwirI8CEIgiAIImogw4cgCIIgiKiBDB+CIAiCIKIGMnwIgiAIgogayPAhCIIgCCJqIMOHIAiCIIiogQwfgiAIgiCiBjJ8CIIgCIKIGsjwIYgI4YsvvoDL5cIXX3xhtypS4HK58Nhjj9mthrQUFBSgSZMmltZJ9yghA2T4EIQJXC6Xpj8tD/onn3wS77//vnCd33zzTYVucXFxaNCgAQoKCnDw4EHh9RP6eeyxx0LeX0eOHLFbRYJwDHF2K0AQTubtt99WvH/rrbdQWFgYcPzSSy8NK+vJJ5/E0KFDMWTIEJ4qBuVvf/sbmjZtiosXL2L9+vV48803sXbtWmzZsgUJCQmW6EDoY+7cuUhJSQk4np6erlvWP/7xD3i9Xg5aEYSzIMOHIExw2223Kd6vX78ehYWFAcdlZNCgQejSpQsA4K677kJmZiaefvppfPjhh7j55ptt1i48586dQ3Jyst1qcOP8+fNISkoKWWbo0KHIzMzkUl98fDwXOQThNMjVRRCCOXfuHCZOnIjc3Fx4PB60atUKzz77LBhjvjIulwvnzp3DggULfO6LgoICAMDevXtx7733olWrVkhMTERGRgZuuukm7Nmzh6uevXr1AgDs2rVLcXz79u0YOnQo6tSpg4SEBHTp0gUffvih7/NTp04hNjYWL730ku/Y77//jpiYGGRkZCjaec899yAnJ8f3fs2aNbjpppvQqFEjeDwe5ObmYvz48bhw4YJCh4KCAqSkpGDXrl249tprkZqaiuHDhwMASkpKMH78eGRlZSE1NRWDBw/GgQMHAtp35swZjBs3Dk2aNIHH40F2djauueYafP/99yH7pcrNtH37dtx8882oVasWMjIyMHbsWFy8eDGg/L/+9S/k5eUhMTERderUwS233IL9+/crylx99dVo164dvvvuO/Tu3RtJSUl4+OGHQ+qhhao1NIsXL8bDDz+MnJwcJCcnY/DgwQE6qK3xWbRoEfLy8pCamopatWqhffv2ePHFFxVlfv31V9x0002oU6cOkpKScMUVV+A///lPgC4HDhzAkCFDkJycjOzsbIwfPx4lJSWqem/YsAEDBw5EWloakpKScNVVV+Hrr7821xkEEQSa8SEIgTDGMHjwYKxevRojR45Ep06d8Omnn+KBBx7AwYMH8fzzzwOodJnddddd6Nq1K0aPHg0AaN68OQBg48aN+O9//4tbbrkFDRs2xJ49ezB37lxcffXV2Lp1a9hZAq1UGVK1a9f2Hfvpp59w5ZVXokGDBpg8eTKSk5Px7rvvYsiQIVi2bBn+/Oc/Iz09He3atcNXX32F+++/HwCwdu1auFwunDhxAlu3bkXbtm0BVBo6VQYWACxZsgTnz5/HPffcg4yMDHzzzTeYM2cODhw4gCVLlij0Ky8vx4ABA9CzZ088++yzvnbfdddd+Ne//oVhw4ahR48eWLVqFa677rqA9t19991YunQp7rvvPrRp0wbHjx/H2rVrsW3bNlx22WVh++fmm29GkyZNMHPmTKxfvx4vvfQSTp48ibfeestXZsaMGZg6dSpuvvlm3HXXXTh27BjmzJmD3r17Y9OmTQqX1PHjxzFo0CDccsstuO2221C3bt2wOpw4cSLgWFxcXICra8aMGXC5XHjooYfw22+/4YUXXkC/fv1QVFSExMREVdmFhYW49dZb0bdvXzz99NMAgG3btuHrr7/G2LFjAQBHjx5Fjx49cP78edx///3IyMjAggULMHjwYCxduhR//vOfAQAXLlxA3759sW/fPtx///2oX78+3n77baxatSqg3lWrVmHQoEHIy8vDo48+ipiYGMyfPx9/+tOfsGbNGnTt2jVsvxCELhhBENwYM2YMq/m1ev/99xkA9sQTTyjKDR06lLlcLrZz507fseTkZJafnx8g8/z58wHH1q1bxwCwt956y3ds9erVDABbvXp1SB3nz5/PALDPPvuMHTt2jO3fv58tXbqUZWVlMY/Hw/bv3+8r27dvX9a+fXt28eJF3zGv18t69OjBWrZsqWh33bp1fe8nTJjAevfuzbKzs9ncuXMZY4wdP36cuVwu9uKLL4Zs28yZM5nL5WJ79+71HcvPz2cA2OTJkxVli4qKGAB27733Ko4PGzaMAWCPPvqo71haWhobM2ZMyL5R49FHH2UA2ODBgxXH7733XgaAbd68mTHG2J49e1hsbCybMWOGotyPP/7I4uLiFMevuuoqBoC9+uqrunRQ+2vVqpWvXNU90KBBA1ZcXOw7/u677zIAir7Pz89njRs39r0fO3Ysq1WrFisvLw+qx7hx4xgAtmbNGt+xM2fOsKZNm7ImTZqwiooKxhhjL7zwAgPA3n33XV+5c+fOsRYtWijuUa/Xy1q2bMkGDBjAvF6vr+z58+dZ06ZN2TXXXKOpfwhCD+TqIgiBfPzxx4iNjfXNhFQxceJEMMawYsWKsDJq/kIvKyvD8ePH0aJFC6Snp4d104SiX79+yMrKQm5uLoYOHYrk5GR8+OGHaNiwIYDK2YVVq1bh5ptvxpkzZ/D777/j999/x/HjxzFgwAD88ssvviiwXr164ejRo9ixYweAypmd3r17o1evXlizZg2Aylkgxphixqdm286dO4fff/8dPXr0AGMMmzZtCtD5nnvuUbz/+OOPASCgf8eNGxdwbnp6OjZs2IBDhw7p7SoAwJgxYxTv//rXvyp0WL58ObxeL26++WZfX/3+++/IyclBy5YtsXr1asX5Ho8HI0aM0KXDsmXLUFhYqPibP39+QLk77rgDqampvvdDhw5FvXr1fLqqkZ6ejnPnzqGwsDBomY8//hhdu3ZFz549fcdSUlIwevRo7NmzB1u3bvWVq1evHoYOHeorl5SU5JvNrKKoqAi//PILhg0bhuPHj/v67Ny5c+jbty+++uorWoBNcIdcXQQhkL1796J+/fqKQQiojvLau3dvWBkXLlzAzJkzMX/+fBw8eFCxZub06dOGdXvllVdwySWX4PTp05g3bx6++uoreDwe3+c7d+4EYwxTp07F1KlTVWX89ttvaNCggc+YWbNmDRo2bIhNmzbhiSeeQFZWFp599lnfZ7Vq1ULHjh195+/btw/Tpk3Dhx9+iJMnTypk+7ctLi7OZ5RVsXfvXsTExPjcglW0atUqQNdnnnkG+fn5yM3NRV5eHq699lrccccdaNasWbiuAgC0bNlS8b558+aIiYnxuQh/+eUXMMYCylXhv5i4QYMGcLvdmuquonfv3poWN/vr4HK50KJFi5Drwu699168++67GDRoEBo0aID+/fvj5ptvxsCBA31l9u7di27dugWcW/N+bteuHfbu3YsWLVrA5XIpyvlfl19++QUAkJ+fH1Sv06dPK9yvBGEWMnwIQnL++te/Yv78+Rg3bhy6d++OtLQ0uFwu3HLLLaZ+DXft2tUX1TVkyBD07NkTw4YNw44dO5CSkuKTPWnSJAwYMEBVRosWLQAA9evXR9OmTfHVV1+hSZMmYIyhe/fuyMrKwtixY7F3716sWbMGPXr0QExM5URzRUUFrrnmGpw4cQIPPfQQWrdujeTkZBw8eBAFBQUBbfN4PL5zjXDzzTejV69eeO+997By5UrMmjULTz/9NJYvX45Bgwbpluc/qHu9XrhcLqxYsQKxsbEB5f3D0IOttbGL7OxsFBUV4dNPP8WKFSuwYsUKzJ8/H3fccQcWLFggpM6qazxr1ix06tRJtYxa+D5BmIEMH4IQSOPGjfHZZ5/hzJkzilmf7du3+z6vwn8grWLp0qXIz8/Hc8895zt28eJFnDp1ipuesbGxmDlzJvr06YOXX34ZkydP9s2ExMfHo1+/fmFl9OrVC1999RWaNm2KTp06ITU1FR07dkRaWho++eQTfP/995g+fbqv/I8//oiff/4ZCxYswB133OE7HsrV4k/jxo3h9Xqxa9cuxWxClcvNn3r16uHee+/Fvffei99++w2XXXYZZsyYocnw+eWXX9C0aVPf+507d8Lr9foio5o3bw7GGJo2bYpLLrlEcxtEUDWTUgVjDDt37kSHDh1Cnud2u3H99dfj+uuvh9frxb333ovXXnsNU6dORYsWLdC4cWPVvvW/nxs3bowtW7aAMaa4r/3PrZqpq1WrlqZ7jCB4QGt8CEIg1157LSoqKvDyyy8rjj///PNwuVyKATc5OVnVmImNjVW4twBgzpw5qKio4Krr1Vdfja5du+KFF17AxYsXkZ2djauvvhqvvfYaDh8+HFD+2LFjive9evXCnj17sHjxYp/rKyYmBj169MDs2bNRVlamWN9TNStSs22MsYDw6VBU9V/NUHoAeOGFFxTvKyoqAlxn2dnZqF+/ftAQa39eeeUVxfs5c+YodLjhhhsQGxuL6dOnB1wvxhiOHz+uqR4evPXWWzhz5ozv/dKlS3H48OGQBp6/fjExMT5DqaqPrr32WnzzzTdYt26dr9y5c+fw+uuvo0mTJmjTpo2v3KFDh7B06VJfufPnz+P1119X1JGXl4fmzZvj2WefxdmzZwN08r/HCIIHNONDEAK5/vrr0adPHzzyyCPYs2cPOnbsiJUrV+KDDz7AuHHjFGtT8vLy8Nlnn2H27Nk+11G3bt3wP//zP3j77beRlpaGNm3aYN26dfjss8+QkZHBXd8HHngAN910E958803cfffdeOWVV9CzZ0+0b98eo0aNQrNmzXD06FGsW7cOBw4cwObNm33nVhk1O3bswJNPPuk73rt3b6xYsQIejweXX36573jr1q3RvHlzTJo0CQcPHkStWrWwbNmygLU+oejUqRNuvfVW/P3vf8fp06fRo0cPfP7559i5c6ei3JkzZ9CwYUMMHToUHTt2REpKCj777DNs3LhRMZMWit27d2Pw4MEYOHAg1q1b5wuhr1qz1Lx5czzxxBOYMmUK9uzZgyFDhiA1NRW7d+/Ge++9h9GjR2PSpEma26bG0qVLVV0/11xzjSIcvk6dOujZsydGjBiBo0eP4oUXXkCLFi0watSooLLvuusunDhxAn/605/QsGFD7N27F3PmzEGnTp18a3gmT56Md955B4MGDcL999+POnXqYMGCBdi9ezeWLVvmc0WOGjUKL7/8Mu644w589913qFevHt5+++2ArRdiYmLwxhtvYNCgQWjbti1GjBiBBg0a4ODBg1i9ejVq1aqFf//736b6jCACsCGSjCAiFv9wdsYqw33Hjx/P6tevz+Lj41nLli3ZrFmzFOG7jDG2fft21rt3b5aYmMgA+ELbT548yUaMGMEyMzNZSkoKGzBgANu+fTtr3LixIvxdbzj7xo0bAz6rqKhgzZs3Z82bN/eFNe/atYvdcccdLCcnh8XHx7MGDRqw//mf/2FLly4NOD87O5sBYEePHvUdW7t2LQPAevXqFVB+69atrF+/fiwlJYVlZmayUaNGsc2bNzMAbP78+b5y+fn5LDk5WbU9Fy5cYPfffz/LyMhgycnJ7Prrr2f79+9XhLOXlJSwBx54gHXs2JGlpqay5ORk1rFjR/b3v/89ZF8xVh1KvnXrVjZ06FCWmprKateuze677z524cKFgPLLli1jPXv2ZMnJySw5OZm1bt2ajRkzhu3YscNX5qqrrmJt27YNW7e/DsH+qq551T3wzjvvsClTprDs7GyWmJjIrrvuOsX2AIwFhrMvXbqU9e/fn2VnZzO3280aNWrE/vKXv7DDhw8rztu1axcbOnQoS09PZwkJCaxr167so48+CtB57969bPDgwSwpKYllZmaysWPHsk8++UT1Ht20aRO74YYbWEZGBvN4PKxx48bs5ptvZp9//rnmPiIIrbgY85uTJQiCIHw89thjmD59Oo4dO8YtXYQovvjiC/Tp0wdLlixRhJITBFENrfEhCIIgCCJqIMOHIAiCIIiogQwfgiAIgiCiBlrjQxAEQRBE1EAzPgRBEARBRA1k+BAEQRAEETXQBoZ+eL1eHDp0CKmpqUFTCBAEQRAEIReMMZw5cwb169cPmdePDB8/Dh06hNzcXLvVIAiCIAjCAPv370fDhg2Dfk6Gjx9ViST379+PWrVq2awNQRAEQRBaKC4uRm5uriIhtBpk+PhR5d6qVasWGT4EQRAE4TDCLVOhxc0EQRAEQUQNZPgQBEEQBBE1kOFDEARBEETUQIYPQRAEQRBRAxk+BEEQBEFEDWT4EARBEAQRNZDhQxAEQRBE1ECGD0EQBEEQUQMZPgRBEARBRA1k+BAEQRAEETWQ4UMQBEEQRNRAhg9BEARBEFEDJSklTHGhtAKJ7ljf+4tlFXDHxiAmJnSSuGByKrwMZRVeJMTHKo6Ve71gDD7Z5RVeHCm+iFRPPNKS4lHhZTh8+gIAoH5aIs6VluP0hTKkJ7lRXuFFepIbF0orAACJ7lgwxnCxzKvQHQCKL5bBHRsDxqD47EJpBWJigLiYGJwvLYfL5UJJWQWS3HFIdMfC62U4cb4UmSke3zk121LzmH9bTp0vhZcBdZLdIfvlYlkFymq0pUq/Y2dKkJHsRmlFpdyqNqpdHzX57rgYlHu98MRVlvN6maqsKhhjOHa2BFkpHrhcLlwsq0BphRe1EuJ9ZS6WVcATFwMvA06eL0XyH/0USqeS8grExcSgtNyrqtOJEHKqdMpI9qDc64XXWy030V19L9W8B6rO878Pjp0pQWaKGxVeBi8DvIzByxhccCEu1oXS8sprGvvHPe4vs6otv58tRZ2kyusSG+OCJy4GZRVenDhXCndcDFI98XC5gNIKL1LccbhQVgEG4NT5UsTGuJCdmoDDpy+gbq0EnDpfhswUty/54u9nS5DkjkVCXCwOnb6A7NQEVHgZTl0oRWpCPFwAyioq++/k+VJ4GfOVOX2hDOV/dFDtJDdcLiAxPhbFF8pR7vUiyR0H7x8Xv6zCi7Ml5aiXlohjZ0qQkhCHuJhqHQAo2uKOjUFJeaXsmBigrIKBMYbii+XISHbjbEk5EuJjcep8KdKT3IiPdcHrrfzeJXvicLGssi/jY2JQUlEBT2wszpSUKe6T9CQ3Ssu9qJPsxpHTF306MQYwMBRfKEdWqgeHT19AepIbXsZ83+mYGOBiqRe1EuNw6PRFZPzxnSv3Mpy9WI60xHhcKKvA+dJy1E9LxPFzpZU6sso+On2hDDEuoHayG0eLLyLG5UJKQhyKL5QhMT4WyZ44nDhXipxaCThxvhSpCXG4WOrFhbIKX5+rkeKJw8Uyr6JMqiceMTHAhbLK70WMCygp9yLJHYsYlwsnz5cCgO9euVhW4TtW1U8uVH7/0pPcYKzy2ld9VnUNTtU4Rw9Vz7Wqa1Z1PU9fKENpuVdVdnxsDErKvIiPc6FuaoLucYIXZPgQhnn8o63459rdWHZPd+Q1roMT50px2eOF6Na0Dhb/pbtmOc8X/owXP/8FC+7siqdXbMfO387ilq65eGvdXiwefQUmL/8Ru38/BwC4rFE6lt3TA4Nf/hpbDxcjNsaFd0ZdgdmFO7D+1xMAgLq1PDh5vvLLV8WEay7B7MKfAQAPX9savxw9iyXfHcCn43qjVU4qAGD7kWIMnvM1Sisqz3vmxg64+fJcrPjxMO5Z+D2Aygc7XFDIfvW2PLz77X6s2v4bHr2+DUZc2RQAcP2ctfjltzMomtYfyZ7Kr9o1s7/Er3+0pXOjdIzvdwkK5n8DLwP+PvwyXNu+nk/uzI+34bWvfsXi0Vdg4pLNOHDygqItd17ZFNm1PHhqxfaAPp07/DIkxMdixJsbMfGaS/DXvi0Dymw/UoyBL6wBACTEx6BoWn8kxMfi5tfW4du9J33l5o+4HH1aZfveP/bhT1iwbi/u6tkU4665BL2fWY2zF8ux/N4eaNcgDcfPliDvic/Qo3kGGAPW/XocAPDysM5I8cShYP5GjOvXEuP6XeKTebGsAp3+thIXy6r71R0Xg6Jp1yDJHYe//Os7FG49CgB46ob2aFk3BTfOXYeRPZti6v+0wd8+2or5X+8JaGOVnNJyL9yxMb5rO6pXUzxyXRtMXLIZy78/iMLxvdGybipmr9yBl1btxE15DfHfXcdx8NQFVZmtc1LxybjeWPrdAUxashkA8PrteejfNgel5V70mfUFDp2+GHBekjsW5/8wlHz6qdxTatxwWQPMvrkT/rl2Nx7/aGvIsnpJdsfiYrkXFV6mqXyqJw5nSsoDjsfGuDTLMEuD9MSg1ycUsTEu1E314NDpi0jxxOGsSjsI8Wx/fCASYoL/KBMJuboIw/xz7W4AwKxPdwAAPv3pCABgw+4TuuS8+PkvAIBHP9iCrYeLUVrhxVvr9gIAnlyx3Wf0AMD3+06h3Muw9XAxgMoZlG2Hi7F5/2lfmaPFJQGDSJXRAwBPfrwdS747AAB47atdvuPbD5/xDYwA8OCyHwAA4xYX+Y6VVngDZI9bvAmrtv8GAFj+/UHf8a2Hi1FWwRRGxK812rJp3ylsOXQaVePEloPVbajU7VcAwFOfbPcZPTXbMu/r3Xj7j37yZ8K7mzF5eaX+z9Voe03mflHd9otlXl/9NfUFgKnvb1G8X/BHnW+s3Y19x8/jxLlSlFZ4sePIGQDAx1sq74P/7jruM3oAYNyiIvzfP2S98NkvCplbDp5WGD1ApSFQtP8UAPiMHgCYvPxHn7FXdQ8GM3qq5ABQXNt/rKk8r+p6/WNNZV+//se/S747EHJQ3f5HW6uMniq9gMqZEDWjB0CA0VOlVzijp6au727cH7ZsOOL8fmmfK63QZbBUGT3+ckQYPTEuwBMXA0+ccrgyYvQAlTpWXR8rjZ74WJevHTX/anZh3B8zg1onQvz7H6g09PXiVtEr1F9sjXpjwyjrjq08x1/X+Fj7zA+a8SEIk9QcsBms+bXrq48Zr8/EqT7KKsIP2E7CqtkKM/C4x566sYPCaDNCakIcJlxzCab/m+/skz+D2tXDK8MvAwB0nfEZfjtTIrQ+Ucy59TIMbJcTcHz84iK8t6nSqJ39fzphcMf6mLL8B7zzTXgDV+06Fk27BtfM/kqXYfjt/+2ncFWHY+4Xu/D0J5U/PqYMao031uzGkWJ1Y3/1A1ejQXoilny7Hw8srfwxFuMKbzCJhGZ8CMfhP2AzxrgMBlYbLYCyLfIPuYHUnEVxov4ioH4QR7T0bZLb2jmJpHh9Lqf42GqjJdwMU1XZmuWMzErxhAwfgiAMU6bBRUPIh32/tQktVK0JDAev6xin0+1U03CJj42BK4Qi7j9k13Rt2enmAsjwIYiohcev59IIc3VFC6EGKs0yYJEB5VJ96TiC9blL5XVyiEjMcDJdcHG5vqHQY8TEqxg+bjJ8tDFjxgz06NEDSUlJSE9PVy3jcrkC/hYtWmStooRw/F1SDHzWq/CQ4eT6jVBWUa20mfVGkQT1gziipWeTNM742IXS8AmzuDkuJqCc3TM+cvduDUpLS3HTTTehe/fu+Oc//xm03Pz58zFw4EDf+2BGEkEQ5om0xc3RgugZAcIcKR7jMz5WUNPV5R9t509VNJfCPRZn7w3oGMNn+vTpAIA333wzZLn09HTk5ASunCcIQgmPmQkyfJyJi4PTqGpWXTRqriAnElT3mq68P15rXdysdh1dLvEGkVvH7E3VPeImV5c4xowZg8zMTHTt2hXz5s0L+3AvKSlBcXGx4o+Qm8CoLj5T4Gq3yoGT5zlIDlVnDVeRAyfyS8opqssfkZ6uB5ZsdkTIvSiipeUpjnJ1aTMjaHGzIP72t7/h3XffRWFhIW688Ubce++9mDNnTshzZs6cibS0NN9fbm6uRdoSTmDCYnN7nUQ6NONjLUu+O4Bdx86FLxgGcnXJTUK8tqGZx3W86pIs3ef4GzF3X9Xc7/NAxRSLm6M5nH3y5MmqC5Jr/m3fHrgdfzCmTp2KK6+8Ep07d8ZDDz2EBx98ELNmzQp5zpQpU3D69Gnf3/795ndFJSIHo7vDOgEev54pnD16scKlUllPdSVOtteCuQVruquqX5trqRZXZm6dRPzn/p547fY83fKVRowLd3RvjEE1NmdUm9Fxx9HiZgDAxIkTUVBQELJMs2bNDMvv1q0bHn/8cZSUlMDj8aiW8Xg8QT8jnAHz/Y+DHItRuEWCKCBzkFDNqK6o8UOYJC7GhfIodleZgXqNHy640LZ+mqFz/Y0Yl8uFy5vUwYo/0tVUGjbK9Cx6IsFEY6vhk5WVhaws/dNsWikqKkLt2rXJsCEIQdA+PvqJj41BuTcwZ5eVWLEomRCPmeto5hZwx1ZHnVW5rZI9gccU5yh2brYnOWkVcq+gqsG+fftw4sQJ7Nu3DxUVFSgqKgIAtGjRAikpKfj3v/+No0eP4oorrkBCQgIKCwvx5JNPYtKkSfYqThCyQrm6bMEdF4MLZTYbPpxkWGE+RXpUl0slqkurUaJWzAoXZLyK26rmbtNqUVuKGR8b83QBDjJ8pk2bhgULFvjed+7cGQCwevVqXH311YiPj8crr7yC8ePHgzGGFi1aYPbs2Rg1apRdKhM8UPHzCMvVZYNPSYOnS+rp/bIK+xK0ykq428ju9Q1Ohu4wOVDbhTmpxm7T4RY32z3j6BjD58033wy5h8/AgQMVGxcSBBEaHoZKKS1u1o3b5vUNAEV1yY7Wy2PmOpq5BdwqoekJNdxXarm/lLNA9pqw9NODIAjDKBY3E5qwO5QX4LeBoRUWlMIVJLw2cejJ1aVZptoGhlyubmjiFBsYqmRfV3V1yXP17P8GEkQI1IZVtZkKLrm6zIsILT+M287rZfj4x8PYf+J88EKSUXNxs1E1tx8pxpc/H+Okkf2Em0mTwfBxKvJ+E6KLmqZV1exOuH16lLNA5OoiCALA+0WH8Mba3QCAPU9dJ7w+HvYUj318Br6wxrwiDiIuxn7Dh1xdfElNiMOZi+Xc5GldA2PK1WXi5MT4GhFcfxg0GSlu37FOueko2n8q6PlZqe6gn1kBGT4EIQm/ny2xWwXd0C9w/cTaHNEC2BvVFR/rQmJ8LIo1GgoyR3UtHn0Fvt51HGUVXsz9YlfIskFdXSpRXVoJHtWlLmjBnV2RP+8bfZWokJYUj2du7ICYGBcS/1jU3LB2Ep4Y0g6pCXHod2ldJHticW37eorz/j78Mvx31+/4S+/mamItgwwfQmrUZiVE5eoSPYqrtkVDpU4xLpyip2gk9kzaQrOsZBw/W4rTF8oAAJP6t8KC/+7RbPjUxI6uvaxROr7fd0r1s8ub1EG3ZhmYvXKHtUqFQc2t3rFhGtrVr8WtjpsvD0zvdNsVjX2vHxjQOuDza9vXCzCG7MD+OVeCIGyBy7ooGuR1I4ObyUodXDA3q2E3doReC4nqclrHC4QMH4IgCAuRY/jhEdVFubp8qmnoiGCxVi6TcV1qR4LmBSPjBwAZPoTkqEZwqZThsfmg6A34VCPUNFTplFkVp+gpGuoGcdjRt040FezYjNVJkOFDEFEKl92uaZjXjwS/ui11dbn85zTsb78e7LhcmlNW6NDNWb0uFjJ8CMfDbXFzMPkCZRPRhwwDEB8dtG2Vp7p/la5a7CVUG6tcR5p0tCyqK4S+NV5H86wQGT6E1KhHdYn5wop+DpgdAKSE1Xzp+NZwIZoHFC1IMOGlD6fpS4SFDB+CCIPdzz1RBgWNz/Ygw8Bv5SJXl8sVUJ8EXWA5WtrsWyutsYf0XEf/otG80JkMH8LxMIgdxMk+IHgiw3DDZQNDjVFdpmc6be4wTQaLqR2UTZyr8ZhaXdE8M0mGDyE16pv+CapLkNyQ8h3+8KmpvcObwg3qhshC5sXNhDHI8CGIMNj9DBJlUNAAbQ8yuBjsjOoC7P9O2YGW66733jAT1SXDfWgXZPgQprHazaSWsoJHBcHkmG1e1ZSy0dkrq2ZSTLeTixZWCBVLuOsVKcON1lxd5qO67O2xoBsPusKX0VqD4TNVTg1lz9TUk1xdBCEp0fzldAJ0fQi9OG2mwWHqEhogw4cwjcgHg/CHpAbxZjWQ9UHvb7NIqaWUSplDhtvBcleXf0SRddVLg56oLu0y9UR1uUK+jybI8CGkRnVGwd/VxckfIj5lhcqUv5aUFQJ04YVCN5r9+YPQ/WC364YX1uXqEl+HkfpdGsqYka/tZDV5IX1dBMjwISIAGm8JRxGVg4+8iUbDYYehqjllhR6ZhjSJTMjwIYiohSxGO5BhAOIxmLs0pqwwX4/6a7vRmzVexMyR3izsds+eyQIZPoTjcOpOxupeu/CVyryAuKZq8mppLRJfLsdjS3Z2BxoLMj8zZIAMH8Lx0JeccBJOHEjNYiYRZzSiOWWFHpnU7z7I8CGIKIXsRXuQYnEzBxVcWjfy4VFP1Wvx1RlCi1GhaT8g3a6uYMeD1KVPfMRChg8hDVo2K1Q7xmsAt8MOcLrxQSkrAqFuEIc9ri51c0HmmWaZdZMBMnwIx0NfccJJRKPLQdYFyloIpq9X4INHe1SXjn18HNfz4iDDhyCiFDIY7UEGw4dLdnZOcsLXI38ovLY8XEGOK9rHJ1eX3mivaIMMH0IatEY9+R/hNqvLcXpYNT+R5Lm6jFCzndE2vR6svVHWDZZCUV3aiLbvol7I8CEcj+gdlwmCJ9HoclAu4HVW++3QVsQGhlF42wWFDB/C8Xz842G7VXAkPH4VksmpHxnGfR7GR2UOLgs2MHRAVJcWgumu6EL9ybqCyKSorlCQ4UNIg9ZcVv4D9s9Hz3Kqnx+a3XaacnU5w7xwhpb8CHbtnHK9nIh/z8bHWmF42ZCywqSJQq6u0JDhQxBRCj0aCatQLODlaEc8OKA1P2FBkHmWRF9UF1EFGT4EQRiHrCfdyLDGhZcGlkR1hXB1JXvi0LB2ogVahEbTJdWSq4tTvZSrKzRk+BDSoDXqSdRYy3N2WPNmjJpydZnXxwqcoicvgjU3XD/Q2GMc/661YiC3w1gwWye5ukJDhg9BRCn0bCSsQuQCZfGGibymKuXqMgYZPgQRBpntA7t1i7SFvHqMQaO/qmUYgHjo4HJZ1RYHbGCoQbPgubpcqq811atzo8Jo3EpBDUcYPnv27MHIkSPRtGlTJCYmonnz5nj00UdRWlqqKPfDDz+gV69eSEhIQG5uLp555hmbNCaMoCWCK1g5PvUL3sBQtaAGWaa1sQan6CkacnWJI8DVZUGdtri6TJ5Prq7QxNmtgBa2b98Or9eL1157DS1atMCWLVswatQonDt3Ds8++ywAoLi4GP3790e/fv3w6quv4scff8Sdd96J9PR0jB492uYWEE5G5oHKjG70aAxEhtkYK7D6l7+iNs6dLLot3BaCa8rgzl9mtewoubk14AjDZ+DAgRg4cKDvfbNmzbBjxw7MnTvXZ/gsXLgQpaWlmDdvHtxuN9q2bYuioiLMnj2bDB/CFGQgBCeaf1gabboMUV080Orq0jz7GaIeO9FksNikoxlDKZpnhRzh6lLj9OnTqFOnju/9unXr0Lt3b7jdbt+xAQMGYMeOHTh58mRQOSUlJSguLlb8EfKgHtUl5gvLdQNDtWMmBwDZieYHaU3C3Z+RYfYYh2f7LYnqsuGK2W3sRTqONHx27tyJOXPm4C9/+Yvv2JEjR1C3bl1Fuar3R44cCSpr5syZSEtL8/3l5uaKUZpwLHY/g0QZFFxSVpCtoxsZBjUrdVBLbeE044cHmrb60dkWXa4ul/97h3ScAGw1fCZPnuz7UgT72759u+KcgwcPYuDAgbjpppswatQo0zpMmTIFp0+f9v3t37/ftEwisqCxnVDDuNEXGQOO64//wmHa1RVGB9GIWJujV76ImqN5htbWNT4TJ05EQUFByDLNmjXzvT506BD69OmDHj164PXXX1eUy8nJwdGjRxXHqt7n5OQEle/xeODxeHRqTliGhTsYct3AUOtmjFH88IlU6JKGxmkTDfbo67BOchi2Gj5ZWVnIysrSVPbgwYPo06cP8vLyMH/+fMTEKCerunfvjkceeQRlZWWIj48HABQWFqJVq1aoXbs2d90J/shqBNj9CJKzVyqJtH18rECGgd9KFdRcKlxdXRxliUSLa0nvDBa5uozhiDU+Bw8exNVXX41GjRrh2WefxbFjx3DkyBHF2p1hw4bB7XZj5MiR+Omnn7B48WK8+OKLmDBhgo2aE5EADe2EGkaNvkgZbqSI6pJkcbMZG0JNvlZ5FNVlDEeEsxcWFmLnzp3YuXMnGjZsqPis6uKlpaVh5cqVGDNmDPLy8pCZmYlp06ZRKLvDsTRXF1dZ2jZejKRnTyS1hRCH4/aTcZi6RHgcYfgUFBSEXQsEAB06dMCaNWvEK0QIQdZx0/bnnsRrmsjY0Y8UHgbLo7rEVe8Ul42I/YD0tN3f4HRKv4nAEa4ugrATGtsJNYwafY6b8QiC1laYj+oKXpMlKSs0lTGuiZr9IapdNfWMZlcXGT6E1Dg3V5faQU2HHAVTvHZ6a/gQxeOJJpw20RDNMyORChk+hDTIOmDY/dgTt6ZJ0g6PcGQYR62cdRLu6uIoSyTaZo74y/SVpaguH2T4EKbhZbCoLgjWWM5EpTyKhD7/jw7SuuA52PmiMd9OLmr4CRUgUzBhU1ZEyHijtiOzGiKjuqwYvEXsuBxOvoh2MUZRXVWQ4UNITaR/N50+6xLp10cEkbLGxyhOa32kGKpENWT4EKYR+WAQ/tARvB09IO+Usr/RIqWWUiplEgnaxOOWdEHrbEhgagtdLpoQ57n0CrORYH3uCtVAwzLV9wZyhSkTLZDhQ5iGm6tL4z43XGcZasgKJtdIdUwhlwWVr8nVZaB+I5h2dXHRwgqhfAh6v0issx2YdXXxOM8MdpgHZuvUEhRCri6CkBSt634Iu6CroZfo/Z1didMmGqJ5ZiRSIcOHMI1QV5foYYJcXT6k1FJKpcwhw/3ARQONKSvMRnXV7K8AV5dLjltE2zVVL6Nsn85cXRpkVh/zq0uC+9AuyPAhpEFrBJeoKVqeC401R6hpaIuVM9Jm+jbaZs6D3S9R1g2WEjWuLpOVRrMbSwtk+BCOI5K+005vSiRdC6uIxt/ZyvW7fHtA+MxFNF6wCIcMH4IIg8xjuxndnB5KLwI9hpzhlBUSDKQ8jIXKqC5rG6Pm6pIBM3v9uDSU0S0zyAeSdJftkOFDSIPd2ct51qXeFoMbGFpooOjtA0pZEQi5GcRhj6vLenPBbJ10D4aGDB/CcVj9nRb52DNrLDj9F5xsD2grZhCcfs2MoJiB4NwBwrf6isYLFuGQ4UMQYZBraFZiytUlc8NsQpery2AdMkTTcNnAUCVaSwShbCZZdsHWFN2m4YOql2b7NairS47ush0yfAiJ0OYKEuVSEbQvYuhjmnJ1mdVGO3qrqjljQ4ZUJdQN4oiWqC6zyDaTKhtk+BCOI7JcXeZw4kO5JrI9n6PF1WW1DiayMoSWq3EvIbN18JETXpDe2UCawTEGGT4EEQbJxmYF5qK6CH/0RXUZDesydppsaM3VZb6e4BsYyoIZvUS464K7umTtQWshw4eQBq3jiKgBm29Ul0a3nWyuLp2VWZHfy2nT9g5T11FES1SXWZz2nbEaMnwIx2H1l1rsY8/GqC56NgZgjavL/oHU8h/+NRfwcq5cdH9yc3UJqEuGe8mJkOFDEGEg+4BQw3hUF1c1bEPr+hqz2dnt7i+t+ch4yhfRZsrOXg0ZPoQQeH2pzD40ddXFNVeXNvmyPXv0R3XVfK2/MbLlKuOD4xS2FOfZfc7TmAgNGT6ENGgdLiIqqsvGMZJ2WrYHOYZR67RwuQIdMrxqt2ovIR6Y2uvHhMxgZaN5oTMZPgQRBjIPghPNfePkXF08cGmM6zLt6tJRVgTaXF0m5KvK499qcnVVQ4YPIQRe3yl1MYI2MBScq0tNbZlmXRjM9YGRczVFdekXayvh+iHaF6TyHNOtCacnIo04uxUgiCq0/gKJNleXqF9mUfyDL+qxctZJbfYiGo0JLQYvr+zsWsqSq4sgiKCQfRCcaJ4uN3pjRMp4Q1FdNcpwli+iyeTqqoYMH0IIvL5S6rm6HIBGvWVqC2PmXG9GzrRzxksU4bS1eyC3G66urijZd4ngCxk+hDRQVFeQMqLqFiSXkB8rh3KRUV1V8p2ANjVdOsrqM8rI1VUNGT4EEQYyEMQh0+JuvRjXPXIGHC0tMe/qsre/NFVvZgNDi+4HcnVVQ4YPIQRuGxiqbfonLKqL5waGGnN1STTwM8Ysj+rSJFeMWGGEjeqKHLvHEDwHeiuMhii/XBEJGT6ENGhOUhpBri4to7owg4KD4Cj+0ehorJxFUdtkkKuri6Msu6nqJ60GHUV1GYMMH4IIA43t4nCy4WR4A0O+athGpUETDRsYaghDNyXfxMk6IFdXNWT4EEIQGtUlbAZErCx1t508mNVFiNuOOc84CjegRPEPbQDOi+oiIg8yfAhp0LyBocXmgtioLg1JOkWtaeIiw2FWiQTIEB5tfVSXska+UV0chQlEz35A2qO6jNdPri7J2bNnD0aOHImmTZsiMTERzZs3x6OPPorS0lJFmaqp15p/69evt1Hz6IDXrIzWfW64zgAw1ZdhddAh1mfcGN2TyKoZD2ZydkWEngzyGldG75dIGW+0Zeoy7+oKVYklKStsyNUlAnJ1VeOIlBXbt2+H1+vFa6+9hhYtWmDLli0YNWoUzp07h2effVZR9rPPPkPbtm197zMyMqxWl+BIpH83I719BOF0ZJihI/jiCMNn4MCBGDhwoO99s2bNsGPHDsydOzfA8MnIyEBOTo7VKkY1In/BCv91bMXOrwIbYcZu4mF0RZrhpqc9Rn8xyzCM8rgltaasMBvVVdPwUM9krkOYIDTl4QpWpkYDqp4VWpsUrO2q+dHI1eXDEa4uNU6fPo06deoEHB88eDCys7PRs2dPfPjhhzZoFn1w259Go8tMmKuL6+JmFvDaaMoKq2wL9sd/xs83cE6Yk8y63+wg/D4+0TXgmHZ1hTjPkpQVDrxcqn1Ori4fjpjx8Wfnzp2YM2eOYrYnJSUFzz33HK688krExMRg2bJlGDJkCN5//30MHjw4qKySkhKUlJT43hcXFwvVndCLdRsY2oHZh48Dn8lS48RBzmk4zfBzlraEFmyd8Zk8ebLqguSaf9u3b1ecc/DgQQwcOBA33XQTRo0a5TuemZmJCRMmoFu3brj88svx1FNP4bbbbsOsWbNC6jBz5kykpaX5/nJzc4W0NZIR+xwT/NiJZlcXj/pNCpHNiNXl6hKnhnB4rFvR4+oKrF9fPaHOk2ENjpkF0C6115qbpF6QXF2hsXXGZ+LEiSgoKAhZplmzZr7Xhw4dQp8+fdCjRw+8/vrrYeV369YNhYWFIctMmTIFEyZM8L0vLi4m40cnIqO6VGd8hEV18UxZUeO1L6rL2JS/ZTPSZt1KAhSVzTDSQjido228qbzvlY3m5eqy4peLE68XubpCY6vhk5WVhaysLE1lDx48iD59+iAvLw/z589HTEz4yaqioiLUq1cvZBmPxwOPx6NJB8J69ISAu1zOWw9idly3+5nsRMMkFE4c5IxgZzud1sW8ZkZEhMVHy/3KG0es8Tl48CCuvvpqNG7cGM8++yyOHTvm+6wqgmvBggVwu93o3LkzAGD58uWYN28e3njjDVt0jiZkiepywYAd4fAHhymzQwIrUQIVFOiL6jJWhx2uGRE/ClwI3JhQve7A1Bb6orpCnyfD4M87ZYXZe4RcXaFxhOFTWFiInTt3YufOnWjYsKHis5rTdY8//jj27t2LuLg4tG7dGosXL8bQoUOtVjfq4PVA1TI9G6yc8UpD12VYrMrGiMaj36yxDpjJmkRo6cSornAdEW3jjeOjusRXwR1ydYXGEYZPQUFB2LVA+fn5yM/Pt0YhwjL0hIC7HOjrMquu3Q9lh3V3WCJ1IDU0GyoIxxl+nPTVs9ePiJQVRDWO3ceHkAehri5BZc2dRPBClsHYCEbXN9kx8Itwa7i05qzQXix4PSHkit/jVIs7T6x8gi9k+BBC4Ob+EihbS13GZan4utTK2Tjy+1dd6VYysYFhlOXqCoaztLUepw30jpuhIsJChg8hDdoHDGuHFpHPPS2DuszuJIlVkxY7FpX612ilCmZTVmiogKc0YeiJ6tKeskJ722lxczVk+BARg6jvMQ3u4nD0AkvDUV3WI+K7odXNZHZxc6gZIlGDd7hNEwPKm7iqVtkftLi5GjJ8CCHwck9ojfTiVBlHWTVfVm1gKLZKvQQ8CE1eNREuKcaY1DNeajhNX6txwkSDIoTeAfoS+iDDh5AGrQOG1eOKWFcXnzLG6uYg2XTKiijEjsXNfpVauc5GtKvLKXaJvjQd2kobTf2hp45IhAwfImJwIfABy4OoHJyJsBi9L2xZ3CuiSpWNCdUw7eoKE9Ulgprt0nS9TEV1WQO5uqohw4cQAkV11XjNqo5Z6LYzgJHNAmu2SVxUl7NwWhSa1ThhnoFcXZENGT6ENGgdMKz+pSL2uaclqktMe2UwumTQwWps2cfHRh1crsDUFlxdXQ4xTMREdRmvn1xdBBEJuMQYKVE4NhMaMJ6ry3qcHdUV4jNBnak/qotPXSIhV1c1ZPgQQuD1ldKTnV1EXTxk+VxdkkV1+cN8/9NxjrZ9Go1jclNFO3CYupbjhIkGxQyVExQmdEGGDyENmqO6LB5YIjaqS4YBWgYdLMYeV5efqylCNjB0CZrlFYOIXF20gaERyPAhIgYXxHyZo3BsJjRgOFeXDUO1EFeXS5tc09nZbV4UpcnVZUJHqwwQcnVVQ4YPIQReXyr1h6agxb4c5Sqinfz+VZST6OHDmP4tDNWi13hidlNFO3CavtYj/0yD3VFdTstn5jTI8CGkQfOAEW2uLgeE7xvFeWaNeaSI6rJ6A8OA+jnJhra9hGRAT1QXT5nByjql30RAhg8RMYjy90ff0KwdmWasrMZZUV38a62M6rJgA0MdZXmhjOrSsjZHfsjVVQ0ZPoQQuEV1CZQdIFdYVBdT/CuqTrMwmNPHyOxNuPqMbKpoN9E8oGjBCRMNNY0dW/R1QB85mTgthSZMmKBZ4OzZsw0rQ0Q5kkZ1iUSbqyt4KVNJRSOpIzmhp0sM954NI6ndGxj6V8itegdFdWlbJC2wfnJ1+dBk+GzatEnx/vvvv0d5eTlatWoFAPj5558RGxuLvLw8/hoShEYq/f00mFsJ9bZ+bBluhER1acuNJzJXlyh0b2BoJlcXbWBoOZoMn9WrV/tez549G6mpqViwYAFq164NADh58iRGjBiBXr16idGScBzcvlOqGxiKiuoSI0tkVBfXZyYz2QcGTg53CrM4WRePQSh6hxNtOGGewfaoLid0koPRvcbnueeew8yZM31GDwDUrl0bTzzxBJ577jmuyhHRhfZcXYIVMcGWg8X44cAprjJDNVfirnAkulxdBm9EOaK6LKxbaFSXqD2KBCwG1yBTb7QdRXUZQ7fhU1xcjGPHjgUcP3bsGM6cOcNFKcJZqD7/jfz615ieIpjoyqgunV9mldQSZhn88teKQdF0ygqLrBsGpnswF52yonLCx2HmXRh17dnAUFRUV3jMR3XZO0BrMljMuLosah+5uqrRbfj8+c9/xogRI7B8+XIcOHAABw4cwLJlyzBy5EjccMMNInQkohj1SKjI+cKaHdSd/ptNtmtpxY9gGVwndv7Y52mEiZq1ECFVz1ohrfVH86yNGTSt8anJq6++ikmTJmHYsGEoKyurFBIXh5EjR2LWrFncFSTkR2wkguAvtsOfG+aiuripETHoc3WJ0yOSEJmrq1KWCF8Xf5F2Q66uanQZPhUVFfj2228xY8YMzJo1C7t27QIANG/eHMnJyUIUJORH3UVlYE8XVdnap8ldvv8Zq5RrygqFqODLm7UMnlaNr8zA4mZlygr+mjLGHGdghLuPImVbGJdGX5cTo7r01m/G+KKoLuvRZfjExsaif//+2LZtG5o2bYoOHTqI0osgAAR5QEbQ99Xss8fpv9lku5SR6+qyc3mzuJpFtUIR1cWpFm0GVFVZbXU6/ftvF7rX+LRr1w6//vqrCF0IhyLU1aWnrEr0CNcKJMSUq4uH2RFhvxqtaI4dLgYxa1Zc2tI5mIzqcgV5bUiY1jp1XiNzi5v5o6Y/ubqq0W34PPHEE5g0aRI++ugjHD58GMXFxYo/IvowHK0UcI62KXGuUT5qG+5wJmRUl4ZKrZqSNpsewtg1D/M55JsVCkeE2YKmMevq4nGeGWTYfkAvWtLjkKtLB9deey0AYPDgwQqLkTEGl8uFiooKftoRUQ8vo0pWot3VJRuR+iNYrqguOWUFrYObHP5h8ZF6v4pGt+FTcxdnggCszS8TsqzO8r6TCMNEkA2qG8PZ2SMmZ4X2tphxq4Q7VdjCbY3186yLsAbdhs9VV10lQg/CwWjdeJCbbEG5JbiKVZHLaZ9HbgRMfcOcG9HImeHqq3S/Ocu8Cqeu3Rvy2Q3XGR8L+tKeDSctrzKq0G34VHH+/Hns27cPpaWliuMU6UUYRet6HmcNg2GQKJydiFxE7qNDaEObMaNzUTVdSUPoNnyOHTuGESNGYMWKFaqf0xqf6ENsVJc+X5fuB4Eg3R2XZsEgDpuM4YrRa+zExbLBZGreYdhMPWE6TEiuLp3yTbnyyHixHN1RXePGjcOpU6ewYcMGJCYm4pNPPsGCBQvQsmVLfPjhhyJ0JCRH3R3FZ0RUnfHhOdoqcnWJ2cDQbFSXKPxrZkZ2MFScz0EJlQJOs63C6RvtwxzPgT5SXUJkDIlF94zPqlWr8MEHH6BLly6IiYlB48aNcc0116BWrVqYOXMmrrvuOhF6ElGA1vU8ThgIteqoaedmJzSYkBraw0UfdvUPRXVZg+4Zn3PnziE7OxsAULt2bV+m9vbt2+P777/nqx3hCCiqKxCnLcg1ivPmY/jhpKguETMILpeOHYZlcYcbka8lO7sp+SZOJgyh2/Bp1aoVduzYAQDo2LEjXnvtNRw8eBCvvvoq6tWrx13BKgYPHoxGjRohISEB9erVw+23345Dhw4pyvzwww/o1asXEhISkJubi2eeeUaYPkQ1ERPVJWxfRKb4N1g5q/E3zsxuFsgrP5vic5ObKtpBOKM36t0YXKO6xGNLbrUov0VEo9vwGTt2LA4fPgwAePTRR7FixQo0atQIL730Ep588knuClbRp08fvPvuu9ixYweWLVuGXbt2YejQob7Pi4uL0b9/fzRu3BjfffcdZs2ahcceewyvv/66MJ0I8agPIfKPhFoHay0zQzLPqjjNKIlWKKpLH6L3BuJVL11HY+he43Pbbbf5Xufl5WHv3r3Yvn07GjVqhMzMTK7K1WT8+PG+140bN8bkyZMxZMgQlJWVIT4+HgsXLkRpaSnmzZsHt9uNtm3boqioCLNnz8bo0aOF6UXIlqtL50hMTw5bcbLhZFT1yInqcmnfwFBg9nIZNhikGRpnoXvGxz9BaVJSEi677DKhRo8/J06cwMKFC9GjRw/Ex8cDANatW4fevXvD7Xb7yg0YMAA7duzAyZMng8oqKSmhfGOcUItkMi0zTD084Su2WlroqC77CIzqsj5XV1iZkHvGSw1naWs9XG0EB6WsIORBt+HTokULNGrUCLfffjv++c9/YufOnSL0UuWhhx5CcnIyMjIysG/fPnzwwQe+z44cOYK6desqyle9P3LkSFCZM2fORFpamu8vNzdXjPIEN6weWIw8+LS7uvjJ0g0HuU6esbELW7Kz+9VppQoulyvgS8SzeiH7+NiU8V33vaEn+IMi+3zoNnz279+PmTNnIjExEc888wwuueQSNGzYEMOHD8cbb7yhS9bkyZMr3RMh/rZv3+4r/8ADD2DTpk1YuXIlYmNjcccdd5iOnpkyZQpOnz7t+9u/f78peYR96Iky0YOQ7WkIAM6bzamJ0WdPpAw3KvaMKmazs4dyk1mSskJTVJcZV541dwRlZ69G9xqfBg0aYPjw4Rg+fDgA4JdffsGMGTOwcOFCLFq0CHfddZdmWRMnTkRBQUHIMs2aNfO9zszMRGZmJi655BJceumlyM3Nxfr169G9e3fk5OTg6NGjinOr3ufk5ASV7/F44PF4NOtMBKfmIMZtQLMwOzvXqC61XF2SuboCYdIZIsxsqJkNRPF4ogmnzTTYsibLWV3kOHQbPufPn8fatWvxxRdf4IsvvsCmTZvQunVr3Hfffbj66qt1ycrKykJWVpZeFQAAXq8XQOUaHQDo3r07HnnkEd9iZwAoLCxEq1atULt2bUN1EHIi2+CshmYdNUV1GfvMjFwrZciEHqPFUYubA1xN1ilRGXTgXz9H+cISclgvUX9Ul/YzyNVVjW7DJz09HbVr18bw4cMxefJk9OrVS7hhsWHDBmzcuBE9e/ZE7dq1sWvXLkydOhXNmzdH9+7dAQDDhg3D9OnTMXLkSDz00EPYsmULXnzxRTz//PNCdSPkQU/uINHQr35tRGM/Rcq+MJWu5fDlTLu6QtRhxdityWAxoYfaqSKMOXJ1VaN7jc+1116LiooKLFq0CIsWLcKSJUvw888/i9DNR1JSEpYvX46+ffuiVatWGDlyJDp06IAvv/zS56ZKS0vDypUrsXv3buTl5WHixImYNm0ahbJbiOJ7xM3TpZari49sLXUZlqWSA0zEBoY8H49GorpqPjx9r3nmPLN4fo/PQBq9A4oWZPlxEgrFfRDFMyORiu4Zn/fffx9A5S7JX375JVauXImpU6ciLi4OV199NRYuXMhbR7Rv3x6rVq0KW65Dhw5Ys2YN9/oJuXDCsKJ1uNZkI4QoY8rVFcW/+IKhy9VlOGWFDVFdfuaG1VFdIjdQdIpdImI/IF0pfcjV5UO34VNF+/btUV5ejtLSUly8eBGffvopFi9eLMTwIQgtVIbN0mDuJKLxasmwxoeLTI3OZfNRXcY+44WItTmKc1VOFnG9yNVVjW5X1+zZszF48GBkZGSgW7dueOedd3DJJZdg2bJlvoSlRHQiwNMVJFeXmC+sqKiukMdM9hRXVxf4LJbmmkrN4lxdPAYcGccTmX7bO2GiQYSnS8u6Hb1rexzQlVKie8bnnXfewVVXXYXRo0ejV69eSEtLE6EXQUQFmjYwDGFK2B3VZRbZfnXqUye69/HRSmVUl5+rzSZdohlydVWj2/DZuHGjCD0IwjQU1UU4Agl2buYjU4aoLgs2MNQyU8M9qos/5OqqRrerCwDWrFmD2267Dd27d8fBgwcBAG+//TbWrl3LVTnCYSgifDiJDF2NtCg2cwy1ONlkW/hHdelTSC0/G1eXIazdt4mLq8u8CO4E7KNj4y8EK/cQMkrN/uHm6hKyuFn+vpQR3YbPsmXLMGDAACQmJmLTpk2+DQRPnz6NJ598kruCBOGPIzYw1Lp/oUlZ5qK6TJzMCRl0qIklUV3GTnMsIqO6RKWpiUTI1VWNbsPniSeewKuvvop//OMfvh2SAeDKK6/E999/z1U5gtCDTA9BycZzQiJsuUUF1Wl3ri4r0FY731xdQnIOkqvLh27DZ8eOHejdu3fA8bS0NJw6dYqHToRDUUZ18flSqT40heXq4rmBYWDeMisj1IzAwPRvYKiSn413P1JUl3kCXV32GROS/DYJSU1ji19UF38c0JVSotvwycnJwc6dOwOOr127VpFQlCBEIePA4g/XkO5Qn5moyAkuQ6uxJFdXlA1XQl1dHGVFOuTqqka34TNq1CiMHTsWGzZsgMvlwqFDh7Bw4UJMmjQJ99xzjwgdCclRW9QqdHFz0NKBD1g9FfDef8b/tdH0G1bNChnRRb2dfHGaeRbOoLRnA0MRUV0uTXJFRnWJQrG4WXRUl9oGhsbFBYVcXdXoDmefPHkyvF4v+vbti/Pnz6N3797weDyYNGkS/vrXv4rQkYhiZHcPBUdjygrHDeuRjSxJL0XXaedvfcfNM/CcngpXRGDKCqIa3YaPy+XCI488ggceeAA7d+7E2bNn0aZNG6SkpODChQtITEwUoSchMSK/fC6X9tkjl8vAM0qQ7lbZZk43nBxhwwbBeK4uvnrYVaceN5Mo957WvYRM1cGpjJ5zyaARi6F9fADA7XajTZs26Nq1K+Lj4zF79mw0bdqUp26EQ6h2ddVc6MpXtuIYJ9n+wnjvP+MvV2saC6sImPpWOablHP/XvFN/iEtRIn/qk4jEAYO6MmWFAxQmdKHZ8CkpKcGUKVPQpUsX9OjRw5elff78+WjatCmef/55jB8/XpSeBFGNAwYWrvv4mNJEbpw+Y2UEOxY325mdnahE21ohvbm66EIaQbOra9q0aXjttdfQr18//Pe//8VNN92EESNGYP369Zg9ezZuuukmxMbGitSVkBRZHqIuGPh1JonuRqHZBfswbLRFiqtLh5vJ3OLfUCeLH/o1ubo4r26mWSaxaDZ8lixZgrfeeguDBw/Gli1b0KFDB5SXl2Pz5s10kaIctWgekQuQuc4SKKK6RO3jE1CVajmrUYvyCNcH/p8q2ikgqsvI3kKaZYuSK0ZsxOCEWYqaYxoNb5GHZlfXgQMHkJeXBwBo164dPB4Pxo8fT0YPYTlOmOXQqqLZlBVOJ5LbFgwZnphOMD604KThR1OuLt1CjWhCaDZ8Kioq4Ha7fe/j4uKQkpIiRCnCWcjy8InOqC57sbt+OzEe1RUh2dlhjQEVrgbR/SnEYOF0LmEMza4uxhgKCgrg8XgAABcvXsTdd9+N5ORkRbnly5fz1ZCQHpEbGKrWJ0gY36iumi6gEKkcJLMcwkd1hdxHWkMZvvqYqU9U1ztjnyn7kOWHklYiZXaMqEaz4ZOfn694f9ttt3FXhiC04IhxxWRUV7QMntHRSiVSbGAYIWO5k5qhbZG0TplO6gCJ0Gz4zJ8/X6QehIOR5cvnggsul86hVJSrS4zYwHrsthzsrt9Gon4DQ5UcXKHKikJI8k+X+mst5c3URViD4Q0MCaIKUTmagtYnLKqLo1gVufJFdQXm3QqnTUhHl4CmVG5gGL6MMdlRbLXZCI3zhN2Q4UM4DieMV1qNs+CuLu01ORnZjA992dmN6S7DjE+kGB9OiirWoqve9UTOab1ckOFDmEaWZ0+lHtG1gaHdyGW2OAMZdm7mI1NMWb2I2pyx+rXg7Oz0ELIcMnwI06jm6or2qC6VJFZ6cnVZYVAEbEYIFnYGJtTHoXKSadVB7XO9myqaqZvHIBqu/TLM+Ng51vKcpbGiGRYmZzewuJmMJiOQ4UM4D8ncI2po38DQXFvMdIUDutFydBlt1H8E4Ug0RXV9+OGHmgUOHjzYsDKEM5HlR0dlri4DJwlAtrUrooiWdjodUZFPVuTq0iBdgER9KSvMuKtkeX5GE5oMnyFDhmgS5nK5UFFRYUYfIkIQmXXbCZKVnq7gcV1BXV02GBTaorr8IsFUPtNz7bVsmGhuU0V9dXNxdYVpvy3uCb867VxXwrP5VnQlr74SsQM02UzG0GT4eL1e0XoQhGYcMcmgdQNDk20xczoP49QR10IHkdYeGXC5Ak0HngM2zZhoIyCyL4o7jtb4EBGD2gPWLkTOeBHORoadm3lJ1fKNU5uRk/3boXcDQzMdbNX94H8ZotlNrXnn5pqcO3cOX375Jfbt24fS0lLFZ/fffz8XxQjnYVmuLkHCRUV1iYh2EoGRzQKVOcnUy4SRGPZTM5sqhj4v8Mxoieqy88c+19keCZKkapfD39cVxZM2ptBt+GzatAnXXnstzp8/j3PnzqFOnTr4/fffkZSUhOzsbDJ8COE44XeK1sHfrBFn5nwehl6k/WikqC7+VKa28F9jxFE+R1kiZdoNubqq0e3qGj9+PK6//nqcPHkSiYmJWL9+Pfbu3Yu8vDw8++yzInQkCM1E8XeZcAj2bGAoQKbGqC4nurpqImJRsl75PCBXVzW6DZ+ioiJMnDgRMTExiI2NRUlJCXJzc/HMM8/g4YcfFqEj4RAUbg+R9QgSztXVpfJaNVeXBbpohdX4v+ZzNOYk03K+eoHwD2jjuboCj0Wuq0vcjItenBbVxa23BITFy7Oq0VnoNnzi4+MRE1N5WnZ2Nvbt2wcASEtLw/79+/lqRxAqOOF3ilfjaGxvVBfhjyW5ugyd5VycGNUViW4gcnVVo3uNT+fOnbFx40a0bNkSV111FaZNm4bff/8db7/9Ntq1aydCR4LQhMsVOb+AoiUqLDpaqcSWGR9BMsnVVVXGxAaGFj2zyNVVje4ZnyeffBL16tUDAMyYMQO1a9fGPffcg2PHjuG1117jrmAVgwcPRqNGjZCQkIB69erh9ttvx6FDh3yf79mzx7eIrubf+vXrhelEKFFGMgncZlBUVBfPDQw1RnXJZOBo2yww8Bz/z/i6DMP3EM8+5LOBoXzI9WvfWT9OuEV1aTKg+MskAtE949OlSxff6+zsbHzyySdcFQpGnz598PDDD6NevXo4ePAgJk2ahKFDh+K///2votxnn32Gtm3b+t5nZGRYoh9BKLHI1WXzKCvjIG8Vxvs++kYrkQO06Mzz0ewSilR0z/j86U9/wqlTpwKOFxcX409/+hMPnVQZP348rrjiCjRu3Bg9evTA5MmTsX79epSVlSnKZWRkICcnx/cXHx8vTCdCLvTkDhKN3QYNT7cfrz5Vuz5G28l7sOMhT6sEe1xdAowDg/eY0xY3C96/MBrtYNvRbfh88cUXAZsWAsDFixexZs0aLkqF48SJE1i4cCF69OgRYNgMHjwY2dnZ6Nmzp6bkqiUlJSguLlb8EcZQi2QSUo/jorr+iJeycK1DZd4tfdFQwTYLVEZusbCfBatXywaJWs9R2zhRL6HaZUieT66E82D+ri57tIhqhBtQhGY0u7p++OEH3+utW7fiyJEjvvcVFRX45JNP0KBBA77a+fHQQw/h5Zdfxvnz53HFFVfgo48+8n2WkpKC5557DldeeSViYmKwbNkyDBkyBO+//37IjPEzZ87E9OnThepN8EWmdTHB0L6Bodl67O0LJ1wLPVixu3Z0Dm7iWi1k1ic6L1LUoNnw6dSpk2/BsJpLKzExEXPmzNFV+eTJk/H000+HLLNt2za0bt0aAPDAAw9g5MiR2Lt3L6ZPn4477rgDH330EVwuFzIzMzFhwgTfeZdffjkOHTqEWbNmhTR8pkyZojivuLgYubm5utoR7agtahWbskL9eGXmIL1TCqovTaOayiGcApYTOOWjf3FzoDieIeFG9hbiVbdxuaGxY82IGNvAZcjoCHbKvIIuuPPNb3XrIBoRi5IJe9Fs+OzevRuMMTRr1gzffPMNsrKyfJ+53W5kZ2cjNjZWV+UTJ05EQUFByDLNmjXzvc7MzERmZiYuueQSXHrppcjNzcX69evRvXt31XO7deuGwsLCkPI9Hg88Ho8uvQl7ccIcg1UzPnbjcPWjBplydTkBMTtdh5eq1yim62gMzYZP48aNAQBer5db5VlZWQoDSg9VepSUlAQtU1RU5Au9J8Th6C+fIN2tMgjI8OCLvl2naQNDrWhL+2CsZxz9/CFswVB29l27duGFF17Atm3bAABt2rTB2LFj0bx5c67KVbFhwwZs3LgRPXv2RO3atbFr1y5MnToVzZs39832LFiwAG63G507dwYALF++HPPmzcMbb7whRCeimmpXjjXLm4O6ulwG3AiC3HOK/W1CyLczZYVapnVtrid1GUZU1uJa0+t+41W3YWRMWSEsqsvIeUHOMuI2syKqS6DRRtiD7qiuTz/9FG3atME333yDDh06oEOHDtiwYQPatm0b1q1klKSkJCxfvhx9+/ZFq1atMHLkSHTo0AFffvmlwk31+OOPIy8vD926dcMHH3yAxYsXY8SIEUJ0IuwjkhbU2r042TxO19967MnV5feeBuqQiFiHJSKqi66jMXTP+EyePBnjx4/HU089FXD8oYcewjXXXMNNuSrat2+PVatWhSyTn5+P/Px87nUT4ZFlqtmQGpLo7o9m487hdodsdp8eQ9R4VJcNi5uF5LPSLldUKLcsaWpkeQYS2tA947Nt2zaMHDky4Pidd96JrVu3clGKcBayRHUZE1bzpZiUFVVv1ORLFNOl0a0UYh+fqnZyvEAiU1aI83RJZs1JRjAbQdYdkmUwrAi+6DZ8srKyUFRUFHC8qKgI2dnZPHQiCMejdfCzMzs7D+yunzf6FjcbrESGNT40lodETFQXnzJmyhOVaHZ1/e1vf8OkSZMwatQojB49Gr/++it69OgBAPj666/x9NNPK/bDIaIHWb58lftM6RyNREV1md6YkI8eshONsyN2fF2EuLoq87Nzq9+QqwsGV1hzRgIVCB1oNnymT5+Ou+++G1OnTkVqaiqee+45TJkyBQBQv359PPbYY7j//vuFKUrIi55oJT71CcstwU+sWrSTWj/ZaOEEuK2gwdUVQkao6DWjiI3qErSBoQNsOTt/rAQN6pLVeuCVq06DIL1uNVm7THY0Gz5VDwmXy4Xx48dj/PjxOHPmDAAgNTVVjHYEoYITBhatKpptit1RYQ64FLrQ150G9/GRdoQnqqBLFNnoiury/8KSwUMA8jwkXDCgizBXlzmTINIMimA4wYjljSRfF/PoiuriP9sBGN9LiDtSKEFoRZfhc8kll4T9tXLixAlTChHOozqqKzA/lZD6BAkTFCwWOleXjQO/alSX3ozuKpF8vPtR76aKemSLwAm2nJ3jdDADR5YfUIBSR15qaWqf7sXNEnWag9Bl+EyfPh1paWmidCEITThilsCibXjs7gq7XW12YrTpNFYRhL3oMnxuueUWClknApDmQW5kMzNZdPcjmg2KSMeeDQzF7ESsVaq4qC45Zj1orx9noXkfHxluLkJOVDcwFJmri2v4VY2XnDfe85erGv1ma1SX33uw8LMYAecEvua7wWR4nYz2oaiud4LNaufzPGjVEg0xNXW0sq907+MjRo2IR7PhQ79ACVlwwq2oVcdgxTRHhdndFxG0X5HeZ5zh/QtptOIG9SVhBM2uLq/XK1IPwsHI8vCRKqpLjFjpiJZ28sSWDQxFyHS5NM+GiMxwLsPjR5ZnIKEN3SkrCMIftWieqI/qUpGrmqvLzqiuEHm3gp4D/3NUXHo8c55p0MtwbaJcXQ4wB2Ucp2U1HqyM6tL9u03SPpMdMnwI5yGTfyQImnN1BSmn3VVmvC9k6EWZjAS9t5WTcnVFLtSZhH7I8CFMI8uvDpfLwGS5pLm6nEKUNJMr9kR1CZAJHVFdmjYwNKiHBM8fCVQgdECGD2EItc0K1TazE1K3IGHCUoCp9A+vOnnrrDcvlqpLj3euLp2bKmqWLchsc4LRK2euLnnMh5q68FJLk/GnszKZ+sxJkOFDOA4nDCxalQxayooNECXoR5mupV5VjEa60ljFD+pLwghk+BCmkeXhY2gzM0l0dyoyrdFxCpET1aXju69lYa9BJWX4CtPMi7Mgw4cwhKrbpuamfU7ZwFAhV4wspnKMW6W8NwvUmReLqTSUr0r6N1XULtvYeWHlihHLFTt3Gg6aq8tiPULhUrzmo5mo3asJ/ZDhQzgOmdwjwfB6TUZ1mYwKcwo8tOfVB9ZtYBh9w5um/JwGukWWlBWEsyDDh4gYXC76xVSFy0jeshCygqFn8NflGgkni/OV5iGPZ94q3ojL1aVfbnBV5Pn2KlNW6CtPyA8ZPoQh1AY8R0Z11ZTLNVdXoFw1+cGq1LyPT4jzdbutgshTXlf/sK6aL0OEr1XpFBAVpk/HgLqCVxcWpZfO/LX3SQijkAxjZKQM1E6a7RE160XohwwfwnE4wdVlNleX5npMnm8WGVxtvDTQH9XFqeIoQIuB4uTFzYSzIMOHiBhckMfXZfeYaJWrS68ccnXZ5OoSIdPlMrYuJ9g+PubU4YrC1aWlvDBNCBGQ4UMYQtVtY1XdTojq0tg/wVw9WnUJer6mjf+Y33sNLsxQn4WJ6lJ1dYXUUP2cyvNqurqMXTnFJpwcXV3hJdEwyQsn9aSmWS9Htci5kOFDOA+7p1M44nxXl/0Y1SFkaL6m82VovTPQtr6FfF2ENZDhQ0QMFNVVDbm6rEdqV5egXF3GznPCPj76fF20KNlZkOFDGEJ9Mz7zkTaG65ZMsGqEW5iIKeVxjfv48IzqYixs5FmoqKxQOcl8OgWcH1LFykgzlXZwierya5fuGZwgbrtw+sgwRkbKQO2kdlBUlzyQ4UM4Dp5h56LwmtRR/hZWIoOeRl1OdrmqnBSCzQuRe+HIOPtHyA0ZPoQhwi1qFZqyIoRo3YOK2j40HFDrCz3yrbDt1BYah11s7FeCqfQf134UmLJCee35Ec4wt2eYdvm946CFQddl8KguA5shCupNZVQXn7iuKLR3pYUMH8JxyDDLEA6zhkv0LJzluHGgyfP0L24mCMKJkOFDmEaWXzIul4Hff5LoTkQPkbO42aV5hlXk+hYZFm7L8gwktEGGD2EItcWllqWs4OqXECM3XP9oECAcNbeVGbeSkXZqKatlrx8jiLpfw4mSYU2KnQM1z6qtaAe/qEZyh8kCGT6E43CCG8i8q4vQil2Lmx2wxp4gCBXI8CFMI8uvFBfk0YUgghE5KSv07F3ksFxdOpWhx46zcJzhU1JSgk6dOsHlcqGoqEjx2Q8//IBevXohISEBubm5eOaZZ+xRMgpQj+qqmQLAmrpNyxIllwX2BW8XkFnU00fo2/tH7TOeHr1K91sYnXi4urhGonETJQw7B2qeUV1WYKVWsvZBpOE4w+fBBx9E/fr1A44XFxejf//+aNy4Mb777jvMmjULjz32GF5//XUbtCSiHYrqsg77orroGhGEE4mzWwE9rFixAitXrsSyZcuwYsUKxWcLFy5EaWkp5s2bB7fbjbZt26KoqAizZ8/G6NGjbdI4OpDFvcQzTYNZnDAkOkHHSCRyorq0y438qC45njuENhwz43P06FGMGjUKb7/9NpKSkgI+X7duHXr37g232+07NmDAAOzYsQMnT560UtWoQz2qS+QGhnw3yPO9FuTuCJe1PNz5wlBJPxE2hYTFUV1Mw1XhkZ2da7qSMJ/LYJzbO1AHydXFcTNEnljZV2Q/WYMjDB/GGAoKCnD33XejS5cuqmWOHDmCunXrKo5VvT9y5EhQ2SUlJSguLlb8EXLjhJkK0xFDnPSIBnis8QH0XzOj9dLgRhD2YqvhM3ny5MpN50L8bd++HXPmzMGZM2cwZcoU7jrMnDkTaWlpvr/c3FzudUQ6sjzIeWb/jgZojYo92BPVxb9SXa5lLbm6jKSscLmEtU1Xee4aECKxdY3PxIkTUVBQELJMs2bNsGrVKqxbtw4ej0fxWZcuXTB8+HAsWLAAOTk5OHr0qOLzqvc5OTlB5U+ZMgUTJkzwvS8uLibjRwPhc3VZU7dpWaLkquWw0lGBFYlY1arQm6tL7Wx9OcnCR2xZEuHGU5YDwrqkjOqS1HqwUi9JuyDisNXwycrKQlZWVthyL730Ep544gnf+0OHDmHAgAFYvHgxunXrBgDo3r07HnnkEZSVlSE+Ph4AUFhYiFatWqF27dpBZXs8ngCDipAbJ8xUmNXQAWOnNHBzdVmUq0uGNT5EaOgKRTaOiOpq1KiR4n1KSgoAoHnz5mjYsCEAYNiwYZg+fTpGjhyJhx56CFu2bMGLL76I559/3nJ9ow1ZfqlVDiiSWAwOsFxk0FAGHawmcqK6XDqiujRsYGhIBzmePzLoQGjHEYaPFtLS0rBy5UqMGTMGeXl5yMzMxLRp0yiUXRCRkqtLUGCPqgtNtqguf5eMFreSlqgu/hFS4TZVNJ+ywgnuKZ7ImKtLVuPB0g0MZe2ECMORhk+TJk1UH1QdOnTAmjVrbNCIsBInDFFOGEcdoKIm+EV16T3fWMU0tMkPGSCRjSPC2Qm5keUZURnVJYcy5sPZI8UsCY0TDETeRIyrS1euLk2ljOkgwVee1m05CzJ8CEOEy9Ulcj7BaVFdRuTbk6uLhY+y0vAZ3wgpLZscGpTNQYaqXAcYc3b+QAhWtwwGjBoU1RV5kOFDOBD5Rxb5NYwcuOzcbECO8WtMw5saMvWKTLoQ/CHDhzCNLL/UXIicB5ZZw4ln3jJe11fNLWHUpSeja4Gv24cvwjb5M7B/YfDFzQZcXZZ86zVEpMl3OxIhIMOHMISqi8iRUV1iHB7qecus28CQsdBGhZr8ynPUZWnRq+qzYGWMbEYYLFeXIiJLn0jV83jcU9VXmeb7CGOQAWUNZPgQjsMJayhkD4+WXD1d2BXVZdS+obFNHUP7+AjqTDJAIhsyfAjTSPOQcGnfUE12osXVZdx4kO9Ca3d12eLrEiJU63Wo2WTeKSsi5TtPWAcZPoQhas5oWJ6ri6dLqubrYGINVKe6gaGFUV1hXV1BjoWLRgu5gWGYMoZcXUHO4RNBqHSXGXHDqUmLpNm0aMUuw1qW7TgiHTJ8CMfhhIHFvKtLbCNlccXx0IKXq8sqaGhTx1B2dgF6EJEPGT6EaWT5kSIsb48BmXbbFY5xdRmVJeGQJ3dUlwCZOq5nzesV7NoZdnUZO40rsjwDCW2Q4UMYQj36J9D9FVaOAQuBq03BVF/yFGtoYz9bXF1BztF+LYPL9sk34jZUi0DjHtUVJKQtpF7q8uSYSyP4QVc00iDDh3Acds+maMG04cJHjeDyJelDLmHkjnN1Rd/0gLAZEUlSVhDOggwfImLg6d5xOuTqsh6pXV0CKjW6daDzDBUNGxhKeD8SwSHDhzBE+OgfbT+nDbk+uEZ11XTPiZKr/FfT+cJdXUHcRxZGdWnpb8a0bGBorLP83WV65QR1dUkym0bwgi5opEGGD+E8HPAcMu/qEh3VJVS8Zni002murmhE2EaDOvYSIogqyPAhjKEyC2BkZxUjY0+wc4xEdSlmIAzoElxu4IyEnkHejkFZy/peLWkwtLZTSxs1ZWfnYfhw7O9w7Xeeq0edStclv8bI2y+UqyvSIMOHcByy7EETCvk1jBx4uLoAIxsYGoM2qeOHNV1J3+ZIgwwfwjT0HOePaNtOFttRFj0I0Yh7SNDzh9ALGT6EIcIt3rVjHx+XS7+334jORuXqWtwseo1PEPk83Eqar73GMuH6goeri+uC+TCiImWcNrq6JniuLol6xhX0jXpxiVQnwkOGD+E4nDBLYHYgdUIbeSBTM/XqYtTlSoMkP4R1JQv6hogAyPAhTCPLg9wFSKOM7IaL7PpFMpEShaQrZYXAJsvQm5FyTaMFMnwIQ6i6cgzsrcIzqssIPFIfqMsNfG2nreE/O6G6Nw5j4d1KIeswp1NQmRZEdZEhaB3BXFpSmQ46XV2EsyDDh3Acjojq4rABYTTA41ryi+rSuYGhoVqlmZSMCIStCyJXV0RDhg9hGlke5JVpGmRB7oelE4zHSEWee9QclSkrtLVGZJtlWBQtgQqEDsjwIQyhcOWoRS1pjuoyV7dZjKTZ0Cu36o0e+byjuoKlV/AvEz6qK8QGhtDXTm1RXeF7QjZXFxmVoQlmI0hlPJCrK6Ihw4dwHg4YV8jVpQ0ezTQqw/88/VFdBiumcZQbFNVFGIEMH8I0svxSc8EljS6yEy2GlYxESgSQS4dvOdK/lxHevIiDDB/CEIpcVCqDqNZx1YhLh292djGYjRbjrVeAvCDXLKxbKdRnLHwZtfLhyphxv2k9z9INDKN8lAy6gaEB80FYX5KrK6Ihw4dwHE6YrTDv6nJAI3nAoZncXF26BUXJNSKICIMMH8I00vyClSiqy+4hsdILEbw39Mxw8Lq+eja8CytLmitdjVaN5NPcOJo3MKzR6mDXzui9IcPzRwYdCO2Q4UMYQj2qK7T7S1WOkagurhE41snVl6vLfP3KfGr+e9YEOUflA619FK6d/m4rpiFmi0HdSFPLFacX3tde60aVMoRfRwoyGsCE/JDhQzgO0Qk8eSB7ri75e1APfJxdeq9ZtHgjCSLSIMOHiBhckOjXtM2DYjhXl15ZvOSQqytyXF16Ngyted2DL242qIcUPSqDDoRWyPAhDKF0WSj/rXwtbuTn+0tbQ2SPyU0WfRv76RJkfsYoVGSZqksriIbKoho2MAxSJsDVpSFiC4wFiRrk7Ory/U/H+UHeU1SXhVBfEgYgw4dwHE7wMJiNyiJXl3Z4RXVZhRwzFAQRvZDhQ0QMwnJ1OXCcinRXl4xoblqE9EHlhqH6c3UFPcNAv8hyT8mgA6Edxxk+JSUl6NSpE1wuF4qKinzH9+zZA5fLFfC3fv16+5SNYBTuDJVonoiK6jLr6pIiqivwc7VzVDc2FBTVFU4eUBXVZVynkLL93W4mzgdqunwjaT6NICKPOLsV0MuDDz6I+vXrY/Pmzaqff/bZZ2jbtq3vfUZGhlWqEZYh/8DiNb2BIR89gsp3QB9qhcfOzVZCswMEYS+OMnxWrFiBlStXYtmyZVixYoVqmYyMDOTk5FisGSEDlVPvAgYzBw5U5OqyHorqClW2ZlhXkDJGUlYEF2cpMuhAaMcxrq6jR49i1KhRePvtt5GUlBS03ODBg5GdnY2ePXviww8/DCu3pKQExcXFij9CA34b0dX81+/jMGL0GypcXV1a5BpyxwX2hS5XF4fF0crrEcQv43dIdbNAlQg+1TrDlFGN6gohr/octQg0bTqFlO33Tm+X+/eVketMEIT1OMLwYYyhoKAAd999N7p06aJaJiUlBc899xyWLFmC//znP+jZsyeGDBkS1viZOXMm0tLSfH+5ubkimkBwxAnjiuk1Oly0sE++lfBY42Ml0uw1RRBRiq2ursmTJ+Ppp58OWWbbtm1YuXIlzpw5gylTpgQtl5mZiQkTJvjeX3755Th06BBmzZqFwYMHBz1vypQpivOKi4vJ+HEoPN07SsEGzrF5jY9TXF2RlIw16lxdMHZv8MzVVRnEov883pAx6yxsNXwmTpyIgoKCkGWaNWuGVatWYd26dfB4PIrPunTpguHDh2PBggWq53br1g2FhYUh5Xs8ngC5RHjCRS1pHdCMRXXxGyyVLqlg4UgG5KpEVOkRwyPlhd6orqCbBWqNoNIZ1aWljcE3VdRw3TTIVuhmMmVFOFcfQRByYKvhk5WVhaysrLDlXnrpJTzxxBO+94cOHcKAAQOwePFidOvWLeh5RUVFqFevHhddCXlwwsAi+0RGJEV1OW4HQ4IgbMURUV2NGjVSvE9JSQEANG/eHA0bNgQALFiwAG63G507dwYALF++HPPmzcMbb7xhrbKEbbhEhXjYMYsdLa4uPqKlwEjeKiej5x4TlatLlvx89mtA6MERho9WHn/8cezduxdxcXFo3bo1Fi9ejKFDh9qtVkQSPleXRjkm6zaLuKiumqf/EfWmQ3HTi6PDuG7U818FOa7RPcXCOHvUorrCEXRTxSCv9eAvQ39UV5D3sk/3EUSU40jDp0mTJgGDSH5+PvLz823SiLASJwwrXskHP7m104fToroIfkgw2UM4EEeEsxOEFlyi0j/a8HCNnqguPrJlQHtUV2SM1noiqmq2OdgpRl1WMvQmGWDOggwfwhDKiJgqV46igDY5BkY+vlFdNV5zk+onS8qoLvWNCoMEewWVo1ZOe1RXeCo9Xeq6VpfhEdWlX4p/H1JUV6RCVzTSIMOHIAQg+0yG7PrpgVxd0YsLOvJmEMQfkOFDGEL9l7v+vVV4Lm42kgtKbWaGDyq9okM+70FZ8545YSoOOeOjoYxSVpCVy371BVuIrfZaDzxkqMoNIyxS3CJGmxHMpSVvt4TXLFLcl9ECGT6E43DCHjRmDRf5WygPvLKzR9Iu0gRP6L6INMjwISIKWX55mQ9HF/uwlWWMl0UPwgAGZli5qyAqTY0BPQjnQIYPYQi1/W/07tGip5zZc4LL0u+e0y23avG3Dvm87YHA9AraFzeHO6/6fH3t1La4OUjWdMV1M4baPcwDJ8xI2knwqC5L1dCBtIoRBiHDh3AcTpglcICKkQMPywcGNjCkixwl0IWONMjwISIGWTI1AxwGRcHPWlkGbUnUsBRZ7lGzuMTtnKVPD/tVIBwGGT6EIZiKq8GIq8tQOghBw6XoVBh65PNuo780Ve8RwuvIN6pLS6Hgula/5rCPjyEJQeRGozWng+C5umS1YGTVizAKGT6E43DCwEIRQtZh1z4+tJbHfmi2hzACGT5ExFCZqdluLfggOmWFHsOMUlZoI/pSVhi7N4K232C3yNCbkfLciRbI8CEMwVR8OUZcB0Z+NYtySwSVy2lPHj1iTM9GML/rESS9QmCd6tFeWusMJtunk85dAyvdb6F14jHjw1iQ6DGN5wPGrjNBENZDhg/hPBwwskTSTIbscArqIhxIpMyeEdZChg8RMQjbzMyASNNJRk2drcXVpU8WLwJcXRFkfmh2dUXIWO2CQTdTME+XUVeXBP1pNLM8YQ9k+BCmUY/q0riJnc1RXaHcQTUK6Zer4orRFdVlcsoowNUVWELliLq7R3N29jBl/KPGNOUPC5I1XdN10yA7mExt5/vrpH6cIAi5IMOHcBxOGFgoV5c2eFxLcnVFLzTRQhiBDB8iYhAW1WWDq8ssTnF1RRLao7oig8qoLv2tCb6Pj3Nxsu7RCBk+hCFUXTk1P9cqx0jdBs4JKktQVJeaS0dXri7uUV1+n6ueFCraq6pIKF9X6Hb6R05paWNAJJiaTlyiuvTL8S9eHdVFc0lOhwyZyIYMH8JxOGFzQPMaim2jLF3IRw1ydkUrogwUujMiGzJ8iIhBWGSFA3/+8YxwI1eXNrRHdUVGJxjN1BU8O7tz+8XBqkclZPgQhlBGDP3h4jDgfjAyeyPM1RV05z0jggPl6ovqMlCn3/kKl0uAq0s9zotHVFew/gqM6goPq/F/IzqFlO3nwtMrJuimkDRdYBmijCWyYyIbMnwIxyGLmyYUXrPh6Jz0CCpfkj7k4bYkRxfBG7o3IhsyfIiIoTKqS44NDGWAXF3WEp1RXUbOi5QeqIZ2kHYWZPgQhlCP6tIf12V7VJeW/GJGorpMiuGROVzNHRlKfuVmgWHcSqHqVInu8/9c7yaXQaO6guinh8CoLp0bGAZ5T7MF1iHK3CAzJrIhw4dwHrL4aUJgeudl0VFdETQ8G21LJPUBwRe6MyIbMnyIiKEykkmEYP2nyPDgJFeXtURlri4jGxjyV8V2IuWaRgtk+BCGUHU1GIrqMle3WZgWn4nZDQwNhHUJ38AwSPRW+Kiu4IpVR/eFKOPnNgvXzmDRVjXr4Obq0i1A/a0T9pmKFGgHC8IIZPgQjsMJ44pZFR3QRGmgqC6CIPRAhg8RQbikydUlg3VGkSbWEm0bGBr9svF1ncrRl3JoQWiFDB/CEApXg9+//q9DyjHwu5vnolRNOpt0xxmJ9jG/ODp0xFqwSCl1t5KyTNA6w0R1Bchi4a+llhxaRvtKeQ8z3bZqQKScT64hdQiCsAgyfAjH4YSBRXYdKaKJIIhohQwfImKQKapLBsjVZS3R1ttG2xuR92UENimSIcOHMIQyGCowmkfzjIfJiCnThIlEY4bCfdQjqqzM1YWAqC4tGxiGdxuFzNWls51a3UthN1XkFNWl90IHRMr5/UsQhJyQ4UM4DicMLDx2XhaJE/pQK7SBIUEQeiDDhzBE2DQCIlNWBLEqjGyoFiqtgxn8M39XHrNwH58gC2+r5avMogRpv7JsqH18wpXwk6VltoepzwqF2qNIK3r3FArUIbzcSMZoQJUkgVhciUj3XQTjGMOnSZMmcLlcir+nnnpKUeaHH35Ar169kJCQgNzcXDzzzDM2aUtECnbtERMtgyePdvIwfAiCiB7i7FZAD3/7298watQo3/vU1FTf6+LiYvTv3x/9+vXDq6++ih9//BF33nkn0tPTMXr0aDvUJaIY2XfvlVs7giAIcTjK8ElNTUVOTo7qZwsXLkRpaSnmzZsHt9uNtm3boqioCLNnz5bC8Dlw8rzdKnDlaPFF3+vSci8OnDyPcyUVvmPHz5ZqavPvZ0t1111a7lU9biSqq+QP3YPJLfcyeA0YMaUV1bLOXizHgZPncepCmebzT5zT3y81qfAyVHir9T586iIullVfn9+KSwLOOXOxHMdVrkeZl/n66NiZwPOqKC2vwIGT53GhtDxomfIaOh06fREnz4du55mSctW+KKuolmO0r2qeV1JWgaMqfaL1fAAor6i8l86WaL/OTobcO9VEovsuknGU4fPUU0/h8ccfR6NGjTBs2DCMHz8ecXGVTVi3bh169+4Nt9vtKz9gwAA8/fTTOHnyJGrXrq0qs6SkBCUl1Q+84uJiIbr/6bkvgw7YTufX38+h59OrFcce/fAnPPrhT8Lq48UPB04H6F6TUAN9KH49Vq3j+0WH8H7RIV3nz/h4m6F6q/AypVF5/ctrw56z9LsDqsePnSkJ2UdV7DoWeB/481uN/hzyytdhZS7//iCWf38w4PjuGveA0b6qed7mA6dx2z836Dp/1qc7FO+LL5Zr6qdwxLgqrx9P4mLsG5k9cbHwrz4hPjagXDAN42KrP0mID1ydIcIA89TQL9ZPeU9cDEo4PstFXBu1/nXHKfvOExdYJlpwzBqf+++/H4sWLcLq1avxl7/8BU8++SQefPBB3+dHjhxB3bp1FedUvT9y5EhQuTNnzkRaWprvLzc3V4j+nriYiPtTa5uR9tY8J9UTF9Bvan2ZlhiPF/5PJ2SlegAAqQlx6N8mBwPa5iDVE4dmmcl4eVhnNKqThEHtcpBSQ27NB5maLu7YwHb4k+yufmikeOIU8v31Vmtrzc/aN0hDXuPaAecE64NQnwXTW63f/QeRUDqqnZcQX/m+V8tMNM9KVm1nzevpDqJTKKrK1Oxvd2ygHLUBMRyhrlGiysChdr47iIzMFDcGtauena6dFA8AGN6tEQDgz50b+Nriz6LR3TGmT3PUSojDte1zkP7HuWp6A8DMG9qjbf1aAIBr2tRFk4wkzBraAc2ykgEAE665BDde1tDXh6N7NwMAzCvogkZ1kjCwbQ5qJcRh2v+0QY/mGQrZHRqm4bmbOqJJRhJeGXaZ73hWqgc9W2YCAG4I0RYAeP7/dMLAdjnITPFgQNu6SIiPVcgCgJE9myLZE4dB7XJwRbM6uLReZXsurVcLQ/Ma+srNHZ6HRnWSFH3Y99JsZCRX/uCtn5aAfpfWRVpivGrfVV2vJHcsBrbN8T0/AKDfpZXjRedG6Xjh/3RCy+wUTOp/CTo0SEPH3HQAwF+uaoaFd3VDozpJmF9wue/cjGQ3erXMRN1aHvRvUxe1Eirv+6o+v+fq5qp9AwDXtq+H9g3ScFfPporj//e6S9E8KxlXt8rCZY3S0bFhGvq2zvZ9/vfhlX14f9+WvmNv3NEFAPDCLZ1qyM9Bs8xkPHZ9WwDAi7d0QpOMJLx4a3WZaMPFbFyMMHnyZDz99NMhy2zbtg2tW7cOOD5v3jz85S9/wdmzZ+HxeNC/f380bdoUr732mq/M1q1b0bZtW2zduhWXXnqpqny1GZ/c3FycPn0atWrVMtgygiAIgiCspLi4GGlpaWHHb1tdXRMnTkRBQUHIMs2aNVM93q1bN5SXl2PPnj1o1aoVcnJycPToUUWZqvfB1gUBgMfjgcfjCfo5QRAEQRCRg62GT1ZWFrKysgydW1RUhJiYGGRnV079de/eHY888gjKysoQH185vVlYWIhWrVoFXd9DEARBEER04Yg1PuvWrcMLL7yAzZs349dff8XChQsxfvx43HbbbT6jZtiwYXC73Rg5ciR++uknLF68GC+++CImTJhgs/YEQRAEQciCI6K6PB4PFi1ahMceewwlJSVo2rQpxo8frzBq0tLSsHLlSowZMwZ5eXnIzMzEtGnTpAhlJwiCIAhCDmxd3CwjWhdHEQRBEAQhD1rHb0e4ugiCIAiCIHhAhg9BEARBEFEDGT4EQRAEQUQNZPgQBEEQBBE1kOFDEARBEETUQIYPQRAEQRBRAxk+BEEQBEFEDWT4EARBEAQRNZDhQxAEQRBE1OCIlBVWUrWRdXFxsc2aEARBEAShlapxO1xCCjJ8/Dhz5gwAIDc312ZNCIIgCILQy5kzZ5CWlhb0c8rV5YfX68WhQ4eQmpoKl8vFTW5xcTFyc3Oxf/9+ygEmEOpn66C+tgbqZ2ugfrYGkf3MGMOZM2dQv359xMQEX8lDMz5+xMTEoGHDhsLk16pVi75UFkD9bB3U19ZA/WwN1M/WIKqfQ830VEGLmwmCIAiCiBrI8CEIgiAIImogw8ciPB4PHn30UXg8HrtViWion62D+toaqJ+tgfrZGmToZ1rcTBAEQRBE1EAzPgRBEARBRA1k+BAEQRAEETWQ4UMQBEEQRNRAhg9BEARBEFEDGT4W8corr6BJkyZISEhAt27d8M0339itkmOYOXMmLr/8cqSmpiI7OxtDhgzBjh07FGUuXryIMWPGICMjAykpKbjxxhtx9OhRRZl9+/bhuuuuQ1JSErKzs/HAAw+gvLzcyqY4iqeeegoulwvjxo3zHaN+5sfBgwdx2223ISMjA4mJiWjfvj2+/fZb3+eMMUybNg316tVDYmIi+vXrh19++UUh48SJExg+fDhq1aqF9PR0jBw5EmfPnrW6KdJSUVGBqVOnomnTpkhMTETz5s3x+OOPK3I5UT/r56uvvsL111+P+vXrw+Vy4f3331d8zqtPf/jhB/Tq1QsJCQnIzc3FM888w6cBjBDOokWLmNvtZvPmzWM//fQTGzVqFEtPT2dHjx61WzVHMGDAADZ//ny2ZcsWVlRUxK699lrWqFEjdvbsWV+Zu+++m+Xm5rLPP/+cffvtt+yKK65gPXr08H1eXl7O2rVrx/r168c2bdrEPv74Y5aZmcmmTJliR5Ok55tvvmFNmjRhHTp0YGPHjvUdp37mw4kTJ1jjxo1ZQUEB27BhA/v111/Zp59+ynbu3Okr89RTT7G0tDT2/vvvs82bN7PBgwezpk2bsgsXLvjKDBw4kHXs2JGtX7+erVmzhrVo0YLdeuutdjRJSmbMmMEyMjLYRx99xHbv3s2WLFnCUlJS2IsvvugrQ/2sn48//pg98sgjbPny5QwAe++99xSf8+jT06dPs7p167Lhw4ezLVu2sHfeeYclJiay1157zbT+ZPhYQNeuXdmYMWN87ysqKlj9+vXZzJkzbdTKufz2228MAPvyyy8ZY4ydOnWKxcfHsyVLlvjKbNu2jQFg69atY4xVflFjYmLYkSNHfGXmzp3LatWqxUpKSqxtgOScOXOGtWzZkhUWFrKrrrrKZ/hQP/PjoYceYj179gz6udfrZTk5OWzWrFm+Y6dOnWIej4e98847jDHGtm7dygCwjRs3+sqsWLGCuVwudvDgQXHKO4jrrruO3XnnnYpjN9xwAxs+fDhjjPqZB/6GD68+/fvf/85q166teG489NBDrFWrVqZ1JleXYEpLS/Hdd9+hX79+vmMxMTHo168f1q1bZ6NmzuX06dMAgDp16gAAvvvuO5SVlSn6uHXr1mjUqJGvj9etW4f27dujbt26vjIDBgxAcXExfvrpJwu1l58xY8bguuuuU/QnQP3Mkw8//BBdunTBTTfdhOzsbHTu3Bn/+Mc/fJ/v3r0bR44cUfR1WloaunXrpujr9PR0dOnSxVemX79+iImJwYYNG6xrjMT06NEDn3/+OX7++WcAwObNm7F27VoMGjQIAPWzCHj16bp169C7d2+43W5fmQEDBmDHjh04efKkKR0pSalgfv/9d1RUVCgGAgCoW7cutm/fbpNWzsXr9WLcuHG48sor0a5dOwDAkSNH4Ha7kZ6erihbt25dHDlyxFdG7RpUfUZUsmjRInz//ffYuHFjwGfUz/z49ddfMXfuXEyYMAEPP/wwNm7ciPvvvx9utxv5+fm+vlLry5p9nZ2drfg8Li4OderUob7+g8mTJ6O4uBitW7dGbGwsKioqMGPGDAwfPhwAqJ8FwKtPjxw5gqZNmwbIqPqsdu3ahnUkw4dwFGPGjMGWLVuwdu1au1WJOPbv34+xY8eisLAQCQkJdqsT0Xi9XnTp0gVPPvkkAKBz587YsmULXn31VeTn59usXeTw7rvvYuHChfh//+//oW3btigqKsK4ceNQv3596ucohlxdgsnMzERsbGxA5MvRo0eRk5Njk1bO5L777sNHH32E1atXo2HDhr7jOTk5KC0txalTpxTla/ZxTk6O6jWo+oyodGX99ttvuOyyyxAXF4e4uDh8+eWXeOmllxAXF4e6detSP3OiXr16aNOmjeLYpZdein379gGo7qtQz42cnBz89ttvis/Ly8tx4sQJ6us/eOCBBzB58mTccsstaN++PW6//XaMHz8eM2fOBED9LAJefSryWUKGj2Dcbjfy8vLw+eef+455vV58/vnn6N69u42aOQfGGO677z689957WLVqVcD0Z15eHuLj4xV9vGPHDuzbt8/Xx927d8ePP/6o+LIVFhaiVq1aAQNQtNK3b1/8+OOPKCoq8v116dIFw4cP972mfubDlVdeGbAlw88//4zGjRsDAJo2bYqcnBxFXxcXF2PDhg2Kvj516hS+++47X5lVq1bB6/WiW7duFrRCfs6fP4+YGOUwFxsbC6/XC4D6WQS8+rR79+746quvUFZW5itTWFiIVq1amXJzAaBwditYtGgR83g87M0332Rbt25lo0ePZunp6YrIFyI499xzD0tLS2NffPEFO3z4sO/v/PnzvjJ33303a9SoEVu1ahX79ttvWffu3Vn37t19n1eFWffv358VFRWxTz75hGVlZVGYdRhqRnUxRv3Mi2+++YbFxcWxGTNmsF9++YUtXLiQJSUlsX/961++Mk899RRLT09nH3zwAfvhhx/Y//7v/6qGBHfu3Jlt2LCBrV27lrVs2TKqw6z9yc/PZw0aNPCFsy9fvpxlZmayBx980FeG+lk/Z86cYZs2bWKbNm1iANjs2bPZpk2b2N69exljfPr01KlTrG7duuz2229nW7ZsYYsWLWJJSUkUzu4k5syZwxo1asTcbjfr2rUrW79+vd0qOQYAqn/z58/3lblw4QK79957We3atVlSUhL785//zA4fPqyQs2fPHjZo0CCWmJjIMjMz2cSJE1lZWZnFrXEW/oYP9TM//v3vf7N27doxj8fDWrduzV5//XXF516vl02dOpXVrVuXeTwe1rdvX7Zjxw5FmePHj7Nbb72VpaSksFq1arERI0awM2fOWNkMqSkuLmZjx45ljRo1YgkJCaxZs2bskUceUYRIUz/rZ/Xq1arP5Pz8fMYYvz7dvHkz69mzJ/N4PKxBgwbsqaee4qK/i7EaW1gSBEEQBEFEMLTGhyAIgiCIqIEMH4IgCIIgogYyfAiCIAiCiBrI8CEIgiAIImogw4cgCIIgiKiBDB+CIAiCIKIGMnwIgiAIgogayPAhCCIi2LNnD1wuF4qKioTVUVBQgCFDhgiTTxCEeMjwIQhCCgoKCuByuQL+Bg4cqOn83NxcHD58GO3atROsKUEQTibObgUIgiCqGDhwIObPn6845vF4NJ0bGxtL2bIJgggLzfgQBCENHo8HOTk5ir+qTMwulwtz587FoEGDkJiYiGbNmmHp0qW+c/1dXSdPnsTw4cORlZWFxMREtGzZUmFU/fjjj/jTn/6ExMREZGRkYPTo0Th79qzv84qKCkyYMAHp6enIyMjAgw8+CP8MP16vFzNnzkTTpk2RmJiIjh07KnQiCEI+yPAhCMIxTJ06FTfeeCM2b96M4cOH45ZbbsG2bduClt26dStWrFiBbdu2Ye7cucjMzAQAnDt3DgMGDEDt2rWxceNGLFmyBJ999hnuu+8+3/nPPfcc3nzzTcybNw9r167FiRMn8N577ynqmDlzJt566y28+uqr+OmnnzB+/Hjcdttt+PLLL8V1AkEQ5uCS6pQgCMIk+fn5LDY2liUnJyv+ZsyYwRhjDAC7++67Fed069aN3XPPPYwxxnbv3s0AsE2bNjHGGLv++uvZiBEjVOt6/fXXWe3atdnZs2d9x/7zn/+wmJgYduTIEcYYY/Xq1WPPPPOM7/OysjLWsGFD9r//+7+MMcYuXrzIkpKS2H//+1+F7JEjR7Jbb73VeEcQBCEUWuNDEIQ09OnTB3PnzlUcq1Onju919+7dFZ917949aBTXPffcgxtvvBHff/89+vfvjyFDhqBHjx4AgG3btqFjx45ITk72lb/yyivh9XqxY8cOJCQk4PDhw+jWrZvv87i4OHTp0sXn7tq5cyfOnz+Pa665RlFvaWkpOnfurL/xBEFYAhk+BEFIQ3JyMlq0aMFF1qBBg7B37158/PHHKCwsRN++fTFmzBg8++yzXORXrQf6z3/+gwYNGig+07ogmyAI66E1PgRBOIb169cHvL/00kuDls/KykJ+fj7+9a9/4YUXXsDrr78OALj00kuxefNmnDt3zlf266+/RkxMDFq1aoW0tDTUq1cPGzZs8H1eXl6O7777zve+TZs28Hg82LdvH1q0aKH4y83N5dVkgiA4QzM+BEFIQ0lJCY4cOaI4FhcX51uUvGTJEnTp0gU9e/bEwoUL8c033+Cf//ynqqxp06YhLy8Pbdu2RUlJCT766COfkTR8+HA8+uijyM/Px2OPPYZjx47hr3/9K26//XbUrVsXADB27Fg89dRTaNmyJVq3bo3Zs2fj1KlTPvmpqamYNGkSxo8fD6/Xi549e+L06dP4+uuvUatWLeTn5wvoIYIgzEKGD0EQ0vDJJ5+gXr16imOtWrXC9u3bAQDTp0/HokWLcO+996JevXp455130KZNG1VZbrcbU6ZMwZ49e5CYmIhevXph0aJFAICkpCR8+umnGDt2LC6//HIkJSXhxhtvxOzZs33nT5w4EYcPH0Z+fj5iYmJw55134s9//jNOnz7tK/P4448jKysLM2fOxK+//or09HRcdtllePjhh3l3DUEQnHAx5rcxBUEQhIS4XC689957lDKCIAhT0BofgiAIgiCiBjJ8CIIgCIKIGmiND0EQjoC88gRB8IBmfAiCIAiCiBrI8CEIgiAIImogw4cgCIIgiKiBDB+CIAiCIKIGMnwIgiAIgogayPAhCIIgCCJqIMOHIAiCIIiogQwfgiAIgiCiBjJ8CIIgCIKIGv4/k6LX2g1TwI8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the total rewards per episode\n",
        "plt.plot(episode_rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.title('Total Rewards per Episode')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzPHd0beIaHJ",
        "outputId": "a2de722b-1ba1-4aa8-fee9-ccfd62a89fb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Episode Path\n",
            "S              \n",
            "X              \n",
            "X              \n",
            "X              \n",
            "X              \n",
            "X              \n",
            "X              \n",
            "X             G\n",
            "\n",
            "Last Episode Path\n",
            "S              \n",
            "X              \n",
            "X              \n",
            "X X X X X X X X\n",
            "              X\n",
            "              X\n",
            "              X\n",
            "              G\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Function to visualize the path of an episode\n",
        "def plot_episode_path(path, title):\n",
        "    grid = [[' ' for _ in range(env.grid_size)] for _ in range(env.grid_size)]  # Initialize an empty grid\n",
        "    grid[0][0] = 'S'  # Mark the start position\n",
        "    grid[env.grid_size-1][env.grid_size-1] = 'G'  # Mark the goal position\n",
        "    for (x, y) in path:\n",
        "        if (x, y) != (0, 0) and (x, y) != (env.grid_size-1, env.grid_size-1):\n",
        "            grid[x][y] = 'X'  # Mark the path positions\n",
        "\n",
        "    # Print the grid\n",
        "    print(title)\n",
        "    for row in grid:\n",
        "        print(' '.join(row))\n",
        "    print()\n",
        "\n",
        "# Visualize the path of the first and last episode\n",
        "plot_episode_path(first_episode_path, 'First Episode Path')\n",
        "plot_episode_path(last_episode_path, 'Last Episode Path')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufTokrGqziKL",
        "outputId": "4f625b37-025d-4f58-de19-23c12b528acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium<0.30,>=0.28.1 (from stable-baselines3[extra])\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.8.0.76)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.2)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.15.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.7.1)\n",
            "Collecting shimmy[atari]~=1.3.0 (from stable-baselines3[extra])\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (9.4.0)\n",
            "Collecting autorom[accept-rom-license]~=0.6.1 (from stable-baselines3[extra])\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra])\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0->stable-baselines3[extra])\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.15.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.16.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]) (6.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=9d687dbad9c1c720c724fd6bc977372c2823aed0ceab1e4775610362636f6840\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: farama-notifications, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, ale-py, shimmy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, AutoROM.accept-rom-license, autorom, nvidia-cusolver-cu12, stable-baselines3\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 farama-notifications-0.0.4 gymnasium-0.29.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 shimmy-1.3.0 stable-baselines3-2.3.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 1, Total Steps: 50, Total Reward: -50\n",
            "Episode: 2, Total Steps: 50, Total Reward: -50\n",
            "Episode: 3, Total Steps: 50, Total Reward: -50\n",
            "Episode: 4, Total Steps: 50, Total Reward: -50\n",
            "Episode: 5, Total Steps: 50, Total Reward: -50\n",
            "Episode: 6, Total Steps: 50, Total Reward: -50\n",
            "Episode: 7, Total Steps: 50, Total Reward: -50\n",
            "Episode: 8, Total Steps: 50, Total Reward: -50\n",
            "Episode: 9, Total Steps: 50, Total Reward: -50\n",
            "Episode: 10, Total Steps: 50, Total Reward: -50\n",
            "Episode: 11, Total Steps: 50, Total Reward: -50\n",
            "Episode: 12, Total Steps: 50, Total Reward: -50\n",
            "Episode: 13, Total Steps: 50, Total Reward: -50\n",
            "Episode: 14, Total Steps: 50, Total Reward: -50\n",
            "Episode: 15, Total Steps: 50, Total Reward: -50\n",
            "Episode: 16, Total Steps: 50, Total Reward: -50\n",
            "Episode: 17, Total Steps: 50, Total Reward: -50\n",
            "Episode: 18, Total Steps: 50, Total Reward: -50\n",
            "Episode: 19, Total Steps: 50, Total Reward: -50\n",
            "Episode: 20, Total Steps: 50, Total Reward: -50\n",
            "Episode: 21, Total Steps: 50, Total Reward: -50\n",
            "Episode: 22, Total Steps: 50, Total Reward: -50\n",
            "Episode: 23, Total Steps: 50, Total Reward: -50\n",
            "Episode: 24, Total Steps: 50, Total Reward: -50\n",
            "Episode: 25, Total Steps: 50, Total Reward: -50\n",
            "Episode: 26, Total Steps: 50, Total Reward: -50\n",
            "Episode: 27, Total Steps: 50, Total Reward: -50\n",
            "Episode: 28, Total Steps: 50, Total Reward: -50\n",
            "Episode: 29, Total Steps: 50, Total Reward: -50\n",
            "Episode: 30, Total Steps: 50, Total Reward: -50\n",
            "Episode: 31, Total Steps: 50, Total Reward: -50\n",
            "Episode: 32, Total Steps: 50, Total Reward: -50\n",
            "Episode: 33, Total Steps: 50, Total Reward: -50\n",
            "Episode: 34, Total Steps: 50, Total Reward: -50\n",
            "Episode: 35, Total Steps: 50, Total Reward: -50\n",
            "Episode: 36, Total Steps: 50, Total Reward: -50\n",
            "Episode: 37, Total Steps: 50, Total Reward: -50\n",
            "Episode: 38, Total Steps: 50, Total Reward: -50\n",
            "Episode: 39, Total Steps: 50, Total Reward: -50\n",
            "Episode: 40, Total Steps: 50, Total Reward: -50\n",
            "Episode: 41, Total Steps: 50, Total Reward: -50\n",
            "Episode: 42, Total Steps: 50, Total Reward: -50\n",
            "Episode: 43, Total Steps: 50, Total Reward: -50\n",
            "Episode: 44, Total Steps: 50, Total Reward: -50\n",
            "Episode: 45, Total Steps: 50, Total Reward: -50\n",
            "Episode: 46, Total Steps: 50, Total Reward: -50\n",
            "Episode: 47, Total Steps: 50, Total Reward: -50\n",
            "Episode: 48, Total Steps: 50, Total Reward: -50\n",
            "Episode: 49, Total Steps: 50, Total Reward: -50\n",
            "Episode: 50, Total Steps: 50, Total Reward: -50\n",
            "Episode: 51, Total Steps: 50, Total Reward: -50\n",
            "Episode: 52, Total Steps: 50, Total Reward: -50\n",
            "Episode: 53, Total Steps: 50, Total Reward: -50\n",
            "Episode: 54, Total Steps: 50, Total Reward: -50\n",
            "Episode: 55, Total Steps: 50, Total Reward: -50\n",
            "Episode: 56, Total Steps: 50, Total Reward: -50\n",
            "Episode: 57, Total Steps: 50, Total Reward: -50\n",
            "Episode: 58, Total Steps: 50, Total Reward: -50\n",
            "Episode: 59, Total Steps: 50, Total Reward: -50\n",
            "Episode: 60, Total Steps: 50, Total Reward: -50\n",
            "Episode: 61, Total Steps: 50, Total Reward: -50\n",
            "Episode: 62, Total Steps: 50, Total Reward: -50\n",
            "Episode: 63, Total Steps: 50, Total Reward: -50\n",
            "Episode: 64, Total Steps: 50, Total Reward: -50\n",
            "Episode: 65, Total Steps: 50, Total Reward: -50\n",
            "Episode: 66, Total Steps: 50, Total Reward: -50\n",
            "Episode: 67, Total Steps: 50, Total Reward: -50\n",
            "Episode: 68, Total Steps: 50, Total Reward: -50\n",
            "Episode: 69, Total Steps: 50, Total Reward: -50\n",
            "Episode: 70, Total Steps: 50, Total Reward: -50\n",
            "Episode: 71, Total Steps: 50, Total Reward: -50\n",
            "Episode: 72, Total Steps: 50, Total Reward: -50\n",
            "Episode: 73, Total Steps: 50, Total Reward: -50\n",
            "Episode: 74, Total Steps: 50, Total Reward: -50\n",
            "Episode: 75, Total Steps: 50, Total Reward: -50\n",
            "Episode: 76, Total Steps: 50, Total Reward: -50\n",
            "Episode: 77, Total Steps: 50, Total Reward: -50\n",
            "Episode: 78, Total Steps: 50, Total Reward: -50\n",
            "Episode: 79, Total Steps: 50, Total Reward: -50\n",
            "Episode: 80, Total Steps: 50, Total Reward: -50\n",
            "Episode: 81, Total Steps: 50, Total Reward: -50\n",
            "Episode: 82, Total Steps: 50, Total Reward: -50\n",
            "Episode: 83, Total Steps: 50, Total Reward: -50\n",
            "Episode: 84, Total Steps: 50, Total Reward: -50\n",
            "Episode: 85, Total Steps: 50, Total Reward: -50\n",
            "Episode: 86, Total Steps: 50, Total Reward: -50\n",
            "Episode: 87, Total Steps: 50, Total Reward: -50\n",
            "Episode: 88, Total Steps: 50, Total Reward: -50\n",
            "Episode: 89, Total Steps: 50, Total Reward: -50\n",
            "Episode: 90, Total Steps: 50, Total Reward: -50\n",
            "Episode: 91, Total Steps: 50, Total Reward: -50\n",
            "Episode: 92, Total Steps: 50, Total Reward: -50\n",
            "Episode: 93, Total Steps: 50, Total Reward: -50\n",
            "Episode: 94, Total Steps: 50, Total Reward: -50\n",
            "Episode: 95, Total Steps: 50, Total Reward: -50\n",
            "Episode: 96, Total Steps: 50, Total Reward: -50\n",
            "Episode: 97, Total Steps: 50, Total Reward: -50\n",
            "Episode: 98, Total Steps: 50, Total Reward: -50\n",
            "Episode: 99, Total Steps: 50, Total Reward: -50\n",
            "Episode: 100, Total Steps: 50, Total Reward: -50\n",
            "Episode: 101, Total Steps: 50, Total Reward: -50\n",
            "Episode: 102, Total Steps: 50, Total Reward: -50\n",
            "Episode: 103, Total Steps: 50, Total Reward: -50\n",
            "Episode: 104, Total Steps: 50, Total Reward: -50\n",
            "Episode: 105, Total Steps: 50, Total Reward: -50\n",
            "Episode: 106, Total Steps: 50, Total Reward: -50\n",
            "Episode: 107, Total Steps: 50, Total Reward: -50\n",
            "Episode: 108, Total Steps: 50, Total Reward: -50\n",
            "Episode: 109, Total Steps: 50, Total Reward: -50\n",
            "Episode: 110, Total Steps: 50, Total Reward: -50\n",
            "Episode: 111, Total Steps: 50, Total Reward: -50\n",
            "Episode: 112, Total Steps: 50, Total Reward: -50\n",
            "Episode: 113, Total Steps: 50, Total Reward: -50\n",
            "Episode: 114, Total Steps: 50, Total Reward: -50\n",
            "Episode: 115, Total Steps: 50, Total Reward: -50\n",
            "Episode: 116, Total Steps: 50, Total Reward: -50\n",
            "Episode: 117, Total Steps: 50, Total Reward: -50\n",
            "Episode: 118, Total Steps: 50, Total Reward: -50\n",
            "Episode: 119, Total Steps: 50, Total Reward: -50\n",
            "Episode: 120, Total Steps: 50, Total Reward: -50\n",
            "Episode: 121, Total Steps: 50, Total Reward: -50\n",
            "Episode: 122, Total Steps: 50, Total Reward: -50\n",
            "Episode: 123, Total Steps: 50, Total Reward: -50\n",
            "Episode: 124, Total Steps: 50, Total Reward: -50\n",
            "Episode: 125, Total Steps: 50, Total Reward: -50\n",
            "Episode: 126, Total Steps: 50, Total Reward: -50\n",
            "Episode: 127, Total Steps: 50, Total Reward: -50\n",
            "Episode: 128, Total Steps: 50, Total Reward: -50\n",
            "Episode: 129, Total Steps: 50, Total Reward: -50\n",
            "Episode: 130, Total Steps: 50, Total Reward: -50\n",
            "Episode: 131, Total Steps: 50, Total Reward: -50\n",
            "Episode: 132, Total Steps: 50, Total Reward: -50\n",
            "Episode: 133, Total Steps: 50, Total Reward: -50\n",
            "Episode: 134, Total Steps: 50, Total Reward: -50\n",
            "Episode: 135, Total Steps: 50, Total Reward: -50\n",
            "Episode: 136, Total Steps: 50, Total Reward: -50\n",
            "Episode: 137, Total Steps: 50, Total Reward: -50\n",
            "Episode: 138, Total Steps: 50, Total Reward: -50\n",
            "Episode: 139, Total Steps: 50, Total Reward: -50\n",
            "Episode: 140, Total Steps: 50, Total Reward: -50\n",
            "Episode: 141, Total Steps: 50, Total Reward: -50\n",
            "Episode: 142, Total Steps: 50, Total Reward: -50\n",
            "Episode: 143, Total Steps: 50, Total Reward: -50\n",
            "Episode: 144, Total Steps: 50, Total Reward: -50\n",
            "Episode: 145, Total Steps: 50, Total Reward: -50\n",
            "Episode: 146, Total Steps: 50, Total Reward: -50\n",
            "Episode: 147, Total Steps: 50, Total Reward: -50\n",
            "Episode: 148, Total Steps: 50, Total Reward: -50\n",
            "Episode: 149, Total Steps: 50, Total Reward: -50\n",
            "Episode: 150, Total Steps: 50, Total Reward: -50\n",
            "Episode: 151, Total Steps: 50, Total Reward: -50\n",
            "Episode: 152, Total Steps: 50, Total Reward: -50\n",
            "Episode: 153, Total Steps: 50, Total Reward: -50\n",
            "Episode: 154, Total Steps: 50, Total Reward: -50\n",
            "Episode: 155, Total Steps: 50, Total Reward: -50\n",
            "Episode: 156, Total Steps: 50, Total Reward: -50\n",
            "Episode: 157, Total Steps: 50, Total Reward: -50\n",
            "Episode: 158, Total Steps: 50, Total Reward: -50\n",
            "Episode: 159, Total Steps: 50, Total Reward: -50\n",
            "Episode: 160, Total Steps: 50, Total Reward: -50\n",
            "Episode: 161, Total Steps: 50, Total Reward: -50\n",
            "Episode: 162, Total Steps: 50, Total Reward: -50\n",
            "Episode: 163, Total Steps: 50, Total Reward: -50\n",
            "Episode: 164, Total Steps: 50, Total Reward: -50\n",
            "Episode: 165, Total Steps: 50, Total Reward: -50\n",
            "Episode: 166, Total Steps: 50, Total Reward: -50\n",
            "Episode: 167, Total Steps: 50, Total Reward: -50\n",
            "Episode: 168, Total Steps: 50, Total Reward: -50\n",
            "Episode: 169, Total Steps: 50, Total Reward: -50\n",
            "Episode: 170, Total Steps: 50, Total Reward: -50\n",
            "Episode: 171, Total Steps: 50, Total Reward: -50\n",
            "Episode: 172, Total Steps: 50, Total Reward: -50\n",
            "Episode: 173, Total Steps: 50, Total Reward: -50\n",
            "Episode: 174, Total Steps: 50, Total Reward: -50\n",
            "Episode: 175, Total Steps: 50, Total Reward: -50\n",
            "Episode: 176, Total Steps: 50, Total Reward: -50\n",
            "Episode: 177, Total Steps: 50, Total Reward: -50\n",
            "Episode: 178, Total Steps: 50, Total Reward: -50\n",
            "Episode: 179, Total Steps: 50, Total Reward: -50\n",
            "Episode: 180, Total Steps: 50, Total Reward: -50\n",
            "Episode: 181, Total Steps: 50, Total Reward: -50\n",
            "Episode: 182, Total Steps: 50, Total Reward: -50\n",
            "Episode: 183, Total Steps: 50, Total Reward: -50\n",
            "Episode: 184, Total Steps: 50, Total Reward: -50\n",
            "Episode: 185, Total Steps: 50, Total Reward: -50\n",
            "Episode: 186, Total Steps: 50, Total Reward: -50\n",
            "Episode: 187, Total Steps: 50, Total Reward: -50\n",
            "Episode: 188, Total Steps: 50, Total Reward: -50\n",
            "Episode: 189, Total Steps: 50, Total Reward: -50\n",
            "Episode: 190, Total Steps: 50, Total Reward: -50\n",
            "Episode: 191, Total Steps: 50, Total Reward: -50\n",
            "Episode: 192, Total Steps: 50, Total Reward: -50\n",
            "Episode: 193, Total Steps: 50, Total Reward: -50\n",
            "Episode: 194, Total Steps: 50, Total Reward: -50\n",
            "Episode: 195, Total Steps: 50, Total Reward: -50\n",
            "Episode: 196, Total Steps: 50, Total Reward: -50\n",
            "Episode: 197, Total Steps: 50, Total Reward: -50\n",
            "Episode: 198, Total Steps: 50, Total Reward: -50\n",
            "Episode: 199, Total Steps: 50, Total Reward: -50\n",
            "Episode: 200, Total Steps: 50, Total Reward: -50\n",
            "Episode: 201, Total Steps: 50, Total Reward: -50\n",
            "Episode: 202, Total Steps: 50, Total Reward: -50\n",
            "Episode: 203, Total Steps: 50, Total Reward: -50\n",
            "Episode: 204, Total Steps: 50, Total Reward: -50\n",
            "Episode: 205, Total Steps: 50, Total Reward: -50\n",
            "Episode: 206, Total Steps: 50, Total Reward: -50\n",
            "Episode: 207, Total Steps: 50, Total Reward: -50\n",
            "Episode: 208, Total Steps: 50, Total Reward: -50\n",
            "Episode: 209, Total Steps: 50, Total Reward: -50\n",
            "Episode: 210, Total Steps: 50, Total Reward: -50\n",
            "Episode: 211, Total Steps: 50, Total Reward: -50\n",
            "Episode: 212, Total Steps: 50, Total Reward: -50\n",
            "Episode: 213, Total Steps: 50, Total Reward: -50\n",
            "Episode: 214, Total Steps: 50, Total Reward: -50\n",
            "Episode: 215, Total Steps: 50, Total Reward: -50\n",
            "Episode: 216, Total Steps: 50, Total Reward: -50\n",
            "Episode: 217, Total Steps: 50, Total Reward: -50\n",
            "Episode: 218, Total Steps: 50, Total Reward: -50\n",
            "Episode: 219, Total Steps: 50, Total Reward: -50\n",
            "Episode: 220, Total Steps: 50, Total Reward: -50\n",
            "Episode: 221, Total Steps: 50, Total Reward: -50\n",
            "Episode: 222, Total Steps: 50, Total Reward: -50\n",
            "Episode: 223, Total Steps: 50, Total Reward: -50\n",
            "Episode: 224, Total Steps: 50, Total Reward: -50\n",
            "Episode: 225, Total Steps: 50, Total Reward: -50\n",
            "Episode: 226, Total Steps: 50, Total Reward: -50\n",
            "Episode: 227, Total Steps: 50, Total Reward: -50\n",
            "Episode: 228, Total Steps: 50, Total Reward: -50\n",
            "Episode: 229, Total Steps: 50, Total Reward: -50\n",
            "Episode: 230, Total Steps: 50, Total Reward: -50\n",
            "Episode: 231, Total Steps: 50, Total Reward: -50\n",
            "Episode: 232, Total Steps: 50, Total Reward: -50\n",
            "Episode: 233, Total Steps: 50, Total Reward: -50\n",
            "Episode: 234, Total Steps: 50, Total Reward: -50\n",
            "Episode: 235, Total Steps: 50, Total Reward: -50\n",
            "Episode: 236, Total Steps: 50, Total Reward: -50\n",
            "Episode: 237, Total Steps: 50, Total Reward: -50\n",
            "Episode: 238, Total Steps: 50, Total Reward: -50\n",
            "Episode: 239, Total Steps: 50, Total Reward: -50\n",
            "Episode: 240, Total Steps: 50, Total Reward: -50\n",
            "Episode: 241, Total Steps: 50, Total Reward: -50\n",
            "Episode: 242, Total Steps: 50, Total Reward: -50\n",
            "Episode: 243, Total Steps: 50, Total Reward: -50\n",
            "Episode: 244, Total Steps: 50, Total Reward: -50\n",
            "Episode: 245, Total Steps: 50, Total Reward: -50\n",
            "Episode: 246, Total Steps: 50, Total Reward: -50\n",
            "Episode: 247, Total Steps: 50, Total Reward: -50\n",
            "Episode: 248, Total Steps: 50, Total Reward: -50\n",
            "Episode: 249, Total Steps: 50, Total Reward: -50\n",
            "Episode: 250, Total Steps: 50, Total Reward: -50\n",
            "Episode: 251, Total Steps: 50, Total Reward: -50\n",
            "Episode: 252, Total Steps: 50, Total Reward: -50\n",
            "Episode: 253, Total Steps: 50, Total Reward: -50\n",
            "Episode: 254, Total Steps: 50, Total Reward: -50\n",
            "Episode: 255, Total Steps: 50, Total Reward: -50\n",
            "Episode: 256, Total Steps: 50, Total Reward: -50\n",
            "Episode: 257, Total Steps: 50, Total Reward: -50\n",
            "Episode: 258, Total Steps: 50, Total Reward: -50\n",
            "Episode: 259, Total Steps: 50, Total Reward: -50\n",
            "Episode: 260, Total Steps: 50, Total Reward: -50\n",
            "Episode: 261, Total Steps: 50, Total Reward: -50\n",
            "Episode: 262, Total Steps: 50, Total Reward: -50\n",
            "Episode: 263, Total Steps: 50, Total Reward: -50\n",
            "Episode: 264, Total Steps: 50, Total Reward: -50\n",
            "Episode: 265, Total Steps: 50, Total Reward: -50\n",
            "Episode: 266, Total Steps: 50, Total Reward: -50\n",
            "Episode: 267, Total Steps: 50, Total Reward: -50\n",
            "Episode: 268, Total Steps: 50, Total Reward: -50\n",
            "Episode: 269, Total Steps: 50, Total Reward: -50\n",
            "Episode: 270, Total Steps: 50, Total Reward: -50\n",
            "Episode: 271, Total Steps: 50, Total Reward: -50\n",
            "Episode: 272, Total Steps: 50, Total Reward: -50\n",
            "Episode: 273, Total Steps: 50, Total Reward: -50\n",
            "Episode: 274, Total Steps: 50, Total Reward: -50\n",
            "Episode: 275, Total Steps: 50, Total Reward: -50\n",
            "Episode: 276, Total Steps: 50, Total Reward: -50\n",
            "Episode: 277, Total Steps: 50, Total Reward: -50\n",
            "Episode: 278, Total Steps: 50, Total Reward: -50\n",
            "Episode: 279, Total Steps: 50, Total Reward: -50\n",
            "Episode: 280, Total Steps: 50, Total Reward: -50\n",
            "Episode: 281, Total Steps: 50, Total Reward: -50\n",
            "Episode: 282, Total Steps: 50, Total Reward: -50\n",
            "Episode: 283, Total Steps: 50, Total Reward: -50\n",
            "Episode: 284, Total Steps: 50, Total Reward: -50\n",
            "Episode: 285, Total Steps: 50, Total Reward: -50\n",
            "Episode: 286, Total Steps: 50, Total Reward: -50\n",
            "Episode: 287, Total Steps: 50, Total Reward: -50\n",
            "Episode: 288, Total Steps: 50, Total Reward: -50\n",
            "Episode: 289, Total Steps: 50, Total Reward: -50\n",
            "Episode: 290, Total Steps: 50, Total Reward: -50\n",
            "Episode: 291, Total Steps: 50, Total Reward: -50\n",
            "Episode: 292, Total Steps: 50, Total Reward: -50\n",
            "Episode: 293, Total Steps: 50, Total Reward: -50\n",
            "Episode: 294, Total Steps: 50, Total Reward: -50\n",
            "Episode: 295, Total Steps: 50, Total Reward: -50\n",
            "Episode: 296, Total Steps: 50, Total Reward: -50\n",
            "Episode: 297, Total Steps: 50, Total Reward: -50\n",
            "Episode: 298, Total Steps: 50, Total Reward: -50\n",
            "Episode: 299, Total Steps: 50, Total Reward: -50\n",
            "Episode: 300, Total Steps: 50, Total Reward: -50\n",
            "Episode: 301, Total Steps: 50, Total Reward: -50\n",
            "Episode: 302, Total Steps: 50, Total Reward: -50\n",
            "Episode: 303, Total Steps: 50, Total Reward: -50\n",
            "Episode: 304, Total Steps: 50, Total Reward: -50\n",
            "Episode: 305, Total Steps: 50, Total Reward: -50\n",
            "Episode: 306, Total Steps: 50, Total Reward: -50\n",
            "Episode: 307, Total Steps: 50, Total Reward: -50\n",
            "Episode: 308, Total Steps: 50, Total Reward: -50\n",
            "Episode: 309, Total Steps: 50, Total Reward: -50\n",
            "Episode: 310, Total Steps: 50, Total Reward: -50\n",
            "Episode: 311, Total Steps: 50, Total Reward: -50\n",
            "Episode: 312, Total Steps: 50, Total Reward: -50\n",
            "Episode: 313, Total Steps: 50, Total Reward: -50\n",
            "Episode: 314, Total Steps: 50, Total Reward: -50\n",
            "Episode: 315, Total Steps: 50, Total Reward: -50\n",
            "Episode: 316, Total Steps: 50, Total Reward: -50\n",
            "Episode: 317, Total Steps: 50, Total Reward: -50\n",
            "Episode: 318, Total Steps: 50, Total Reward: -50\n",
            "Episode: 319, Total Steps: 50, Total Reward: -50\n",
            "Episode: 320, Total Steps: 50, Total Reward: -50\n",
            "Episode: 321, Total Steps: 50, Total Reward: -50\n",
            "Episode: 322, Total Steps: 50, Total Reward: -50\n",
            "Episode: 323, Total Steps: 50, Total Reward: -50\n",
            "Episode: 324, Total Steps: 50, Total Reward: -50\n",
            "Episode: 325, Total Steps: 50, Total Reward: -50\n",
            "Episode: 326, Total Steps: 50, Total Reward: -50\n",
            "Episode: 327, Total Steps: 50, Total Reward: -50\n",
            "Episode: 328, Total Steps: 50, Total Reward: -50\n",
            "Episode: 329, Total Steps: 50, Total Reward: -50\n",
            "Episode: 330, Total Steps: 50, Total Reward: -50\n",
            "Episode: 331, Total Steps: 50, Total Reward: -50\n",
            "Episode: 332, Total Steps: 50, Total Reward: -50\n",
            "Episode: 333, Total Steps: 50, Total Reward: -50\n",
            "Episode: 334, Total Steps: 50, Total Reward: -50\n",
            "Episode: 335, Total Steps: 50, Total Reward: -50\n",
            "Episode: 336, Total Steps: 50, Total Reward: -50\n",
            "Episode: 337, Total Steps: 50, Total Reward: -50\n",
            "Episode: 338, Total Steps: 50, Total Reward: -50\n",
            "Episode: 339, Total Steps: 50, Total Reward: -50\n",
            "Episode: 340, Total Steps: 50, Total Reward: -50\n",
            "Episode: 341, Total Steps: 50, Total Reward: -50\n",
            "Episode: 342, Total Steps: 50, Total Reward: -50\n",
            "Episode: 343, Total Steps: 50, Total Reward: -50\n",
            "Episode: 344, Total Steps: 50, Total Reward: -50\n",
            "Episode: 345, Total Steps: 50, Total Reward: -50\n",
            "Episode: 346, Total Steps: 50, Total Reward: -50\n",
            "Episode: 347, Total Steps: 50, Total Reward: -50\n",
            "Episode: 348, Total Steps: 50, Total Reward: -50\n",
            "Episode: 349, Total Steps: 50, Total Reward: -50\n",
            "Episode: 350, Total Steps: 50, Total Reward: -50\n",
            "Episode: 351, Total Steps: 50, Total Reward: -50\n",
            "Episode: 352, Total Steps: 50, Total Reward: -50\n",
            "Episode: 353, Total Steps: 50, Total Reward: -50\n",
            "Episode: 354, Total Steps: 50, Total Reward: -50\n",
            "Episode: 355, Total Steps: 50, Total Reward: -50\n",
            "Episode: 356, Total Steps: 50, Total Reward: -50\n",
            "Episode: 357, Total Steps: 50, Total Reward: -50\n",
            "Episode: 358, Total Steps: 50, Total Reward: -50\n",
            "Episode: 359, Total Steps: 50, Total Reward: -50\n",
            "Episode: 360, Total Steps: 50, Total Reward: -50\n",
            "Episode: 361, Total Steps: 50, Total Reward: -50\n",
            "Episode: 362, Total Steps: 50, Total Reward: -50\n",
            "Episode: 363, Total Steps: 50, Total Reward: -50\n",
            "Episode: 364, Total Steps: 50, Total Reward: -50\n",
            "Episode: 365, Total Steps: 50, Total Reward: -50\n",
            "Episode: 366, Total Steps: 50, Total Reward: -50\n",
            "Episode: 367, Total Steps: 50, Total Reward: -50\n",
            "Episode: 368, Total Steps: 50, Total Reward: -50\n",
            "Episode: 369, Total Steps: 50, Total Reward: -50\n",
            "Episode: 370, Total Steps: 50, Total Reward: -50\n",
            "Episode: 371, Total Steps: 50, Total Reward: -50\n",
            "Episode: 372, Total Steps: 50, Total Reward: -50\n",
            "Episode: 373, Total Steps: 50, Total Reward: -50\n",
            "Episode: 374, Total Steps: 50, Total Reward: -50\n",
            "Episode: 375, Total Steps: 50, Total Reward: -50\n",
            "Episode: 376, Total Steps: 50, Total Reward: -50\n",
            "Episode: 377, Total Steps: 50, Total Reward: -50\n",
            "Episode: 378, Total Steps: 50, Total Reward: -50\n",
            "Episode: 379, Total Steps: 50, Total Reward: -50\n",
            "Episode: 380, Total Steps: 50, Total Reward: -50\n",
            "Episode: 381, Total Steps: 50, Total Reward: -50\n",
            "Episode: 382, Total Steps: 50, Total Reward: -50\n",
            "Episode: 383, Total Steps: 50, Total Reward: -50\n",
            "Episode: 384, Total Steps: 50, Total Reward: -50\n",
            "Episode: 385, Total Steps: 50, Total Reward: -50\n",
            "Episode: 386, Total Steps: 50, Total Reward: -50\n",
            "Episode: 387, Total Steps: 50, Total Reward: -50\n",
            "Episode: 388, Total Steps: 50, Total Reward: -50\n",
            "Episode: 389, Total Steps: 50, Total Reward: -50\n",
            "Episode: 390, Total Steps: 50, Total Reward: -50\n",
            "Episode: 391, Total Steps: 50, Total Reward: -50\n",
            "Episode: 392, Total Steps: 50, Total Reward: -50\n",
            "Episode: 393, Total Steps: 50, Total Reward: -50\n",
            "Episode: 394, Total Steps: 50, Total Reward: -50\n",
            "Episode: 395, Total Steps: 50, Total Reward: -50\n",
            "Episode: 396, Total Steps: 50, Total Reward: -50\n",
            "Episode: 397, Total Steps: 50, Total Reward: -50\n",
            "Episode: 398, Total Steps: 50, Total Reward: -50\n",
            "Episode: 399, Total Steps: 50, Total Reward: -50\n",
            "Episode: 400, Total Steps: 50, Total Reward: -50\n",
            "Episode: 401, Total Steps: 50, Total Reward: -50\n",
            "Episode: 402, Total Steps: 50, Total Reward: -50\n",
            "Episode: 403, Total Steps: 50, Total Reward: -50\n",
            "Episode: 404, Total Steps: 50, Total Reward: -50\n",
            "Episode: 405, Total Steps: 50, Total Reward: -50\n",
            "Episode: 406, Total Steps: 50, Total Reward: -50\n",
            "Episode: 407, Total Steps: 50, Total Reward: -50\n",
            "Episode: 408, Total Steps: 50, Total Reward: -50\n",
            "Episode: 409, Total Steps: 50, Total Reward: -50\n",
            "Episode: 410, Total Steps: 50, Total Reward: -50\n",
            "Episode: 411, Total Steps: 50, Total Reward: -50\n",
            "Episode: 412, Total Steps: 50, Total Reward: -50\n",
            "Episode: 413, Total Steps: 50, Total Reward: -50\n",
            "Episode: 414, Total Steps: 50, Total Reward: -50\n",
            "Episode: 415, Total Steps: 50, Total Reward: -50\n",
            "Episode: 416, Total Steps: 50, Total Reward: -50\n",
            "Episode: 417, Total Steps: 50, Total Reward: -50\n",
            "Episode: 418, Total Steps: 50, Total Reward: -50\n",
            "Episode: 419, Total Steps: 50, Total Reward: -50\n",
            "Episode: 420, Total Steps: 50, Total Reward: -50\n",
            "Episode: 421, Total Steps: 50, Total Reward: -50\n",
            "Episode: 422, Total Steps: 50, Total Reward: -50\n",
            "Episode: 423, Total Steps: 50, Total Reward: -50\n",
            "Episode: 424, Total Steps: 50, Total Reward: -50\n",
            "Episode: 425, Total Steps: 50, Total Reward: -50\n",
            "Episode: 426, Total Steps: 50, Total Reward: -50\n",
            "Episode: 427, Total Steps: 50, Total Reward: -50\n",
            "Episode: 428, Total Steps: 50, Total Reward: -50\n",
            "Episode: 429, Total Steps: 50, Total Reward: -50\n",
            "Episode: 430, Total Steps: 50, Total Reward: -50\n",
            "Episode: 431, Total Steps: 50, Total Reward: -50\n",
            "Episode: 432, Total Steps: 50, Total Reward: -50\n",
            "Episode: 433, Total Steps: 50, Total Reward: -50\n",
            "Episode: 434, Total Steps: 50, Total Reward: -50\n",
            "Episode: 435, Total Steps: 50, Total Reward: -50\n",
            "Episode: 436, Total Steps: 50, Total Reward: -50\n",
            "Episode: 437, Total Steps: 50, Total Reward: -50\n",
            "Episode: 438, Total Steps: 50, Total Reward: -50\n",
            "Episode: 439, Total Steps: 50, Total Reward: -50\n",
            "Episode: 440, Total Steps: 50, Total Reward: -50\n",
            "Episode: 441, Total Steps: 50, Total Reward: -50\n",
            "Episode: 442, Total Steps: 50, Total Reward: -50\n",
            "Episode: 443, Total Steps: 50, Total Reward: -50\n",
            "Episode: 444, Total Steps: 50, Total Reward: -50\n",
            "Episode: 445, Total Steps: 50, Total Reward: -50\n",
            "Episode: 446, Total Steps: 50, Total Reward: -50\n",
            "Episode: 447, Total Steps: 50, Total Reward: -50\n",
            "Episode: 448, Total Steps: 50, Total Reward: -50\n",
            "Episode: 449, Total Steps: 50, Total Reward: -50\n",
            "Episode: 450, Total Steps: 50, Total Reward: -50\n",
            "Episode: 451, Total Steps: 50, Total Reward: -50\n",
            "Episode: 452, Total Steps: 50, Total Reward: -50\n",
            "Episode: 453, Total Steps: 50, Total Reward: -50\n",
            "Episode: 454, Total Steps: 50, Total Reward: -50\n",
            "Episode: 455, Total Steps: 50, Total Reward: -50\n",
            "Episode: 456, Total Steps: 50, Total Reward: -50\n",
            "Episode: 457, Total Steps: 50, Total Reward: -50\n",
            "Episode: 458, Total Steps: 50, Total Reward: -50\n",
            "Episode: 459, Total Steps: 50, Total Reward: -50\n",
            "Episode: 460, Total Steps: 50, Total Reward: -50\n",
            "Episode: 461, Total Steps: 50, Total Reward: -50\n",
            "Episode: 462, Total Steps: 50, Total Reward: -50\n",
            "Episode: 463, Total Steps: 50, Total Reward: -50\n",
            "Episode: 464, Total Steps: 50, Total Reward: -50\n",
            "Episode: 465, Total Steps: 50, Total Reward: -50\n",
            "Episode: 466, Total Steps: 50, Total Reward: -50\n",
            "Episode: 467, Total Steps: 50, Total Reward: -50\n",
            "Episode: 468, Total Steps: 50, Total Reward: -50\n",
            "Episode: 469, Total Steps: 50, Total Reward: -50\n",
            "Episode: 470, Total Steps: 50, Total Reward: -50\n",
            "Episode: 471, Total Steps: 50, Total Reward: -50\n",
            "Episode: 472, Total Steps: 50, Total Reward: -50\n",
            "Episode: 473, Total Steps: 50, Total Reward: -50\n",
            "Episode: 474, Total Steps: 50, Total Reward: -50\n",
            "Episode: 475, Total Steps: 50, Total Reward: -50\n",
            "Episode: 476, Total Steps: 50, Total Reward: -50\n",
            "Episode: 477, Total Steps: 50, Total Reward: -50\n",
            "Episode: 478, Total Steps: 50, Total Reward: -50\n",
            "Episode: 479, Total Steps: 50, Total Reward: -50\n",
            "Episode: 480, Total Steps: 50, Total Reward: -50\n",
            "Episode: 481, Total Steps: 50, Total Reward: -50\n",
            "Episode: 482, Total Steps: 50, Total Reward: -50\n",
            "Episode: 483, Total Steps: 50, Total Reward: -50\n",
            "Episode: 484, Total Steps: 50, Total Reward: -50\n",
            "Episode: 485, Total Steps: 50, Total Reward: -50\n",
            "Episode: 486, Total Steps: 50, Total Reward: -50\n",
            "Episode: 487, Total Steps: 50, Total Reward: -50\n",
            "Episode: 488, Total Steps: 50, Total Reward: -50\n",
            "Episode: 489, Total Steps: 50, Total Reward: -50\n",
            "Episode: 490, Total Steps: 50, Total Reward: -50\n",
            "Episode: 491, Total Steps: 50, Total Reward: -50\n",
            "Episode: 492, Total Steps: 50, Total Reward: -50\n",
            "Episode: 493, Total Steps: 50, Total Reward: -50\n",
            "Episode: 494, Total Steps: 50, Total Reward: -50\n",
            "Episode: 495, Total Steps: 50, Total Reward: -50\n",
            "Episode: 496, Total Steps: 50, Total Reward: -50\n",
            "Episode: 497, Total Steps: 50, Total Reward: -50\n",
            "Episode: 498, Total Steps: 50, Total Reward: -50\n",
            "Episode: 499, Total Steps: 50, Total Reward: -50\n",
            "Episode: 500, Total Steps: 50, Total Reward: -50\n",
            "Episode: 501, Total Steps: 50, Total Reward: -50\n",
            "Episode: 502, Total Steps: 50, Total Reward: -50\n",
            "Episode: 503, Total Steps: 50, Total Reward: -50\n",
            "Episode: 504, Total Steps: 50, Total Reward: -50\n",
            "Episode: 505, Total Steps: 50, Total Reward: -50\n",
            "Episode: 506, Total Steps: 50, Total Reward: -50\n",
            "Episode: 507, Total Steps: 50, Total Reward: -50\n",
            "Episode: 508, Total Steps: 50, Total Reward: -50\n",
            "Episode: 509, Total Steps: 50, Total Reward: -50\n",
            "Episode: 510, Total Steps: 50, Total Reward: -50\n",
            "Episode: 511, Total Steps: 50, Total Reward: -50\n",
            "Episode: 512, Total Steps: 50, Total Reward: -50\n",
            "Episode: 513, Total Steps: 50, Total Reward: -50\n",
            "Episode: 514, Total Steps: 50, Total Reward: -50\n",
            "Episode: 515, Total Steps: 50, Total Reward: -50\n",
            "Episode: 516, Total Steps: 50, Total Reward: -50\n",
            "Episode: 517, Total Steps: 50, Total Reward: -50\n",
            "Episode: 518, Total Steps: 50, Total Reward: -50\n",
            "Episode: 519, Total Steps: 50, Total Reward: -50\n",
            "Episode: 520, Total Steps: 50, Total Reward: -50\n",
            "Episode: 521, Total Steps: 50, Total Reward: -50\n",
            "Episode: 522, Total Steps: 50, Total Reward: -50\n",
            "Episode: 523, Total Steps: 50, Total Reward: -50\n",
            "Episode: 524, Total Steps: 50, Total Reward: -50\n",
            "Episode: 525, Total Steps: 50, Total Reward: -50\n",
            "Episode: 526, Total Steps: 50, Total Reward: -50\n",
            "Episode: 527, Total Steps: 50, Total Reward: -50\n",
            "Episode: 528, Total Steps: 50, Total Reward: -50\n",
            "Episode: 529, Total Steps: 50, Total Reward: -50\n",
            "Episode: 530, Total Steps: 50, Total Reward: -50\n",
            "Episode: 531, Total Steps: 50, Total Reward: -50\n",
            "Episode: 532, Total Steps: 50, Total Reward: -50\n",
            "Episode: 533, Total Steps: 50, Total Reward: -50\n",
            "Episode: 534, Total Steps: 50, Total Reward: -50\n",
            "Episode: 535, Total Steps: 50, Total Reward: -50\n",
            "Episode: 536, Total Steps: 50, Total Reward: -50\n",
            "Episode: 537, Total Steps: 50, Total Reward: -50\n",
            "Episode: 538, Total Steps: 50, Total Reward: -50\n",
            "Episode: 539, Total Steps: 50, Total Reward: -50\n",
            "Episode: 540, Total Steps: 50, Total Reward: -50\n",
            "Episode: 541, Total Steps: 50, Total Reward: -50\n",
            "Episode: 542, Total Steps: 50, Total Reward: -50\n",
            "Episode: 543, Total Steps: 50, Total Reward: -50\n",
            "Episode: 544, Total Steps: 50, Total Reward: -50\n",
            "Episode: 545, Total Steps: 50, Total Reward: -50\n",
            "Episode: 546, Total Steps: 50, Total Reward: -50\n",
            "Episode: 547, Total Steps: 50, Total Reward: -50\n",
            "Episode: 548, Total Steps: 50, Total Reward: -50\n",
            "Episode: 549, Total Steps: 50, Total Reward: -50\n",
            "Episode: 550, Total Steps: 50, Total Reward: -50\n",
            "Episode: 551, Total Steps: 50, Total Reward: -50\n",
            "Episode: 552, Total Steps: 50, Total Reward: -50\n",
            "Episode: 553, Total Steps: 50, Total Reward: -50\n",
            "Episode: 554, Total Steps: 50, Total Reward: -50\n",
            "Episode: 555, Total Steps: 50, Total Reward: -50\n",
            "Episode: 556, Total Steps: 50, Total Reward: -50\n",
            "Episode: 557, Total Steps: 50, Total Reward: -50\n",
            "Episode: 558, Total Steps: 50, Total Reward: -50\n",
            "Episode: 559, Total Steps: 50, Total Reward: -50\n",
            "Episode: 560, Total Steps: 50, Total Reward: -50\n",
            "Episode: 561, Total Steps: 50, Total Reward: -50\n",
            "Episode: 562, Total Steps: 50, Total Reward: -50\n",
            "Episode: 563, Total Steps: 50, Total Reward: -50\n",
            "Episode: 564, Total Steps: 50, Total Reward: -50\n",
            "Episode: 565, Total Steps: 50, Total Reward: -50\n",
            "Episode: 566, Total Steps: 50, Total Reward: -50\n",
            "Episode: 567, Total Steps: 50, Total Reward: -50\n",
            "Episode: 568, Total Steps: 50, Total Reward: -50\n",
            "Episode: 569, Total Steps: 50, Total Reward: -50\n",
            "Episode: 570, Total Steps: 50, Total Reward: -50\n",
            "Episode: 571, Total Steps: 50, Total Reward: -50\n",
            "Episode: 572, Total Steps: 50, Total Reward: -50\n",
            "Episode: 573, Total Steps: 50, Total Reward: -50\n",
            "Episode: 574, Total Steps: 50, Total Reward: -50\n",
            "Episode: 575, Total Steps: 50, Total Reward: -50\n",
            "Episode: 576, Total Steps: 50, Total Reward: -50\n",
            "Episode: 577, Total Steps: 50, Total Reward: -50\n",
            "Episode: 578, Total Steps: 50, Total Reward: -50\n",
            "Episode: 579, Total Steps: 50, Total Reward: -50\n",
            "Episode: 580, Total Steps: 50, Total Reward: -50\n",
            "Episode: 581, Total Steps: 50, Total Reward: -50\n",
            "Episode: 582, Total Steps: 50, Total Reward: -50\n",
            "Episode: 583, Total Steps: 50, Total Reward: -50\n",
            "Episode: 584, Total Steps: 50, Total Reward: -50\n",
            "Episode: 585, Total Steps: 50, Total Reward: -50\n",
            "Episode: 586, Total Steps: 50, Total Reward: -50\n",
            "Episode: 587, Total Steps: 50, Total Reward: -50\n",
            "Episode: 588, Total Steps: 50, Total Reward: -50\n",
            "Episode: 589, Total Steps: 50, Total Reward: -50\n",
            "Episode: 590, Total Steps: 50, Total Reward: -50\n",
            "Episode: 591, Total Steps: 50, Total Reward: -50\n",
            "Episode: 592, Total Steps: 50, Total Reward: -50\n",
            "Episode: 593, Total Steps: 50, Total Reward: -50\n",
            "Episode: 594, Total Steps: 50, Total Reward: -50\n",
            "Episode: 595, Total Steps: 50, Total Reward: -50\n",
            "Episode: 596, Total Steps: 50, Total Reward: -50\n",
            "Episode: 597, Total Steps: 50, Total Reward: -50\n",
            "Episode: 598, Total Steps: 50, Total Reward: -50\n",
            "Episode: 599, Total Steps: 50, Total Reward: -50\n",
            "Episode: 600, Total Steps: 50, Total Reward: -50\n",
            "Episode: 601, Total Steps: 50, Total Reward: -50\n",
            "Episode: 602, Total Steps: 50, Total Reward: -50\n",
            "Episode: 603, Total Steps: 50, Total Reward: -50\n",
            "Episode: 604, Total Steps: 50, Total Reward: -50\n",
            "Episode: 605, Total Steps: 50, Total Reward: -50\n",
            "Episode: 606, Total Steps: 50, Total Reward: -50\n",
            "Episode: 607, Total Steps: 50, Total Reward: -50\n",
            "Episode: 608, Total Steps: 50, Total Reward: -50\n",
            "Episode: 609, Total Steps: 50, Total Reward: -50\n",
            "Episode: 610, Total Steps: 50, Total Reward: -50\n",
            "Episode: 611, Total Steps: 50, Total Reward: -50\n",
            "Episode: 612, Total Steps: 50, Total Reward: -50\n",
            "Episode: 613, Total Steps: 50, Total Reward: -50\n",
            "Episode: 614, Total Steps: 50, Total Reward: -50\n",
            "Episode: 615, Total Steps: 50, Total Reward: -50\n",
            "Episode: 616, Total Steps: 50, Total Reward: -50\n",
            "Episode: 617, Total Steps: 50, Total Reward: -50\n",
            "Episode: 618, Total Steps: 50, Total Reward: -50\n",
            "Episode: 619, Total Steps: 50, Total Reward: -50\n",
            "Episode: 620, Total Steps: 50, Total Reward: -50\n",
            "Episode: 621, Total Steps: 50, Total Reward: -50\n",
            "Episode: 622, Total Steps: 50, Total Reward: -50\n",
            "Episode: 623, Total Steps: 50, Total Reward: -50\n",
            "Episode: 624, Total Steps: 50, Total Reward: -50\n",
            "Episode: 625, Total Steps: 50, Total Reward: -50\n",
            "Episode: 626, Total Steps: 50, Total Reward: -50\n",
            "Episode: 627, Total Steps: 50, Total Reward: -50\n",
            "Episode: 628, Total Steps: 50, Total Reward: -50\n",
            "Episode: 629, Total Steps: 50, Total Reward: -50\n",
            "Episode: 630, Total Steps: 50, Total Reward: -50\n",
            "Episode: 631, Total Steps: 50, Total Reward: -50\n",
            "Episode: 632, Total Steps: 50, Total Reward: -50\n",
            "Episode: 633, Total Steps: 50, Total Reward: -50\n",
            "Episode: 634, Total Steps: 50, Total Reward: -50\n",
            "Episode: 635, Total Steps: 50, Total Reward: -50\n",
            "Episode: 636, Total Steps: 50, Total Reward: -50\n",
            "Episode: 637, Total Steps: 50, Total Reward: -50\n",
            "Episode: 638, Total Steps: 50, Total Reward: -50\n",
            "Episode: 639, Total Steps: 50, Total Reward: -50\n",
            "Episode: 640, Total Steps: 50, Total Reward: -50\n",
            "Episode: 641, Total Steps: 50, Total Reward: -50\n",
            "Episode: 642, Total Steps: 50, Total Reward: -50\n",
            "Episode: 643, Total Steps: 50, Total Reward: -50\n",
            "Episode: 644, Total Steps: 50, Total Reward: -50\n",
            "Episode: 645, Total Steps: 50, Total Reward: -50\n",
            "Episode: 646, Total Steps: 50, Total Reward: -50\n",
            "Episode: 647, Total Steps: 50, Total Reward: -50\n",
            "Episode: 648, Total Steps: 50, Total Reward: -50\n",
            "Episode: 649, Total Steps: 50, Total Reward: -50\n",
            "Episode: 650, Total Steps: 50, Total Reward: -50\n",
            "Episode: 651, Total Steps: 50, Total Reward: -50\n",
            "Episode: 652, Total Steps: 50, Total Reward: -50\n",
            "Episode: 653, Total Steps: 50, Total Reward: -50\n",
            "Episode: 654, Total Steps: 50, Total Reward: -50\n",
            "Episode: 655, Total Steps: 50, Total Reward: -50\n",
            "Episode: 656, Total Steps: 50, Total Reward: -50\n",
            "Episode: 657, Total Steps: 50, Total Reward: -50\n",
            "Episode: 658, Total Steps: 50, Total Reward: -50\n",
            "Episode: 659, Total Steps: 50, Total Reward: -50\n",
            "Episode: 660, Total Steps: 50, Total Reward: -50\n",
            "Episode: 661, Total Steps: 50, Total Reward: -50\n",
            "Episode: 662, Total Steps: 50, Total Reward: -50\n",
            "Episode: 663, Total Steps: 50, Total Reward: -50\n",
            "Episode: 664, Total Steps: 50, Total Reward: -50\n",
            "Episode: 665, Total Steps: 50, Total Reward: -50\n",
            "Episode: 666, Total Steps: 50, Total Reward: -50\n",
            "Episode: 667, Total Steps: 50, Total Reward: -50\n",
            "Episode: 668, Total Steps: 50, Total Reward: -50\n",
            "Episode: 669, Total Steps: 50, Total Reward: -50\n",
            "Episode: 670, Total Steps: 50, Total Reward: -50\n",
            "Episode: 671, Total Steps: 50, Total Reward: -50\n",
            "Episode: 672, Total Steps: 50, Total Reward: -50\n",
            "Episode: 673, Total Steps: 50, Total Reward: -50\n",
            "Episode: 674, Total Steps: 50, Total Reward: -50\n",
            "Episode: 675, Total Steps: 50, Total Reward: -50\n",
            "Episode: 676, Total Steps: 50, Total Reward: -50\n",
            "Episode: 677, Total Steps: 50, Total Reward: -50\n",
            "Episode: 678, Total Steps: 50, Total Reward: -50\n",
            "Episode: 679, Total Steps: 50, Total Reward: -50\n",
            "Episode: 680, Total Steps: 50, Total Reward: -50\n",
            "Episode: 681, Total Steps: 50, Total Reward: -50\n",
            "Episode: 682, Total Steps: 50, Total Reward: -50\n",
            "Episode: 683, Total Steps: 50, Total Reward: -50\n",
            "Episode: 684, Total Steps: 50, Total Reward: -50\n",
            "Episode: 685, Total Steps: 50, Total Reward: -50\n",
            "Episode: 686, Total Steps: 50, Total Reward: -50\n",
            "Episode: 687, Total Steps: 50, Total Reward: -50\n",
            "Episode: 688, Total Steps: 50, Total Reward: -50\n",
            "Episode: 689, Total Steps: 50, Total Reward: -50\n",
            "Episode: 690, Total Steps: 50, Total Reward: -50\n",
            "Episode: 691, Total Steps: 50, Total Reward: -50\n",
            "Episode: 692, Total Steps: 50, Total Reward: -50\n",
            "Episode: 693, Total Steps: 50, Total Reward: -50\n",
            "Episode: 694, Total Steps: 50, Total Reward: -50\n",
            "Episode: 695, Total Steps: 50, Total Reward: -50\n",
            "Episode: 696, Total Steps: 50, Total Reward: -50\n",
            "Episode: 697, Total Steps: 50, Total Reward: -50\n",
            "Episode: 698, Total Steps: 50, Total Reward: -50\n",
            "Episode: 699, Total Steps: 50, Total Reward: -50\n",
            "Episode: 700, Total Steps: 50, Total Reward: -50\n",
            "Episode: 701, Total Steps: 50, Total Reward: -50\n",
            "Episode: 702, Total Steps: 50, Total Reward: -50\n",
            "Episode: 703, Total Steps: 50, Total Reward: -50\n",
            "Episode: 704, Total Steps: 50, Total Reward: -50\n",
            "Episode: 705, Total Steps: 50, Total Reward: -50\n",
            "Episode: 706, Total Steps: 50, Total Reward: -50\n",
            "Episode: 707, Total Steps: 50, Total Reward: -50\n",
            "Episode: 708, Total Steps: 50, Total Reward: -50\n",
            "Episode: 709, Total Steps: 50, Total Reward: -50\n",
            "Episode: 710, Total Steps: 50, Total Reward: -50\n",
            "Episode: 711, Total Steps: 50, Total Reward: -50\n",
            "Episode: 712, Total Steps: 50, Total Reward: -50\n",
            "Episode: 713, Total Steps: 50, Total Reward: -50\n",
            "Episode: 714, Total Steps: 50, Total Reward: -50\n",
            "Episode: 715, Total Steps: 50, Total Reward: -50\n",
            "Episode: 716, Total Steps: 50, Total Reward: -50\n",
            "Episode: 717, Total Steps: 50, Total Reward: -50\n",
            "Episode: 718, Total Steps: 50, Total Reward: -50\n",
            "Episode: 719, Total Steps: 50, Total Reward: -50\n",
            "Episode: 720, Total Steps: 50, Total Reward: -50\n",
            "Episode: 721, Total Steps: 50, Total Reward: -50\n",
            "Episode: 722, Total Steps: 50, Total Reward: -50\n",
            "Episode: 723, Total Steps: 50, Total Reward: -50\n",
            "Episode: 724, Total Steps: 50, Total Reward: -50\n",
            "Episode: 725, Total Steps: 50, Total Reward: -50\n",
            "Episode: 726, Total Steps: 50, Total Reward: -50\n",
            "Episode: 727, Total Steps: 50, Total Reward: -50\n",
            "Episode: 728, Total Steps: 50, Total Reward: -50\n",
            "Episode: 729, Total Steps: 50, Total Reward: -50\n",
            "Episode: 730, Total Steps: 50, Total Reward: -50\n",
            "Episode: 731, Total Steps: 50, Total Reward: -50\n",
            "Episode: 732, Total Steps: 50, Total Reward: -50\n",
            "Episode: 733, Total Steps: 50, Total Reward: -50\n",
            "Episode: 734, Total Steps: 50, Total Reward: -50\n",
            "Episode: 735, Total Steps: 50, Total Reward: -50\n",
            "Episode: 736, Total Steps: 50, Total Reward: -50\n",
            "Episode: 737, Total Steps: 50, Total Reward: -50\n",
            "Episode: 738, Total Steps: 50, Total Reward: -50\n",
            "Episode: 739, Total Steps: 50, Total Reward: -50\n",
            "Episode: 740, Total Steps: 50, Total Reward: -50\n",
            "Episode: 741, Total Steps: 50, Total Reward: -50\n",
            "Episode: 742, Total Steps: 50, Total Reward: -50\n",
            "Episode: 743, Total Steps: 50, Total Reward: -50\n",
            "Episode: 744, Total Steps: 50, Total Reward: -50\n",
            "Episode: 745, Total Steps: 50, Total Reward: -50\n",
            "Episode: 746, Total Steps: 50, Total Reward: -50\n",
            "Episode: 747, Total Steps: 50, Total Reward: -50\n",
            "Episode: 748, Total Steps: 50, Total Reward: -50\n",
            "Episode: 749, Total Steps: 50, Total Reward: -50\n",
            "Episode: 750, Total Steps: 50, Total Reward: -50\n",
            "Episode: 751, Total Steps: 50, Total Reward: -50\n",
            "Episode: 752, Total Steps: 50, Total Reward: -50\n",
            "Episode: 753, Total Steps: 50, Total Reward: -50\n",
            "Episode: 754, Total Steps: 50, Total Reward: -50\n",
            "Episode: 755, Total Steps: 50, Total Reward: -50\n",
            "Episode: 756, Total Steps: 50, Total Reward: -50\n",
            "Episode: 757, Total Steps: 50, Total Reward: -50\n",
            "Episode: 758, Total Steps: 50, Total Reward: -50\n",
            "Episode: 759, Total Steps: 50, Total Reward: -50\n",
            "Episode: 760, Total Steps: 50, Total Reward: -50\n",
            "Episode: 761, Total Steps: 50, Total Reward: -50\n",
            "Episode: 762, Total Steps: 50, Total Reward: -50\n",
            "Episode: 763, Total Steps: 50, Total Reward: -50\n",
            "Episode: 764, Total Steps: 50, Total Reward: -50\n",
            "Episode: 765, Total Steps: 50, Total Reward: -50\n",
            "Episode: 766, Total Steps: 50, Total Reward: -50\n",
            "Episode: 767, Total Steps: 50, Total Reward: -50\n",
            "Episode: 768, Total Steps: 50, Total Reward: -50\n",
            "Episode: 769, Total Steps: 50, Total Reward: -50\n",
            "Episode: 770, Total Steps: 50, Total Reward: -50\n",
            "Episode: 771, Total Steps: 50, Total Reward: -50\n",
            "Episode: 772, Total Steps: 50, Total Reward: -50\n",
            "Episode: 773, Total Steps: 50, Total Reward: -50\n",
            "Episode: 774, Total Steps: 50, Total Reward: -50\n",
            "Episode: 775, Total Steps: 50, Total Reward: -50\n",
            "Episode: 776, Total Steps: 50, Total Reward: -50\n",
            "Episode: 777, Total Steps: 50, Total Reward: -50\n",
            "Episode: 778, Total Steps: 50, Total Reward: -50\n",
            "Episode: 779, Total Steps: 50, Total Reward: -50\n",
            "Episode: 780, Total Steps: 50, Total Reward: -50\n",
            "Episode: 781, Total Steps: 50, Total Reward: -50\n",
            "Episode: 782, Total Steps: 50, Total Reward: -50\n",
            "Episode: 783, Total Steps: 50, Total Reward: -50\n",
            "Episode: 784, Total Steps: 50, Total Reward: -50\n",
            "Episode: 785, Total Steps: 50, Total Reward: -50\n",
            "Episode: 786, Total Steps: 50, Total Reward: -50\n",
            "Episode: 787, Total Steps: 50, Total Reward: -50\n",
            "Episode: 788, Total Steps: 50, Total Reward: -50\n",
            "Episode: 789, Total Steps: 50, Total Reward: -50\n",
            "Episode: 790, Total Steps: 50, Total Reward: -50\n",
            "Episode: 791, Total Steps: 50, Total Reward: -50\n",
            "Episode: 792, Total Steps: 50, Total Reward: -50\n",
            "Episode: 793, Total Steps: 50, Total Reward: -50\n",
            "Episode: 794, Total Steps: 50, Total Reward: -50\n",
            "Episode: 795, Total Steps: 50, Total Reward: -50\n",
            "Episode: 796, Total Steps: 50, Total Reward: -50\n",
            "Episode: 797, Total Steps: 50, Total Reward: -50\n",
            "Episode: 798, Total Steps: 50, Total Reward: -50\n",
            "Episode: 799, Total Steps: 50, Total Reward: -50\n",
            "Episode: 800, Total Steps: 50, Total Reward: -50\n",
            "Episode: 801, Total Steps: 50, Total Reward: -50\n",
            "Episode: 802, Total Steps: 50, Total Reward: -50\n",
            "Episode: 803, Total Steps: 50, Total Reward: -50\n",
            "Episode: 804, Total Steps: 50, Total Reward: -50\n",
            "Episode: 805, Total Steps: 50, Total Reward: -50\n",
            "Episode: 806, Total Steps: 50, Total Reward: -50\n",
            "Episode: 807, Total Steps: 50, Total Reward: -50\n",
            "Episode: 808, Total Steps: 50, Total Reward: -50\n",
            "Episode: 809, Total Steps: 50, Total Reward: -50\n",
            "Episode: 810, Total Steps: 50, Total Reward: -50\n",
            "Episode: 811, Total Steps: 50, Total Reward: -50\n",
            "Episode: 812, Total Steps: 50, Total Reward: -50\n",
            "Episode: 813, Total Steps: 50, Total Reward: -50\n",
            "Episode: 814, Total Steps: 50, Total Reward: -50\n",
            "Episode: 815, Total Steps: 50, Total Reward: -50\n",
            "Episode: 816, Total Steps: 50, Total Reward: -50\n",
            "Episode: 817, Total Steps: 50, Total Reward: -50\n",
            "Episode: 818, Total Steps: 50, Total Reward: -50\n",
            "Episode: 819, Total Steps: 50, Total Reward: -50\n",
            "Episode: 820, Total Steps: 50, Total Reward: -50\n",
            "Episode: 821, Total Steps: 50, Total Reward: -50\n",
            "Episode: 822, Total Steps: 50, Total Reward: -50\n",
            "Episode: 823, Total Steps: 50, Total Reward: -50\n",
            "Episode: 824, Total Steps: 50, Total Reward: -50\n",
            "Episode: 825, Total Steps: 50, Total Reward: -50\n",
            "Episode: 826, Total Steps: 50, Total Reward: -50\n",
            "Episode: 827, Total Steps: 50, Total Reward: -50\n",
            "Episode: 828, Total Steps: 50, Total Reward: -50\n",
            "Episode: 829, Total Steps: 50, Total Reward: -50\n",
            "Episode: 830, Total Steps: 50, Total Reward: -50\n",
            "Episode: 831, Total Steps: 50, Total Reward: -50\n",
            "Episode: 832, Total Steps: 50, Total Reward: -50\n",
            "Episode: 833, Total Steps: 50, Total Reward: -50\n",
            "Episode: 834, Total Steps: 50, Total Reward: -50\n",
            "Episode: 835, Total Steps: 50, Total Reward: -50\n",
            "Episode: 836, Total Steps: 50, Total Reward: -50\n",
            "Episode: 837, Total Steps: 50, Total Reward: -50\n",
            "Episode: 838, Total Steps: 50, Total Reward: -50\n",
            "Episode: 839, Total Steps: 50, Total Reward: -50\n",
            "Episode: 840, Total Steps: 50, Total Reward: -50\n",
            "Episode: 841, Total Steps: 50, Total Reward: -50\n",
            "Episode: 842, Total Steps: 50, Total Reward: -50\n",
            "Episode: 843, Total Steps: 50, Total Reward: -50\n",
            "Episode: 844, Total Steps: 50, Total Reward: -50\n",
            "Episode: 845, Total Steps: 50, Total Reward: -50\n",
            "Episode: 846, Total Steps: 50, Total Reward: -50\n",
            "Episode: 847, Total Steps: 50, Total Reward: -50\n",
            "Episode: 848, Total Steps: 50, Total Reward: -50\n",
            "Episode: 849, Total Steps: 50, Total Reward: -50\n",
            "Episode: 850, Total Steps: 50, Total Reward: -50\n",
            "Episode: 851, Total Steps: 50, Total Reward: -50\n",
            "Episode: 852, Total Steps: 50, Total Reward: -50\n",
            "Episode: 853, Total Steps: 50, Total Reward: -50\n",
            "Episode: 854, Total Steps: 50, Total Reward: -50\n",
            "Episode: 855, Total Steps: 50, Total Reward: -50\n",
            "Episode: 856, Total Steps: 50, Total Reward: -50\n",
            "Episode: 857, Total Steps: 50, Total Reward: -50\n",
            "Episode: 858, Total Steps: 50, Total Reward: -50\n",
            "Episode: 859, Total Steps: 50, Total Reward: -50\n",
            "Episode: 860, Total Steps: 50, Total Reward: -50\n",
            "Episode: 861, Total Steps: 50, Total Reward: -50\n",
            "Episode: 862, Total Steps: 50, Total Reward: -50\n",
            "Episode: 863, Total Steps: 50, Total Reward: -50\n",
            "Episode: 864, Total Steps: 50, Total Reward: -50\n",
            "Episode: 865, Total Steps: 50, Total Reward: -50\n",
            "Episode: 866, Total Steps: 50, Total Reward: -50\n",
            "Episode: 867, Total Steps: 50, Total Reward: -50\n",
            "Episode: 868, Total Steps: 50, Total Reward: -50\n",
            "Episode: 869, Total Steps: 50, Total Reward: -50\n",
            "Episode: 870, Total Steps: 50, Total Reward: -50\n",
            "Episode: 871, Total Steps: 50, Total Reward: -50\n",
            "Episode: 872, Total Steps: 50, Total Reward: -50\n",
            "Episode: 873, Total Steps: 50, Total Reward: -50\n",
            "Episode: 874, Total Steps: 50, Total Reward: -50\n",
            "Episode: 875, Total Steps: 50, Total Reward: -50\n",
            "Episode: 876, Total Steps: 50, Total Reward: -50\n",
            "Episode: 877, Total Steps: 50, Total Reward: -50\n",
            "Episode: 878, Total Steps: 50, Total Reward: -50\n",
            "Episode: 879, Total Steps: 50, Total Reward: -50\n",
            "Episode: 880, Total Steps: 50, Total Reward: -50\n",
            "Episode: 881, Total Steps: 50, Total Reward: -50\n",
            "Episode: 882, Total Steps: 50, Total Reward: -50\n",
            "Episode: 883, Total Steps: 50, Total Reward: -50\n",
            "Episode: 884, Total Steps: 50, Total Reward: -50\n",
            "Episode: 885, Total Steps: 50, Total Reward: -50\n",
            "Episode: 886, Total Steps: 50, Total Reward: -50\n",
            "Episode: 887, Total Steps: 50, Total Reward: -50\n",
            "Episode: 888, Total Steps: 50, Total Reward: -50\n",
            "Episode: 889, Total Steps: 50, Total Reward: -50\n",
            "Episode: 890, Total Steps: 50, Total Reward: -50\n",
            "Episode: 891, Total Steps: 50, Total Reward: -50\n",
            "Episode: 892, Total Steps: 50, Total Reward: -50\n",
            "Episode: 893, Total Steps: 50, Total Reward: -50\n",
            "Episode: 894, Total Steps: 50, Total Reward: -50\n",
            "Episode: 895, Total Steps: 50, Total Reward: -50\n",
            "Episode: 896, Total Steps: 50, Total Reward: -50\n",
            "Episode: 897, Total Steps: 50, Total Reward: -50\n",
            "Episode: 898, Total Steps: 50, Total Reward: -50\n",
            "Episode: 899, Total Steps: 50, Total Reward: -50\n",
            "Episode: 900, Total Steps: 50, Total Reward: -50\n",
            "Episode: 901, Total Steps: 50, Total Reward: -50\n",
            "Episode: 902, Total Steps: 50, Total Reward: -50\n",
            "Episode: 903, Total Steps: 50, Total Reward: -50\n",
            "Episode: 904, Total Steps: 50, Total Reward: -50\n",
            "Episode: 905, Total Steps: 50, Total Reward: -50\n",
            "Episode: 906, Total Steps: 50, Total Reward: -50\n",
            "Episode: 907, Total Steps: 50, Total Reward: -50\n",
            "Episode: 908, Total Steps: 50, Total Reward: -50\n",
            "Episode: 909, Total Steps: 50, Total Reward: -50\n",
            "Episode: 910, Total Steps: 50, Total Reward: -50\n",
            "Episode: 911, Total Steps: 50, Total Reward: -50\n",
            "Episode: 912, Total Steps: 50, Total Reward: -50\n",
            "Episode: 913, Total Steps: 50, Total Reward: -50\n",
            "Episode: 914, Total Steps: 50, Total Reward: -50\n",
            "Episode: 915, Total Steps: 50, Total Reward: -50\n",
            "Episode: 916, Total Steps: 50, Total Reward: -50\n",
            "Episode: 917, Total Steps: 50, Total Reward: -50\n",
            "Episode: 918, Total Steps: 50, Total Reward: -50\n",
            "Episode: 919, Total Steps: 50, Total Reward: -50\n",
            "Episode: 920, Total Steps: 50, Total Reward: -50\n",
            "Episode: 921, Total Steps: 50, Total Reward: -50\n",
            "Episode: 922, Total Steps: 50, Total Reward: -50\n",
            "Episode: 923, Total Steps: 50, Total Reward: -50\n",
            "Episode: 924, Total Steps: 50, Total Reward: -50\n",
            "Episode: 925, Total Steps: 50, Total Reward: -50\n",
            "Episode: 926, Total Steps: 50, Total Reward: -50\n",
            "Episode: 927, Total Steps: 50, Total Reward: -50\n",
            "Episode: 928, Total Steps: 50, Total Reward: -50\n",
            "Episode: 929, Total Steps: 50, Total Reward: -50\n",
            "Episode: 930, Total Steps: 50, Total Reward: -50\n",
            "Episode: 931, Total Steps: 50, Total Reward: -50\n",
            "Episode: 932, Total Steps: 50, Total Reward: -50\n",
            "Episode: 933, Total Steps: 50, Total Reward: -50\n",
            "Episode: 934, Total Steps: 50, Total Reward: -50\n",
            "Episode: 935, Total Steps: 50, Total Reward: -50\n",
            "Episode: 936, Total Steps: 50, Total Reward: -50\n",
            "Episode: 937, Total Steps: 50, Total Reward: -50\n",
            "Episode: 938, Total Steps: 50, Total Reward: -50\n",
            "Episode: 939, Total Steps: 50, Total Reward: -50\n",
            "Episode: 940, Total Steps: 50, Total Reward: -50\n",
            "Episode: 941, Total Steps: 50, Total Reward: -50\n",
            "Episode: 942, Total Steps: 50, Total Reward: -50\n",
            "Episode: 943, Total Steps: 50, Total Reward: -50\n",
            "Episode: 944, Total Steps: 50, Total Reward: -50\n",
            "Episode: 945, Total Steps: 50, Total Reward: -50\n",
            "Episode: 946, Total Steps: 50, Total Reward: -50\n",
            "Episode: 947, Total Steps: 50, Total Reward: -50\n",
            "Episode: 948, Total Steps: 50, Total Reward: -50\n",
            "Episode: 949, Total Steps: 50, Total Reward: -50\n",
            "Episode: 950, Total Steps: 50, Total Reward: -50\n",
            "Episode: 951, Total Steps: 50, Total Reward: -50\n",
            "Episode: 952, Total Steps: 50, Total Reward: -50\n",
            "Episode: 953, Total Steps: 50, Total Reward: -50\n",
            "Episode: 954, Total Steps: 50, Total Reward: -50\n",
            "Episode: 955, Total Steps: 50, Total Reward: -50\n",
            "Episode: 956, Total Steps: 50, Total Reward: -50\n",
            "Episode: 957, Total Steps: 50, Total Reward: -50\n",
            "Episode: 958, Total Steps: 50, Total Reward: -50\n",
            "Episode: 959, Total Steps: 50, Total Reward: -50\n",
            "Episode: 960, Total Steps: 50, Total Reward: -50\n",
            "Episode: 961, Total Steps: 50, Total Reward: -50\n",
            "Episode: 962, Total Steps: 50, Total Reward: -50\n",
            "Episode: 963, Total Steps: 50, Total Reward: -50\n",
            "Episode: 964, Total Steps: 50, Total Reward: -50\n",
            "Episode: 965, Total Steps: 50, Total Reward: -50\n",
            "Episode: 966, Total Steps: 50, Total Reward: -50\n",
            "Episode: 967, Total Steps: 50, Total Reward: -50\n",
            "Episode: 968, Total Steps: 50, Total Reward: -50\n",
            "Episode: 969, Total Steps: 50, Total Reward: -50\n",
            "Episode: 970, Total Steps: 50, Total Reward: -50\n",
            "Episode: 971, Total Steps: 50, Total Reward: -50\n",
            "Episode: 972, Total Steps: 50, Total Reward: -50\n",
            "Episode: 973, Total Steps: 50, Total Reward: -50\n",
            "Episode: 974, Total Steps: 50, Total Reward: -50\n",
            "Episode: 975, Total Steps: 50, Total Reward: -50\n",
            "Episode: 976, Total Steps: 50, Total Reward: -50\n",
            "Episode: 977, Total Steps: 50, Total Reward: -50\n",
            "Episode: 978, Total Steps: 50, Total Reward: -50\n",
            "Episode: 979, Total Steps: 50, Total Reward: -50\n",
            "Episode: 980, Total Steps: 50, Total Reward: -50\n",
            "Episode: 981, Total Steps: 50, Total Reward: -50\n",
            "Episode: 982, Total Steps: 50, Total Reward: -50\n",
            "Episode: 983, Total Steps: 50, Total Reward: -50\n",
            "Episode: 984, Total Steps: 50, Total Reward: -50\n",
            "Episode: 985, Total Steps: 50, Total Reward: -50\n",
            "Episode: 986, Total Steps: 50, Total Reward: -50\n",
            "Episode: 987, Total Steps: 50, Total Reward: -50\n",
            "Episode: 988, Total Steps: 50, Total Reward: -50\n",
            "Episode: 989, Total Steps: 50, Total Reward: -50\n",
            "Episode: 990, Total Steps: 50, Total Reward: -50\n",
            "Episode: 991, Total Steps: 50, Total Reward: -50\n",
            "Episode: 992, Total Steps: 50, Total Reward: -50\n",
            "Episode: 993, Total Steps: 50, Total Reward: -50\n",
            "Episode: 994, Total Steps: 50, Total Reward: -50\n",
            "Episode: 995, Total Steps: 50, Total Reward: -50\n",
            "Episode: 996, Total Steps: 50, Total Reward: -50\n",
            "Episode: 997, Total Steps: 50, Total Reward: -50\n",
            "Episode: 998, Total Steps: 50, Total Reward: -50\n",
            "Episode: 999, Total Steps: 50, Total Reward: -50\n",
            "Episode: 1000, Total Steps: 50, Total Reward: -50\n",
            "First Episode Path\n",
            "S              \n",
            "               \n",
            "               \n",
            "               \n",
            "               \n",
            "               \n",
            "               \n",
            "              G\n",
            "\n",
            "Last Episode Path\n",
            "S              \n",
            "               \n",
            "               \n",
            "               \n",
            "               \n",
            "               \n",
            "               \n",
            "              G\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install Stable Baseline 3\n",
        "!pip install stable-baselines3[extra]\n",
        "\n",
        "# Import packages\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import DQN\n",
        "\n",
        "class GridWorldEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        # Initialize the GridWorld environment\n",
        "        super(GridWorldEnv, self).__init__()\n",
        "        self.grid_size = 8  # Define the size of the grid\n",
        "        self.action_space = spaces.Discrete(4)  # Define the action space: 4 possible actions\n",
        "        self.observation_space = spaces.Box(low=0, high=self.grid_size-1, shape=(2,), dtype=np.int32)  # Define the observation space\n",
        "        self.maze = [\n",
        "            [0, 0, 1, 1, 1, 0, 0, 0],\n",
        "            [0, 1, 1, 0, 1, 0, 1, 1],\n",
        "            [0, 1, 0, 0, 1, 1, 1, 0],\n",
        "            [0, 0, 0, 1, 1, 0, 0, 0],\n",
        "            [1, 1, 0, 1, 0, 0, 1, 1],\n",
        "            [0, 0, 0, 1, 0, 1, 1, 0],\n",
        "            [0, 1, 1, 1, 0, 0, 1, 0],\n",
        "            [0, 0, 0, 1, 1, 1, 0, 0]\n",
        "        ]  # 1 represents walls, 0 represents free space\n",
        "        self.reset()  # Reset the environment\n",
        "\n",
        "    def step(self, action):\n",
        "        # Execute the action\n",
        "        if action == 0:\n",
        "            self.move_left()\n",
        "        elif action == 1:\n",
        "            self.move_up()\n",
        "        elif action == 2:\n",
        "            self.move_right()\n",
        "        elif action == 3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1 # Reward is -1 if the agent moves\n",
        "        done = self.is_done()  # Check if the episode is done\n",
        "        return np.array([self.x, self.y], dtype=np.int32), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the agent's position to the start\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        return np.array([self.x, self.y], dtype=np.int32)\n",
        "\n",
        "    def move_right(self):\n",
        "        # Move the agent to the right\n",
        "        if self.y < self.grid_size - 1 and self.maze[self.x][self.y + 1] == 0:\n",
        "            self.y += 1\n",
        "\n",
        "    def move_left(self):\n",
        "        # Move the agent to the left\n",
        "        if self.y > 0 and self.maze[self.x][self.y - 1] == 0:\n",
        "            self.y -= 1\n",
        "\n",
        "    def move_up(self):\n",
        "        # Move the agent up\n",
        "        if self.x > 0 and self.maze[self.x - 1][self.y] == 0:\n",
        "            self.x -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        # Move the agent down\n",
        "        if self.x < self.grid_size - 1 and self.maze[self.x + 1][self.y] == 0:\n",
        "            self.x += 1\n",
        "\n",
        "    def is_done(self):\n",
        "        # Check if the agent has reached the goal\n",
        "        return self.x == self.grid_size - 1 and self.y == self.grid_size - 1\n",
        "\n",
        "# Initialize the GridWorld environment\n",
        "env = GridWorldEnv()\n",
        "\n",
        "# Build a DQN model\n",
        "model = DQN('MlpPolicy', env, verbose=0, exploration_fraction=0.5, exploration_final_eps=0.01, learning_rate=0.01)\n",
        "\n",
        "# Train the DQN agent\n",
        "episode_rewards = []  # List to store rewards for each episode\n",
        "first_episode_path = []  # List to store the path of the first episode\n",
        "last_episode_path = []  # List to store the path of the last episode\n",
        "\n",
        "max_steps_per_episode = 50  # Maximum number of steps per episode\n",
        "num_episodes = 1000  # Total number of episodes\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    obs = env.reset()  # Reset the environment at the start of each episode\n",
        "    total_rewards = 0  # Initialize total rewards for the episode\n",
        "    done = False  # Initialize the done flag\n",
        "    action_count = 0  # Initialize action count for the episode\n",
        "    episode_path = [tuple(obs)]  # Initialize the path for the episode\n",
        "\n",
        "    while not done and action_count < max_steps_per_episode:\n",
        "        action, _ = model.predict(obs, deterministic=False)  # Predict the next action using the DQN model\n",
        "        obs, reward, done, _ = env.step(action)  # Execute the action in the environment\n",
        "        total_rewards += reward  # Accumulate the reward\n",
        "        action_count += 1  # Increment the action count\n",
        "        episode_path.append(tuple(obs))  # Append the current position to the path\n",
        "    print(f\"Episode: {episode + 1}, Total Steps: {action_count}, Total Reward: {total_rewards}\")\n",
        "\n",
        "    # Store total rewards per episode\n",
        "    episode_rewards.append(total_rewards)\n",
        "\n",
        "    # Store the path of the first episode\n",
        "    if episode == 0:\n",
        "        first_episode_path = episode_path\n",
        "\n",
        "    # Store the path of the last episode\n",
        "    if episode == num_episodes - 1:\n",
        "        last_episode_path = episode_path\n",
        "\n",
        "    # Update the model after each episode\n",
        "    model.learn(total_timesteps=200)\n",
        "\n",
        "# Function to visualize the path of an episode\n",
        "def plot_episode_path(path, title):\n",
        "    grid = [[' ' for _ in range(env.grid_size)] for _ in range(env.grid_size)]  # Initialize an empty grid\n",
        "    grid[0][0] = 'S'  # Mark the start position\n",
        "    grid[env.grid_size-1][env.grid_size-1] = 'G'  # Mark the goal position\n",
        "    for (x, y) in path:\n",
        "        if (x, y) != (0, 0) and (x, y) != (env.grid_size-1, env.grid_size-1):\n",
        "            grid[x][y] = 'X'  # Mark the path positions\n",
        "\n",
        "    # Print the grid\n",
        "    print(title)\n",
        "    for row in grid:\n",
        "        print(' '.join(row))\n",
        "    print()\n",
        "\n",
        "# Visualize the path of the first and last episode\n",
        "plot_episode_path(first_episode_path, 'First Episode Path')\n",
        "plot_episode_path(last_episode_path, 'Last Episode Path')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE821aspi-3K",
        "outputId": "d095c427-2e7d-45c4-befa-052a10ef888f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Episode: 21, Total Steps: 300, Total Reward: -300\n",
            "Episode: 22, Total Steps: 300, Total Reward: -300\n",
            "Episode: 23, Total Steps: 300, Total Reward: -300\n",
            "Episode: 24, Total Steps: 300, Total Reward: -300\n",
            "Episode: 25, Total Steps: 300, Total Reward: -300\n",
            "Episode: 26, Total Steps: 300, Total Reward: -300\n",
            "Episode: 27, Total Steps: 300, Total Reward: -300\n",
            "Episode: 28, Total Steps: 300, Total Reward: -300\n",
            "Episode: 29, Total Steps: 300, Total Reward: -300\n",
            "Episode: 30, Total Steps: 300, Total Reward: -300\n",
            "Episode: 31, Total Steps: 300, Total Reward: -300\n",
            "Episode: 32, Total Steps: 300, Total Reward: -300\n",
            "Episode: 33, Total Steps: 300, Total Reward: -300\n",
            "Episode: 34, Total Steps: 300, Total Reward: -300\n",
            "Episode: 35, Total Steps: 300, Total Reward: -300\n",
            "Episode: 36, Total Steps: 300, Total Reward: -300\n",
            "Episode: 37, Total Steps: 300, Total Reward: -300\n",
            "Episode: 38, Total Steps: 300, Total Reward: -300\n",
            "Episode: 39, Total Steps: 300, Total Reward: -300\n",
            "Episode: 40, Total Steps: 300, Total Reward: -300\n",
            "Episode: 41, Total Steps: 300, Total Reward: -300\n",
            "Episode: 42, Total Steps: 300, Total Reward: -300\n",
            "Episode: 43, Total Steps: 300, Total Reward: -300\n",
            "Episode: 44, Total Steps: 300, Total Reward: -300\n",
            "Episode: 45, Total Steps: 300, Total Reward: -300\n",
            "Episode: 46, Total Steps: 300, Total Reward: -300\n",
            "Episode: 47, Total Steps: 300, Total Reward: -300\n",
            "Episode: 48, Total Steps: 300, Total Reward: -300\n",
            "Episode: 49, Total Steps: 300, Total Reward: -300\n",
            "Episode: 50, Total Steps: 300, Total Reward: -300\n",
            "Episode: 51, Total Steps: 300, Total Reward: -300\n",
            "Episode: 52, Total Steps: 300, Total Reward: -300\n",
            "Episode: 53, Total Steps: 300, Total Reward: -300\n",
            "Episode: 54, Total Steps: 300, Total Reward: -300\n",
            "Episode: 55, Total Steps: 300, Total Reward: -300\n",
            "Episode: 56, Total Steps: 300, Total Reward: -300\n",
            "Episode: 57, Total Steps: 300, Total Reward: -300\n",
            "Episode: 58, Total Steps: 300, Total Reward: -300\n",
            "Episode: 59, Total Steps: 300, Total Reward: -300\n",
            "Episode: 60, Total Steps: 300, Total Reward: -300\n",
            "Episode: 61, Total Steps: 300, Total Reward: -300\n",
            "Episode: 62, Total Steps: 300, Total Reward: -300\n",
            "Episode: 63, Total Steps: 300, Total Reward: -300\n",
            "Episode: 64, Total Steps: 300, Total Reward: -300\n",
            "Episode: 65, Total Steps: 300, Total Reward: -300\n",
            "Episode: 66, Total Steps: 300, Total Reward: -300\n",
            "Episode: 67, Total Steps: 300, Total Reward: -300\n",
            "Episode: 68, Total Steps: 300, Total Reward: -300\n",
            "Episode: 69, Total Steps: 300, Total Reward: -300\n",
            "Episode: 70, Total Steps: 300, Total Reward: -300\n",
            "Episode: 71, Total Steps: 300, Total Reward: -300\n",
            "Episode: 72, Total Steps: 300, Total Reward: -300\n",
            "Episode: 73, Total Steps: 300, Total Reward: -300\n",
            "Episode: 74, Total Steps: 300, Total Reward: -300\n",
            "Episode: 75, Total Steps: 300, Total Reward: -300\n",
            "Episode: 76, Total Steps: 300, Total Reward: -300\n",
            "Episode: 77, Total Steps: 300, Total Reward: -300\n",
            "Episode: 78, Total Steps: 300, Total Reward: -300\n",
            "Episode: 79, Total Steps: 300, Total Reward: -300\n",
            "Episode: 80, Total Steps: 300, Total Reward: -300\n",
            "Episode: 81, Total Steps: 300, Total Reward: -300\n",
            "Episode: 82, Total Steps: 300, Total Reward: -300\n",
            "Episode: 83, Total Steps: 300, Total Reward: -300\n",
            "Episode: 84, Total Steps: 300, Total Reward: -300\n",
            "Episode: 85, Total Steps: 300, Total Reward: -300\n",
            "Episode: 86, Total Steps: 300, Total Reward: -300\n",
            "Episode: 87, Total Steps: 300, Total Reward: -300\n",
            "Episode: 88, Total Steps: 300, Total Reward: -300\n",
            "Episode: 89, Total Steps: 300, Total Reward: -300\n",
            "Episode: 90, Total Steps: 300, Total Reward: -300\n",
            "Episode: 91, Total Steps: 300, Total Reward: -300\n",
            "Episode: 92, Total Steps: 300, Total Reward: -300\n",
            "Episode: 93, Total Steps: 300, Total Reward: -300\n",
            "Episode: 94, Total Steps: 300, Total Reward: -300\n",
            "Episode: 95, Total Steps: 300, Total Reward: -300\n",
            "Episode: 96, Total Steps: 300, Total Reward: -300\n",
            "Episode: 97, Total Steps: 300, Total Reward: -300\n",
            "Episode: 98, Total Steps: 300, Total Reward: -300\n",
            "Episode: 99, Total Steps: 300, Total Reward: -300\n",
            "Episode: 100, Total Steps: 300, Total Reward: -300\n",
            "Episode: 101, Total Steps: 300, Total Reward: -300\n",
            "Episode: 102, Total Steps: 300, Total Reward: -300\n",
            "Episode: 103, Total Steps: 300, Total Reward: -300\n",
            "Episode: 104, Total Steps: 300, Total Reward: -300\n",
            "Episode: 105, Total Steps: 300, Total Reward: -300\n",
            "Episode: 106, Total Steps: 300, Total Reward: -300\n",
            "Episode: 107, Total Steps: 300, Total Reward: -300\n",
            "Episode: 108, Total Steps: 300, Total Reward: -300\n",
            "Episode: 109, Total Steps: 300, Total Reward: -300\n",
            "Episode: 110, Total Steps: 300, Total Reward: -300\n",
            "Episode: 111, Total Steps: 300, Total Reward: -300\n",
            "Episode: 112, Total Steps: 300, Total Reward: -300\n",
            "Episode: 113, Total Steps: 300, Total Reward: -300\n",
            "Episode: 114, Total Steps: 300, Total Reward: -300\n",
            "Episode: 115, Total Steps: 300, Total Reward: -300\n",
            "Episode: 116, Total Steps: 300, Total Reward: -300\n",
            "Episode: 117, Total Steps: 300, Total Reward: -300\n",
            "Episode: 118, Total Steps: 300, Total Reward: -300\n",
            "Episode: 119, Total Steps: 300, Total Reward: -300\n",
            "Episode: 120, Total Steps: 300, Total Reward: -300\n",
            "Episode: 121, Total Steps: 300, Total Reward: -300\n",
            "Episode: 122, Total Steps: 300, Total Reward: -300\n",
            "Episode: 123, Total Steps: 300, Total Reward: -300\n",
            "Episode: 124, Total Steps: 300, Total Reward: -300\n",
            "Episode: 125, Total Steps: 300, Total Reward: -300\n",
            "Episode: 126, Total Steps: 300, Total Reward: -300\n",
            "Episode: 127, Total Steps: 300, Total Reward: -300\n",
            "Episode: 128, Total Steps: 300, Total Reward: -300\n",
            "Episode: 129, Total Steps: 300, Total Reward: -300\n",
            "Episode: 130, Total Steps: 300, Total Reward: -300\n",
            "Episode: 131, Total Steps: 300, Total Reward: -300\n",
            "Episode: 132, Total Steps: 300, Total Reward: -300\n",
            "Episode: 133, Total Steps: 300, Total Reward: -300\n",
            "Episode: 134, Total Steps: 300, Total Reward: -300\n",
            "Episode: 135, Total Steps: 300, Total Reward: -300\n",
            "Episode: 136, Total Steps: 300, Total Reward: -300\n",
            "Episode: 137, Total Steps: 300, Total Reward: -300\n",
            "Episode: 138, Total Steps: 300, Total Reward: -300\n",
            "Episode: 139, Total Steps: 300, Total Reward: -300\n",
            "Episode: 140, Total Steps: 300, Total Reward: -300\n",
            "Episode: 141, Total Steps: 300, Total Reward: -300\n",
            "Episode: 142, Total Steps: 300, Total Reward: -300\n",
            "Episode: 143, Total Steps: 300, Total Reward: -300\n",
            "Episode: 144, Total Steps: 300, Total Reward: -300\n",
            "Episode: 145, Total Steps: 300, Total Reward: -300\n",
            "Episode: 146, Total Steps: 300, Total Reward: -300\n",
            "Episode: 147, Total Steps: 300, Total Reward: -300\n",
            "Episode: 148, Total Steps: 300, Total Reward: -300\n",
            "Episode: 149, Total Steps: 300, Total Reward: -300\n",
            "Episode: 150, Total Steps: 300, Total Reward: -300\n",
            "Episode: 151, Total Steps: 300, Total Reward: -300\n",
            "Episode: 152, Total Steps: 300, Total Reward: -300\n",
            "Episode: 153, Total Steps: 300, Total Reward: -300\n",
            "Episode: 154, Total Steps: 300, Total Reward: -300\n",
            "Episode: 155, Total Steps: 300, Total Reward: -300\n",
            "Episode: 156, Total Steps: 300, Total Reward: -300\n",
            "Episode: 157, Total Steps: 300, Total Reward: -300\n",
            "Episode: 158, Total Steps: 300, Total Reward: -300\n",
            "Episode: 159, Total Steps: 300, Total Reward: -300\n",
            "Episode: 160, Total Steps: 300, Total Reward: -300\n",
            "Episode: 161, Total Steps: 300, Total Reward: -300\n",
            "Episode: 162, Total Steps: 300, Total Reward: -300\n",
            "Episode: 163, Total Steps: 300, Total Reward: -300\n",
            "Episode: 164, Total Steps: 300, Total Reward: -300\n",
            "Episode: 165, Total Steps: 300, Total Reward: -300\n",
            "Episode: 166, Total Steps: 300, Total Reward: -300\n",
            "Episode: 167, Total Steps: 300, Total Reward: -300\n",
            "Episode: 168, Total Steps: 300, Total Reward: -300\n",
            "Episode: 169, Total Steps: 300, Total Reward: -300\n",
            "Episode: 170, Total Steps: 300, Total Reward: -300\n",
            "Episode: 171, Total Steps: 300, Total Reward: -300\n",
            "Episode: 172, Total Steps: 300, Total Reward: -300\n",
            "Episode: 173, Total Steps: 300, Total Reward: -300\n",
            "Episode: 174, Total Steps: 300, Total Reward: -300\n",
            "Episode: 175, Total Steps: 300, Total Reward: -300\n",
            "Episode: 176, Total Steps: 300, Total Reward: -300\n",
            "Episode: 177, Total Steps: 300, Total Reward: -300\n",
            "Episode: 178, Total Steps: 300, Total Reward: -300\n",
            "Episode: 179, Total Steps: 300, Total Reward: -300\n",
            "Episode: 180, Total Steps: 300, Total Reward: -300\n",
            "Episode: 181, Total Steps: 300, Total Reward: -300\n",
            "Episode: 182, Total Steps: 300, Total Reward: -300\n",
            "Episode: 183, Total Steps: 300, Total Reward: -300\n",
            "Episode: 184, Total Steps: 300, Total Reward: -300\n",
            "Episode: 185, Total Steps: 300, Total Reward: -300\n",
            "Episode: 186, Total Steps: 300, Total Reward: -300\n",
            "Episode: 187, Total Steps: 300, Total Reward: -300\n",
            "Episode: 188, Total Steps: 300, Total Reward: -300\n",
            "Episode: 189, Total Steps: 300, Total Reward: -300\n",
            "Episode: 190, Total Steps: 300, Total Reward: -300\n",
            "Episode: 191, Total Steps: 300, Total Reward: -300\n",
            "Episode: 192, Total Steps: 300, Total Reward: -300\n",
            "Episode: 193, Total Steps: 300, Total Reward: -300\n",
            "Episode: 194, Total Steps: 300, Total Reward: -300\n",
            "Episode: 195, Total Steps: 300, Total Reward: -300\n",
            "Episode: 196, Total Steps: 300, Total Reward: -300\n",
            "Episode: 197, Total Steps: 300, Total Reward: -300\n",
            "Episode: 198, Total Steps: 300, Total Reward: -300\n",
            "Episode: 199, Total Steps: 300, Total Reward: -300\n",
            "Episode: 200, Total Steps: 300, Total Reward: -300\n",
            "Episode: 201, Total Steps: 300, Total Reward: -300\n",
            "Episode: 202, Total Steps: 300, Total Reward: -300\n",
            "Episode: 203, Total Steps: 300, Total Reward: -300\n",
            "Episode: 204, Total Steps: 300, Total Reward: -300\n",
            "Episode: 205, Total Steps: 300, Total Reward: -300\n",
            "Episode: 206, Total Steps: 300, Total Reward: -300\n",
            "Episode: 207, Total Steps: 300, Total Reward: -300\n",
            "Episode: 208, Total Steps: 300, Total Reward: -300\n",
            "Episode: 209, Total Steps: 300, Total Reward: -300\n",
            "Episode: 210, Total Steps: 300, Total Reward: -300\n",
            "Episode: 211, Total Steps: 300, Total Reward: -300\n",
            "Episode: 212, Total Steps: 300, Total Reward: -300\n",
            "Episode: 213, Total Steps: 300, Total Reward: -300\n",
            "Episode: 214, Total Steps: 300, Total Reward: -300\n",
            "Episode: 215, Total Steps: 300, Total Reward: -300\n",
            "Episode: 216, Total Steps: 300, Total Reward: -300\n",
            "Episode: 217, Total Steps: 300, Total Reward: -300\n",
            "Episode: 218, Total Steps: 300, Total Reward: -300\n",
            "Episode: 219, Total Steps: 300, Total Reward: -300\n",
            "Episode: 220, Total Steps: 300, Total Reward: -300\n",
            "Episode: 221, Total Steps: 300, Total Reward: -300\n",
            "Episode: 222, Total Steps: 300, Total Reward: -300\n",
            "Episode: 223, Total Steps: 300, Total Reward: -300\n",
            "Episode: 224, Total Steps: 300, Total Reward: -300\n",
            "Episode: 225, Total Steps: 300, Total Reward: -300\n",
            "Episode: 226, Total Steps: 300, Total Reward: -300\n",
            "Episode: 227, Total Steps: 300, Total Reward: -300\n",
            "Episode: 228, Total Steps: 300, Total Reward: -300\n",
            "Episode: 229, Total Steps: 300, Total Reward: -300\n",
            "Episode: 230, Total Steps: 300, Total Reward: -300\n",
            "Episode: 231, Total Steps: 300, Total Reward: -300\n",
            "Episode: 232, Total Steps: 300, Total Reward: -300\n",
            "Episode: 233, Total Steps: 300, Total Reward: -300\n",
            "Episode: 234, Total Steps: 300, Total Reward: -300\n",
            "Episode: 235, Total Steps: 300, Total Reward: -300\n",
            "Episode: 236, Total Steps: 300, Total Reward: -300\n",
            "Episode: 237, Total Steps: 300, Total Reward: -300\n",
            "Episode: 238, Total Steps: 300, Total Reward: -300\n",
            "Episode: 239, Total Steps: 300, Total Reward: -300\n",
            "Episode: 240, Total Steps: 300, Total Reward: -300\n",
            "Episode: 241, Total Steps: 300, Total Reward: -300\n",
            "Episode: 242, Total Steps: 300, Total Reward: -300\n",
            "Episode: 243, Total Steps: 300, Total Reward: -300\n",
            "Episode: 244, Total Steps: 300, Total Reward: -300\n",
            "Episode: 245, Total Steps: 300, Total Reward: -300\n",
            "Episode: 246, Total Steps: 300, Total Reward: -300\n",
            "Episode: 247, Total Steps: 300, Total Reward: -300\n",
            "Episode: 248, Total Steps: 300, Total Reward: -300\n",
            "Episode: 249, Total Steps: 300, Total Reward: -300\n",
            "Episode: 250, Total Steps: 300, Total Reward: -300\n",
            "Episode: 251, Total Steps: 300, Total Reward: -300\n",
            "Episode: 252, Total Steps: 300, Total Reward: -300\n",
            "Episode: 253, Total Steps: 300, Total Reward: -300\n",
            "Episode: 254, Total Steps: 300, Total Reward: -300\n",
            "Episode: 255, Total Steps: 300, Total Reward: -300\n",
            "Episode: 256, Total Steps: 300, Total Reward: -300\n",
            "Episode: 257, Total Steps: 300, Total Reward: -300\n",
            "Episode: 258, Total Steps: 300, Total Reward: -300\n",
            "Episode: 259, Total Steps: 300, Total Reward: -300\n",
            "Episode: 260, Total Steps: 300, Total Reward: -300\n",
            "Episode: 261, Total Steps: 300, Total Reward: -300\n",
            "Episode: 262, Total Steps: 300, Total Reward: -300\n",
            "Episode: 263, Total Steps: 300, Total Reward: -300\n",
            "Episode: 264, Total Steps: 300, Total Reward: -300\n",
            "Episode: 265, Total Steps: 300, Total Reward: -300\n",
            "Episode: 266, Total Steps: 300, Total Reward: -300\n",
            "Episode: 267, Total Steps: 300, Total Reward: -300\n",
            "Episode: 268, Total Steps: 300, Total Reward: -300\n",
            "Episode: 269, Total Steps: 300, Total Reward: -300\n",
            "Episode: 270, Total Steps: 300, Total Reward: -300\n",
            "Episode: 271, Total Steps: 300, Total Reward: -300\n",
            "Episode: 272, Total Steps: 300, Total Reward: -300\n",
            "Episode: 273, Total Steps: 300, Total Reward: -300\n",
            "Episode: 274, Total Steps: 300, Total Reward: -300\n",
            "Episode: 275, Total Steps: 300, Total Reward: -300\n",
            "Episode: 276, Total Steps: 300, Total Reward: -300\n",
            "Episode: 277, Total Steps: 300, Total Reward: -300\n",
            "Episode: 278, Total Steps: 300, Total Reward: -300\n",
            "Episode: 279, Total Steps: 300, Total Reward: -300\n",
            "Episode: 280, Total Steps: 300, Total Reward: -300\n",
            "Episode: 281, Total Steps: 300, Total Reward: -300\n",
            "Episode: 282, Total Steps: 300, Total Reward: -300\n",
            "Episode: 283, Total Steps: 300, Total Reward: -300\n",
            "Episode: 284, Total Steps: 300, Total Reward: -300\n",
            "Episode: 285, Total Steps: 300, Total Reward: -300\n",
            "Episode: 286, Total Steps: 300, Total Reward: -300\n",
            "Episode: 287, Total Steps: 300, Total Reward: -300\n",
            "Episode: 288, Total Steps: 300, Total Reward: -300\n",
            "Episode: 289, Total Steps: 300, Total Reward: -300\n",
            "Episode: 290, Total Steps: 300, Total Reward: -300\n",
            "Episode: 291, Total Steps: 300, Total Reward: -300\n",
            "Episode: 292, Total Steps: 300, Total Reward: -300\n",
            "Episode: 293, Total Steps: 300, Total Reward: -300\n",
            "Episode: 294, Total Steps: 300, Total Reward: -300\n",
            "Episode: 295, Total Steps: 300, Total Reward: -300\n",
            "Episode: 296, Total Steps: 300, Total Reward: -300\n",
            "Episode: 297, Total Steps: 300, Total Reward: -300\n",
            "Episode: 298, Total Steps: 300, Total Reward: -300\n",
            "Episode: 299, Total Steps: 300, Total Reward: -300\n",
            "Episode: 300, Total Steps: 300, Total Reward: -300\n",
            "Episode: 301, Total Steps: 300, Total Reward: -300\n",
            "Episode: 302, Total Steps: 300, Total Reward: -300\n",
            "Episode: 303, Total Steps: 300, Total Reward: -300\n",
            "Episode: 304, Total Steps: 300, Total Reward: -300\n",
            "Episode: 305, Total Steps: 300, Total Reward: -300\n",
            "Episode: 306, Total Steps: 300, Total Reward: -300\n",
            "Episode: 307, Total Steps: 300, Total Reward: -300\n",
            "Episode: 308, Total Steps: 300, Total Reward: -300\n",
            "Episode: 309, Total Steps: 300, Total Reward: -300\n",
            "Episode: 310, Total Steps: 300, Total Reward: -300\n",
            "Episode: 311, Total Steps: 300, Total Reward: -300\n",
            "Episode: 312, Total Steps: 300, Total Reward: -300\n",
            "Episode: 313, Total Steps: 300, Total Reward: -300\n",
            "Episode: 314, Total Steps: 300, Total Reward: -300\n",
            "Episode: 315, Total Steps: 300, Total Reward: -300\n",
            "Episode: 316, Total Steps: 300, Total Reward: -300\n",
            "Episode: 317, Total Steps: 300, Total Reward: -300\n",
            "Episode: 318, Total Steps: 300, Total Reward: -300\n",
            "Episode: 319, Total Steps: 300, Total Reward: -300\n",
            "Episode: 320, Total Steps: 300, Total Reward: -300\n",
            "Episode: 321, Total Steps: 300, Total Reward: -300\n",
            "Episode: 322, Total Steps: 300, Total Reward: -300\n",
            "Episode: 323, Total Steps: 300, Total Reward: -300\n",
            "Episode: 324, Total Steps: 300, Total Reward: -300\n",
            "Episode: 325, Total Steps: 300, Total Reward: -300\n",
            "Episode: 326, Total Steps: 300, Total Reward: -300\n",
            "Episode: 327, Total Steps: 300, Total Reward: -300\n",
            "Episode: 328, Total Steps: 300, Total Reward: -300\n",
            "Episode: 329, Total Steps: 300, Total Reward: -300\n",
            "Episode: 330, Total Steps: 300, Total Reward: -300\n",
            "Episode: 331, Total Steps: 300, Total Reward: -300\n",
            "Episode: 332, Total Steps: 300, Total Reward: -300\n",
            "Episode: 333, Total Steps: 300, Total Reward: -300\n",
            "Episode: 334, Total Steps: 300, Total Reward: -300\n",
            "Episode: 335, Total Steps: 300, Total Reward: -300\n",
            "Episode: 336, Total Steps: 300, Total Reward: -300\n",
            "Episode: 337, Total Steps: 300, Total Reward: -300\n",
            "Episode: 338, Total Steps: 300, Total Reward: -300\n",
            "Episode: 339, Total Steps: 300, Total Reward: -300\n",
            "Episode: 340, Total Steps: 300, Total Reward: -300\n",
            "Episode: 341, Total Steps: 300, Total Reward: -300\n",
            "Episode: 342, Total Steps: 300, Total Reward: -300\n",
            "Episode: 343, Total Steps: 300, Total Reward: -300\n",
            "Episode: 344, Total Steps: 300, Total Reward: -300\n",
            "Episode: 345, Total Steps: 300, Total Reward: -300\n",
            "Episode: 346, Total Steps: 300, Total Reward: -300\n",
            "Episode: 347, Total Steps: 300, Total Reward: -300\n",
            "Episode: 348, Total Steps: 300, Total Reward: -300\n",
            "Episode: 349, Total Steps: 300, Total Reward: -300\n",
            "Episode: 350, Total Steps: 300, Total Reward: -300\n",
            "Episode: 351, Total Steps: 300, Total Reward: -300\n",
            "Episode: 352, Total Steps: 300, Total Reward: -300\n",
            "Episode: 353, Total Steps: 300, Total Reward: -300\n",
            "Episode: 354, Total Steps: 300, Total Reward: -300\n",
            "Episode: 355, Total Steps: 300, Total Reward: -300\n",
            "Episode: 356, Total Steps: 300, Total Reward: -300\n",
            "Episode: 357, Total Steps: 300, Total Reward: -300\n",
            "Episode: 358, Total Steps: 300, Total Reward: -300\n",
            "Episode: 359, Total Steps: 300, Total Reward: -300\n",
            "Episode: 360, Total Steps: 300, Total Reward: -300\n",
            "Episode: 361, Total Steps: 300, Total Reward: -300\n",
            "Episode: 362, Total Steps: 300, Total Reward: -300\n",
            "Episode: 363, Total Steps: 300, Total Reward: -300\n",
            "Episode: 364, Total Steps: 300, Total Reward: -300\n",
            "Episode: 365, Total Steps: 300, Total Reward: -300\n",
            "Episode: 366, Total Steps: 300, Total Reward: -300\n",
            "Episode: 367, Total Steps: 300, Total Reward: -300\n",
            "Episode: 368, Total Steps: 300, Total Reward: -300\n",
            "Episode: 369, Total Steps: 300, Total Reward: -300\n",
            "Episode: 370, Total Steps: 300, Total Reward: -300\n",
            "Episode: 371, Total Steps: 300, Total Reward: -300\n",
            "Episode: 372, Total Steps: 300, Total Reward: -300\n",
            "Episode: 373, Total Steps: 300, Total Reward: -300\n",
            "Episode: 374, Total Steps: 300, Total Reward: -300\n",
            "Episode: 375, Total Steps: 300, Total Reward: -300\n",
            "Episode: 376, Total Steps: 300, Total Reward: -300\n",
            "Episode: 377, Total Steps: 300, Total Reward: -300\n",
            "Episode: 378, Total Steps: 300, Total Reward: -300\n",
            "Episode: 379, Total Steps: 300, Total Reward: -300\n",
            "Episode: 380, Total Steps: 300, Total Reward: -300\n",
            "Episode: 381, Total Steps: 300, Total Reward: -300\n",
            "Episode: 382, Total Steps: 300, Total Reward: -300\n",
            "Episode: 383, Total Steps: 300, Total Reward: -300\n",
            "Episode: 384, Total Steps: 300, Total Reward: -300\n",
            "Episode: 385, Total Steps: 300, Total Reward: -300\n",
            "Episode: 386, Total Steps: 300, Total Reward: -300\n",
            "Episode: 387, Total Steps: 300, Total Reward: -300\n",
            "Episode: 388, Total Steps: 300, Total Reward: -300\n",
            "Episode: 389, Total Steps: 300, Total Reward: -300\n",
            "Episode: 390, Total Steps: 300, Total Reward: -300\n",
            "Episode: 391, Total Steps: 300, Total Reward: -300\n",
            "Episode: 392, Total Steps: 300, Total Reward: -300\n",
            "Episode: 393, Total Steps: 300, Total Reward: -300\n",
            "Episode: 394, Total Steps: 300, Total Reward: -300\n",
            "Episode: 395, Total Steps: 300, Total Reward: -300\n",
            "Episode: 396, Total Steps: 300, Total Reward: -300\n",
            "Episode: 397, Total Steps: 300, Total Reward: -300\n",
            "Episode: 398, Total Steps: 300, Total Reward: -300\n",
            "Episode: 399, Total Steps: 300, Total Reward: -300\n",
            "Episode: 400, Total Steps: 300, Total Reward: -300\n",
            "Episode: 401, Total Steps: 300, Total Reward: -300\n",
            "Episode: 402, Total Steps: 300, Total Reward: -300\n",
            "Episode: 403, Total Steps: 300, Total Reward: -300\n",
            "Episode: 404, Total Steps: 300, Total Reward: -300\n",
            "Episode: 405, Total Steps: 300, Total Reward: -300\n",
            "Episode: 406, Total Steps: 300, Total Reward: -300\n",
            "Episode: 407, Total Steps: 300, Total Reward: -300\n",
            "Episode: 408, Total Steps: 300, Total Reward: -300\n",
            "Episode: 409, Total Steps: 300, Total Reward: -300\n",
            "Episode: 410, Total Steps: 300, Total Reward: -300\n",
            "Episode: 411, Total Steps: 300, Total Reward: -300\n",
            "Episode: 412, Total Steps: 300, Total Reward: -300\n",
            "Episode: 413, Total Steps: 300, Total Reward: -300\n",
            "Episode: 414, Total Steps: 300, Total Reward: -300\n",
            "Episode: 415, Total Steps: 300, Total Reward: -300\n",
            "Episode: 416, Total Steps: 300, Total Reward: -300\n",
            "Episode: 417, Total Steps: 300, Total Reward: -300\n",
            "Episode: 418, Total Steps: 300, Total Reward: -300\n",
            "Episode: 419, Total Steps: 300, Total Reward: -300\n",
            "Episode: 420, Total Steps: 300, Total Reward: -300\n",
            "Episode: 421, Total Steps: 300, Total Reward: -300\n",
            "Episode: 422, Total Steps: 300, Total Reward: -300\n",
            "Episode: 423, Total Steps: 300, Total Reward: -300\n",
            "Episode: 424, Total Steps: 300, Total Reward: -300\n",
            "Episode: 425, Total Steps: 300, Total Reward: -300\n",
            "Episode: 426, Total Steps: 300, Total Reward: -300\n",
            "Episode: 427, Total Steps: 300, Total Reward: -300\n",
            "Episode: 428, Total Steps: 300, Total Reward: -300\n",
            "Episode: 429, Total Steps: 300, Total Reward: -300\n",
            "Episode: 430, Total Steps: 300, Total Reward: -300\n",
            "Episode: 431, Total Steps: 300, Total Reward: -300\n",
            "Episode: 432, Total Steps: 300, Total Reward: -300\n",
            "Episode: 433, Total Steps: 300, Total Reward: -300\n",
            "Episode: 434, Total Steps: 300, Total Reward: -300\n",
            "Episode: 435, Total Steps: 300, Total Reward: -300\n",
            "Episode: 436, Total Steps: 300, Total Reward: -300\n",
            "Episode: 437, Total Steps: 300, Total Reward: -300\n",
            "Episode: 438, Total Steps: 300, Total Reward: -300\n",
            "Episode: 439, Total Steps: 300, Total Reward: -300\n",
            "Episode: 440, Total Steps: 300, Total Reward: -300\n",
            "Episode: 441, Total Steps: 300, Total Reward: -300\n",
            "Episode: 442, Total Steps: 300, Total Reward: -300\n",
            "Episode: 443, Total Steps: 300, Total Reward: -300\n",
            "Episode: 444, Total Steps: 300, Total Reward: -300\n",
            "Episode: 445, Total Steps: 300, Total Reward: -300\n",
            "Episode: 446, Total Steps: 300, Total Reward: -300\n",
            "Episode: 447, Total Steps: 300, Total Reward: -300\n",
            "Episode: 448, Total Steps: 300, Total Reward: -300\n",
            "Episode: 449, Total Steps: 300, Total Reward: -300\n",
            "Episode: 450, Total Steps: 300, Total Reward: -300\n",
            "Episode: 451, Total Steps: 300, Total Reward: -300\n",
            "Episode: 452, Total Steps: 300, Total Reward: -300\n",
            "Episode: 453, Total Steps: 300, Total Reward: -300\n",
            "Episode: 454, Total Steps: 300, Total Reward: -300\n",
            "Episode: 455, Total Steps: 300, Total Reward: -300\n",
            "Episode: 456, Total Steps: 300, Total Reward: -300\n",
            "Episode: 457, Total Steps: 300, Total Reward: -300\n",
            "Episode: 458, Total Steps: 300, Total Reward: -300\n",
            "Episode: 459, Total Steps: 300, Total Reward: -300\n",
            "Episode: 460, Total Steps: 300, Total Reward: -300\n",
            "Episode: 461, Total Steps: 300, Total Reward: -300\n",
            "Episode: 462, Total Steps: 300, Total Reward: -300\n",
            "Episode: 463, Total Steps: 300, Total Reward: -300\n",
            "Episode: 464, Total Steps: 300, Total Reward: -300\n",
            "Episode: 465, Total Steps: 300, Total Reward: -300\n",
            "Episode: 466, Total Steps: 300, Total Reward: -300\n",
            "Episode: 467, Total Steps: 300, Total Reward: -300\n",
            "Episode: 468, Total Steps: 300, Total Reward: -300\n",
            "Episode: 469, Total Steps: 300, Total Reward: -300\n",
            "Episode: 470, Total Steps: 300, Total Reward: -300\n",
            "Episode: 471, Total Steps: 300, Total Reward: -300\n",
            "Episode: 472, Total Steps: 300, Total Reward: -300\n",
            "Episode: 473, Total Steps: 300, Total Reward: -300\n",
            "Episode: 474, Total Steps: 300, Total Reward: -300\n",
            "Episode: 475, Total Steps: 300, Total Reward: -300\n",
            "Episode: 476, Total Steps: 300, Total Reward: -300\n",
            "Episode: 477, Total Steps: 300, Total Reward: -300\n",
            "Episode: 478, Total Steps: 300, Total Reward: -300\n",
            "Episode: 479, Total Steps: 300, Total Reward: -300\n",
            "Episode: 480, Total Steps: 300, Total Reward: -300\n",
            "Episode: 481, Total Steps: 300, Total Reward: -300\n",
            "Episode: 482, Total Steps: 300, Total Reward: -300\n",
            "Episode: 483, Total Steps: 300, Total Reward: -300\n",
            "Episode: 484, Total Steps: 300, Total Reward: -300\n",
            "Episode: 485, Total Steps: 300, Total Reward: -300\n",
            "Episode: 486, Total Steps: 300, Total Reward: -300\n",
            "Episode: 487, Total Steps: 300, Total Reward: -300\n",
            "Episode: 488, Total Steps: 300, Total Reward: -300\n",
            "Episode: 489, Total Steps: 300, Total Reward: -300\n",
            "Episode: 490, Total Steps: 300, Total Reward: -300\n",
            "Episode: 491, Total Steps: 300, Total Reward: -300\n",
            "Episode: 492, Total Steps: 300, Total Reward: -300\n",
            "Episode: 493, Total Steps: 300, Total Reward: -300\n",
            "Episode: 494, Total Steps: 300, Total Reward: -300\n",
            "Episode: 495, Total Steps: 300, Total Reward: -300\n",
            "Episode: 496, Total Steps: 300, Total Reward: -300\n",
            "Episode: 497, Total Steps: 300, Total Reward: -300\n",
            "Episode: 498, Total Steps: 300, Total Reward: -300\n",
            "Episode: 499, Total Steps: 300, Total Reward: -300\n",
            "Episode: 500, Total Steps: 300, Total Reward: -300\n",
            "Episode: 501, Total Steps: 300, Total Reward: -300\n",
            "Episode: 502, Total Steps: 300, Total Reward: -300\n",
            "Episode: 503, Total Steps: 300, Total Reward: -300\n",
            "Episode: 504, Total Steps: 300, Total Reward: -300\n",
            "Episode: 505, Total Steps: 300, Total Reward: -300\n",
            "Episode: 506, Total Steps: 300, Total Reward: -300\n",
            "Episode: 507, Total Steps: 300, Total Reward: -300\n",
            "Episode: 508, Total Steps: 300, Total Reward: -300\n",
            "Episode: 509, Total Steps: 300, Total Reward: -300\n",
            "Episode: 510, Total Steps: 300, Total Reward: -300\n",
            "Episode: 511, Total Steps: 300, Total Reward: -300\n",
            "Episode: 512, Total Steps: 300, Total Reward: -300\n",
            "Episode: 513, Total Steps: 300, Total Reward: -300\n",
            "Episode: 514, Total Steps: 300, Total Reward: -300\n",
            "Episode: 515, Total Steps: 300, Total Reward: -300\n",
            "Episode: 516, Total Steps: 300, Total Reward: -300\n",
            "Episode: 517, Total Steps: 300, Total Reward: -300\n",
            "Episode: 518, Total Steps: 300, Total Reward: -300\n",
            "Episode: 519, Total Steps: 300, Total Reward: -300\n",
            "Episode: 520, Total Steps: 300, Total Reward: -300\n",
            "Episode: 521, Total Steps: 300, Total Reward: -300\n",
            "Episode: 522, Total Steps: 300, Total Reward: -300\n",
            "Episode: 523, Total Steps: 300, Total Reward: -300\n",
            "Episode: 524, Total Steps: 300, Total Reward: -300\n",
            "Episode: 525, Total Steps: 300, Total Reward: -300\n",
            "Episode: 526, Total Steps: 300, Total Reward: -300\n",
            "Episode: 527, Total Steps: 300, Total Reward: -300\n",
            "Episode: 528, Total Steps: 300, Total Reward: -300\n",
            "Episode: 529, Total Steps: 300, Total Reward: -300\n",
            "Episode: 530, Total Steps: 300, Total Reward: -300\n",
            "Episode: 531, Total Steps: 300, Total Reward: -300\n",
            "Episode: 532, Total Steps: 300, Total Reward: -300\n",
            "Episode: 533, Total Steps: 300, Total Reward: -300\n",
            "Episode: 534, Total Steps: 300, Total Reward: -300\n",
            "Episode: 535, Total Steps: 300, Total Reward: -300\n",
            "Episode: 536, Total Steps: 300, Total Reward: -300\n",
            "Episode: 537, Total Steps: 300, Total Reward: -300\n",
            "Episode: 538, Total Steps: 300, Total Reward: -300\n",
            "Episode: 539, Total Steps: 300, Total Reward: -300\n",
            "Episode: 540, Total Steps: 300, Total Reward: -300\n",
            "Episode: 541, Total Steps: 300, Total Reward: -300\n",
            "Episode: 542, Total Steps: 300, Total Reward: -300\n",
            "Episode: 543, Total Steps: 300, Total Reward: -300\n",
            "Episode: 544, Total Steps: 300, Total Reward: -300\n",
            "Episode: 545, Total Steps: 300, Total Reward: -300\n",
            "Episode: 546, Total Steps: 300, Total Reward: -300\n",
            "Episode: 547, Total Steps: 300, Total Reward: -300\n",
            "Episode: 548, Total Steps: 300, Total Reward: -300\n",
            "Episode: 549, Total Steps: 300, Total Reward: -300\n",
            "Episode: 550, Total Steps: 300, Total Reward: -300\n",
            "Episode: 551, Total Steps: 300, Total Reward: -300\n",
            "Episode: 552, Total Steps: 300, Total Reward: -300\n",
            "Episode: 553, Total Steps: 300, Total Reward: -300\n",
            "Episode: 554, Total Steps: 300, Total Reward: -300\n",
            "Episode: 555, Total Steps: 300, Total Reward: -300\n",
            "Episode: 556, Total Steps: 300, Total Reward: -300\n",
            "Episode: 557, Total Steps: 300, Total Reward: -300\n",
            "Episode: 558, Total Steps: 300, Total Reward: -300\n",
            "Episode: 559, Total Steps: 300, Total Reward: -300\n",
            "Episode: 560, Total Steps: 300, Total Reward: -300\n",
            "Episode: 561, Total Steps: 300, Total Reward: -300\n",
            "Episode: 562, Total Steps: 300, Total Reward: -300\n",
            "Episode: 563, Total Steps: 300, Total Reward: -300\n",
            "Episode: 564, Total Steps: 300, Total Reward: -300\n",
            "Episode: 565, Total Steps: 300, Total Reward: -300\n",
            "Episode: 566, Total Steps: 300, Total Reward: -300\n",
            "Episode: 567, Total Steps: 300, Total Reward: -300\n",
            "Episode: 568, Total Steps: 300, Total Reward: -300\n",
            "Episode: 569, Total Steps: 300, Total Reward: -300\n",
            "Episode: 570, Total Steps: 300, Total Reward: -300\n",
            "Episode: 571, Total Steps: 300, Total Reward: -300\n",
            "Episode: 572, Total Steps: 300, Total Reward: -300\n",
            "Episode: 573, Total Steps: 300, Total Reward: -300\n",
            "Episode: 574, Total Steps: 300, Total Reward: -300\n",
            "Episode: 575, Total Steps: 300, Total Reward: -300\n",
            "Episode: 576, Total Steps: 300, Total Reward: -300\n",
            "Episode: 577, Total Steps: 300, Total Reward: -300\n",
            "Episode: 578, Total Steps: 300, Total Reward: -300\n",
            "Episode: 579, Total Steps: 300, Total Reward: -300\n",
            "Episode: 580, Total Steps: 300, Total Reward: -300\n",
            "Episode: 581, Total Steps: 300, Total Reward: -300\n",
            "Episode: 582, Total Steps: 300, Total Reward: -300\n",
            "Episode: 583, Total Steps: 300, Total Reward: -300\n",
            "Episode: 584, Total Steps: 300, Total Reward: -300\n",
            "Episode: 585, Total Steps: 300, Total Reward: -300\n",
            "Episode: 586, Total Steps: 300, Total Reward: -300\n",
            "Episode: 587, Total Steps: 300, Total Reward: -300\n",
            "Episode: 588, Total Steps: 300, Total Reward: -300\n",
            "Episode: 589, Total Steps: 300, Total Reward: -300\n",
            "Episode: 590, Total Steps: 300, Total Reward: -300\n",
            "Episode: 591, Total Steps: 300, Total Reward: -300\n",
            "Episode: 592, Total Steps: 300, Total Reward: -300\n",
            "Episode: 593, Total Steps: 300, Total Reward: -300\n",
            "Episode: 594, Total Steps: 300, Total Reward: -300\n",
            "Episode: 595, Total Steps: 300, Total Reward: -300\n",
            "Episode: 596, Total Steps: 300, Total Reward: -300\n",
            "Episode: 597, Total Steps: 300, Total Reward: -300\n",
            "Episode: 598, Total Steps: 300, Total Reward: -300\n",
            "Episode: 599, Total Steps: 300, Total Reward: -300\n",
            "Episode: 600, Total Steps: 300, Total Reward: -300\n",
            "Episode: 601, Total Steps: 300, Total Reward: -300\n",
            "Episode: 602, Total Steps: 300, Total Reward: -300\n",
            "Episode: 603, Total Steps: 300, Total Reward: -300\n",
            "Episode: 604, Total Steps: 300, Total Reward: -300\n",
            "Episode: 605, Total Steps: 300, Total Reward: -300\n",
            "Episode: 606, Total Steps: 300, Total Reward: -300\n",
            "Episode: 607, Total Steps: 300, Total Reward: -300\n",
            "Episode: 608, Total Steps: 300, Total Reward: -300\n",
            "Episode: 609, Total Steps: 300, Total Reward: -300\n",
            "Episode: 610, Total Steps: 300, Total Reward: -300\n",
            "Episode: 611, Total Steps: 300, Total Reward: -300\n",
            "Episode: 612, Total Steps: 300, Total Reward: -300\n",
            "Episode: 613, Total Steps: 300, Total Reward: -300\n",
            "Episode: 614, Total Steps: 300, Total Reward: -300\n",
            "Episode: 615, Total Steps: 300, Total Reward: -300\n",
            "Episode: 616, Total Steps: 300, Total Reward: -300\n",
            "Episode: 617, Total Steps: 300, Total Reward: -300\n",
            "Episode: 618, Total Steps: 300, Total Reward: -300\n",
            "Episode: 619, Total Steps: 300, Total Reward: -300\n",
            "Episode: 620, Total Steps: 300, Total Reward: -300\n",
            "Episode: 621, Total Steps: 300, Total Reward: -300\n",
            "Episode: 622, Total Steps: 300, Total Reward: -300\n",
            "Episode: 623, Total Steps: 300, Total Reward: -300\n",
            "Episode: 624, Total Steps: 300, Total Reward: -300\n",
            "Episode: 625, Total Steps: 300, Total Reward: -300\n",
            "Episode: 626, Total Steps: 300, Total Reward: -300\n",
            "Episode: 627, Total Steps: 300, Total Reward: -300\n",
            "Episode: 628, Total Steps: 300, Total Reward: -300\n",
            "Episode: 629, Total Steps: 300, Total Reward: -300\n",
            "Episode: 630, Total Steps: 300, Total Reward: -300\n",
            "Episode: 631, Total Steps: 300, Total Reward: -300\n",
            "Episode: 632, Total Steps: 300, Total Reward: -300\n",
            "Episode: 633, Total Steps: 300, Total Reward: -300\n",
            "Episode: 634, Total Steps: 300, Total Reward: -300\n",
            "Episode: 635, Total Steps: 300, Total Reward: -300\n",
            "Episode: 636, Total Steps: 300, Total Reward: -300\n",
            "Episode: 637, Total Steps: 300, Total Reward: -300\n",
            "Episode: 638, Total Steps: 300, Total Reward: -300\n",
            "Episode: 639, Total Steps: 300, Total Reward: -300\n",
            "Episode: 640, Total Steps: 300, Total Reward: -300\n",
            "Episode: 641, Total Steps: 300, Total Reward: -300\n",
            "Episode: 642, Total Steps: 300, Total Reward: -300\n",
            "Episode: 643, Total Steps: 300, Total Reward: -300\n",
            "Episode: 644, Total Steps: 300, Total Reward: -300\n",
            "Episode: 645, Total Steps: 300, Total Reward: -300\n",
            "Episode: 646, Total Steps: 300, Total Reward: -300\n",
            "Episode: 647, Total Steps: 300, Total Reward: -300\n",
            "Episode: 648, Total Steps: 300, Total Reward: -300\n",
            "Episode: 649, Total Steps: 300, Total Reward: -300\n",
            "Episode: 650, Total Steps: 300, Total Reward: -300\n",
            "Episode: 651, Total Steps: 300, Total Reward: -300\n",
            "Episode: 652, Total Steps: 300, Total Reward: -300\n",
            "Episode: 653, Total Steps: 300, Total Reward: -300\n",
            "Episode: 654, Total Steps: 300, Total Reward: -300\n",
            "Episode: 655, Total Steps: 300, Total Reward: -300\n",
            "Episode: 656, Total Steps: 300, Total Reward: -300\n",
            "Episode: 657, Total Steps: 300, Total Reward: -300\n",
            "Episode: 658, Total Steps: 300, Total Reward: -300\n",
            "Episode: 659, Total Steps: 300, Total Reward: -300\n",
            "Episode: 660, Total Steps: 300, Total Reward: -300\n",
            "Episode: 661, Total Steps: 300, Total Reward: -300\n",
            "Episode: 662, Total Steps: 300, Total Reward: -300\n",
            "Episode: 663, Total Steps: 300, Total Reward: -300\n",
            "Episode: 664, Total Steps: 300, Total Reward: -300\n",
            "Episode: 665, Total Steps: 300, Total Reward: -300\n",
            "Episode: 666, Total Steps: 300, Total Reward: -300\n",
            "Episode: 667, Total Steps: 300, Total Reward: -300\n",
            "Episode: 668, Total Steps: 300, Total Reward: -300\n",
            "Episode: 669, Total Steps: 300, Total Reward: -300\n",
            "Episode: 670, Total Steps: 300, Total Reward: -300\n",
            "Episode: 671, Total Steps: 300, Total Reward: -300\n",
            "Episode: 672, Total Steps: 300, Total Reward: -300\n",
            "Episode: 673, Total Steps: 300, Total Reward: -300\n",
            "Episode: 674, Total Steps: 300, Total Reward: -300\n",
            "Episode: 675, Total Steps: 300, Total Reward: -300\n",
            "Episode: 676, Total Steps: 300, Total Reward: -300\n",
            "Episode: 677, Total Steps: 300, Total Reward: -300\n",
            "Episode: 678, Total Steps: 300, Total Reward: -300\n",
            "Episode: 679, Total Steps: 300, Total Reward: -300\n",
            "Episode: 680, Total Steps: 300, Total Reward: -300\n",
            "Episode: 681, Total Steps: 300, Total Reward: -300\n",
            "Episode: 682, Total Steps: 300, Total Reward: -300\n",
            "Episode: 683, Total Steps: 300, Total Reward: -300\n",
            "Episode: 684, Total Steps: 300, Total Reward: -300\n",
            "Episode: 685, Total Steps: 300, Total Reward: -300\n",
            "Episode: 686, Total Steps: 300, Total Reward: -300\n",
            "Episode: 687, Total Steps: 300, Total Reward: -300\n",
            "Episode: 688, Total Steps: 300, Total Reward: -300\n",
            "Episode: 689, Total Steps: 300, Total Reward: -300\n",
            "Episode: 690, Total Steps: 300, Total Reward: -300\n",
            "Episode: 691, Total Steps: 300, Total Reward: -300\n",
            "Episode: 692, Total Steps: 300, Total Reward: -300\n",
            "Episode: 693, Total Steps: 300, Total Reward: -300\n",
            "Episode: 694, Total Steps: 300, Total Reward: -300\n",
            "Episode: 695, Total Steps: 300, Total Reward: -300\n",
            "Episode: 696, Total Steps: 300, Total Reward: -300\n",
            "Episode: 697, Total Steps: 300, Total Reward: -300\n",
            "Episode: 698, Total Steps: 300, Total Reward: -300\n",
            "Episode: 699, Total Steps: 300, Total Reward: -300\n",
            "Episode: 700, Total Steps: 300, Total Reward: -300\n",
            "Episode: 701, Total Steps: 300, Total Reward: -300\n",
            "Episode: 702, Total Steps: 300, Total Reward: -300\n",
            "Episode: 703, Total Steps: 300, Total Reward: -300\n",
            "Episode: 704, Total Steps: 300, Total Reward: -300\n",
            "Episode: 705, Total Steps: 300, Total Reward: -300\n",
            "Episode: 706, Total Steps: 300, Total Reward: -300\n",
            "Episode: 707, Total Steps: 300, Total Reward: -300\n",
            "Episode: 708, Total Steps: 300, Total Reward: -300\n",
            "Episode: 709, Total Steps: 300, Total Reward: -300\n",
            "Episode: 710, Total Steps: 300, Total Reward: -300\n",
            "Episode: 711, Total Steps: 300, Total Reward: -300\n",
            "Episode: 712, Total Steps: 300, Total Reward: -300\n",
            "Episode: 713, Total Steps: 300, Total Reward: -300\n",
            "Episode: 714, Total Steps: 300, Total Reward: -300\n",
            "Episode: 715, Total Steps: 300, Total Reward: -300\n",
            "Episode: 716, Total Steps: 300, Total Reward: -300\n",
            "Episode: 717, Total Steps: 300, Total Reward: -300\n",
            "Episode: 718, Total Steps: 300, Total Reward: -300\n",
            "Episode: 719, Total Steps: 300, Total Reward: -300\n",
            "Episode: 720, Total Steps: 300, Total Reward: -300\n",
            "Episode: 721, Total Steps: 300, Total Reward: -300\n",
            "Episode: 722, Total Steps: 300, Total Reward: -300\n",
            "Episode: 723, Total Steps: 300, Total Reward: -300\n",
            "Episode: 724, Total Steps: 300, Total Reward: -300\n",
            "Episode: 725, Total Steps: 300, Total Reward: -300\n",
            "Episode: 726, Total Steps: 300, Total Reward: -300\n",
            "Episode: 727, Total Steps: 300, Total Reward: -300\n",
            "Episode: 728, Total Steps: 300, Total Reward: -300\n",
            "Episode: 729, Total Steps: 300, Total Reward: -300\n",
            "Episode: 730, Total Steps: 300, Total Reward: -300\n",
            "Episode: 731, Total Steps: 300, Total Reward: -300\n",
            "Episode: 732, Total Steps: 300, Total Reward: -300\n",
            "Episode: 733, Total Steps: 300, Total Reward: -300\n",
            "Episode: 734, Total Steps: 300, Total Reward: -300\n",
            "Episode: 735, Total Steps: 300, Total Reward: -300\n",
            "Episode: 736, Total Steps: 300, Total Reward: -300\n",
            "Episode: 737, Total Steps: 300, Total Reward: -300\n",
            "Episode: 738, Total Steps: 300, Total Reward: -300\n",
            "Episode: 739, Total Steps: 300, Total Reward: -300\n",
            "Episode: 740, Total Steps: 300, Total Reward: -300\n",
            "Episode: 741, Total Steps: 300, Total Reward: -300\n",
            "Episode: 742, Total Steps: 300, Total Reward: -300\n",
            "Episode: 743, Total Steps: 300, Total Reward: -300\n",
            "Episode: 744, Total Steps: 300, Total Reward: -300\n",
            "Episode: 745, Total Steps: 300, Total Reward: -300\n",
            "Episode: 746, Total Steps: 300, Total Reward: -300\n",
            "Episode: 747, Total Steps: 300, Total Reward: -300\n",
            "Episode: 748, Total Steps: 300, Total Reward: -300\n",
            "Episode: 749, Total Steps: 300, Total Reward: -300\n",
            "Episode: 750, Total Steps: 300, Total Reward: -300\n",
            "Episode: 751, Total Steps: 300, Total Reward: -300\n",
            "Episode: 752, Total Steps: 300, Total Reward: -300\n",
            "Episode: 753, Total Steps: 300, Total Reward: -300\n",
            "Episode: 754, Total Steps: 300, Total Reward: -300\n",
            "Episode: 755, Total Steps: 300, Total Reward: -300\n",
            "Episode: 756, Total Steps: 300, Total Reward: -300\n",
            "Episode: 757, Total Steps: 300, Total Reward: -300\n",
            "Episode: 758, Total Steps: 300, Total Reward: -300\n",
            "Episode: 759, Total Steps: 300, Total Reward: -300\n",
            "Episode: 760, Total Steps: 300, Total Reward: -300\n",
            "Episode: 761, Total Steps: 300, Total Reward: -300\n",
            "Episode: 762, Total Steps: 300, Total Reward: -300\n",
            "Episode: 763, Total Steps: 300, Total Reward: -300\n",
            "Episode: 764, Total Steps: 300, Total Reward: -300\n",
            "Episode: 765, Total Steps: 300, Total Reward: -300\n",
            "Episode: 766, Total Steps: 300, Total Reward: -300\n",
            "Episode: 767, Total Steps: 300, Total Reward: -300\n",
            "Episode: 768, Total Steps: 300, Total Reward: -300\n",
            "Episode: 769, Total Steps: 300, Total Reward: -300\n",
            "Episode: 770, Total Steps: 300, Total Reward: -300\n",
            "Episode: 771, Total Steps: 300, Total Reward: -300\n",
            "Episode: 772, Total Steps: 300, Total Reward: -300\n",
            "Episode: 773, Total Steps: 300, Total Reward: -300\n",
            "Episode: 774, Total Steps: 300, Total Reward: -300\n",
            "Episode: 775, Total Steps: 300, Total Reward: -300\n",
            "Episode: 776, Total Steps: 300, Total Reward: -300\n",
            "Episode: 777, Total Steps: 300, Total Reward: -300\n",
            "Episode: 778, Total Steps: 300, Total Reward: -300\n",
            "Episode: 779, Total Steps: 300, Total Reward: -300\n",
            "Episode: 780, Total Steps: 300, Total Reward: -300\n",
            "Episode: 781, Total Steps: 300, Total Reward: -300\n",
            "Episode: 782, Total Steps: 300, Total Reward: -300\n",
            "Episode: 783, Total Steps: 300, Total Reward: -300\n",
            "Episode: 784, Total Steps: 300, Total Reward: -300\n",
            "Episode: 785, Total Steps: 300, Total Reward: -300\n",
            "Episode: 786, Total Steps: 300, Total Reward: -300\n",
            "Episode: 787, Total Steps: 300, Total Reward: -300\n",
            "Episode: 788, Total Steps: 300, Total Reward: -300\n",
            "Episode: 789, Total Steps: 300, Total Reward: -300\n",
            "Episode: 790, Total Steps: 300, Total Reward: -300\n",
            "Episode: 791, Total Steps: 300, Total Reward: -300\n",
            "Episode: 792, Total Steps: 300, Total Reward: -300\n",
            "Episode: 793, Total Steps: 300, Total Reward: -300\n",
            "Episode: 794, Total Steps: 300, Total Reward: -300\n",
            "Episode: 795, Total Steps: 300, Total Reward: -300\n",
            "Episode: 796, Total Steps: 300, Total Reward: -300\n",
            "Episode: 797, Total Steps: 300, Total Reward: -300\n",
            "Episode: 798, Total Steps: 300, Total Reward: -300\n",
            "Episode: 799, Total Steps: 300, Total Reward: -300\n",
            "Episode: 800, Total Steps: 300, Total Reward: -300\n",
            "Episode: 801, Total Steps: 300, Total Reward: -300\n",
            "Episode: 802, Total Steps: 300, Total Reward: -300\n",
            "Episode: 803, Total Steps: 300, Total Reward: -300\n",
            "Episode: 804, Total Steps: 300, Total Reward: -300\n",
            "Episode: 805, Total Steps: 300, Total Reward: -300\n",
            "Episode: 806, Total Steps: 300, Total Reward: -300\n",
            "Episode: 807, Total Steps: 300, Total Reward: -300\n",
            "Episode: 808, Total Steps: 300, Total Reward: -300\n",
            "Episode: 809, Total Steps: 300, Total Reward: -300\n",
            "Episode: 810, Total Steps: 300, Total Reward: -300\n",
            "Episode: 811, Total Steps: 300, Total Reward: -300\n",
            "Episode: 812, Total Steps: 300, Total Reward: -300\n",
            "Episode: 813, Total Steps: 300, Total Reward: -300\n",
            "Episode: 814, Total Steps: 300, Total Reward: -300\n",
            "Episode: 815, Total Steps: 300, Total Reward: -300\n",
            "Episode: 816, Total Steps: 300, Total Reward: -300\n",
            "Episode: 817, Total Steps: 300, Total Reward: -300\n",
            "Episode: 818, Total Steps: 300, Total Reward: -300\n",
            "Episode: 819, Total Steps: 300, Total Reward: -300\n",
            "Episode: 820, Total Steps: 300, Total Reward: -300\n",
            "Episode: 821, Total Steps: 300, Total Reward: -300\n",
            "Episode: 822, Total Steps: 300, Total Reward: -300\n",
            "Episode: 823, Total Steps: 300, Total Reward: -300\n",
            "Episode: 824, Total Steps: 300, Total Reward: -300\n",
            "Episode: 825, Total Steps: 300, Total Reward: -300\n",
            "Episode: 826, Total Steps: 300, Total Reward: -300\n",
            "Episode: 827, Total Steps: 300, Total Reward: -300\n",
            "Episode: 828, Total Steps: 300, Total Reward: -300\n",
            "Episode: 829, Total Steps: 300, Total Reward: -300\n",
            "Episode: 830, Total Steps: 300, Total Reward: -300\n",
            "Episode: 831, Total Steps: 300, Total Reward: -300\n",
            "Episode: 832, Total Steps: 300, Total Reward: -300\n",
            "Episode: 833, Total Steps: 300, Total Reward: -300\n",
            "Episode: 834, Total Steps: 300, Total Reward: -300\n",
            "Episode: 835, Total Steps: 300, Total Reward: -300\n",
            "Episode: 836, Total Steps: 300, Total Reward: -300\n",
            "Episode: 837, Total Steps: 300, Total Reward: -300\n",
            "Episode: 838, Total Steps: 300, Total Reward: -300\n",
            "Episode: 839, Total Steps: 300, Total Reward: -300\n",
            "Episode: 840, Total Steps: 300, Total Reward: -300\n",
            "Episode: 841, Total Steps: 300, Total Reward: -300\n",
            "Episode: 842, Total Steps: 300, Total Reward: -300\n",
            "Episode: 843, Total Steps: 300, Total Reward: -300\n",
            "Episode: 844, Total Steps: 300, Total Reward: -300\n",
            "Episode: 845, Total Steps: 300, Total Reward: -300\n",
            "Episode: 846, Total Steps: 300, Total Reward: -300\n",
            "Episode: 847, Total Steps: 300, Total Reward: -300\n",
            "Episode: 848, Total Steps: 300, Total Reward: -300\n",
            "Episode: 849, Total Steps: 300, Total Reward: -300\n",
            "Episode: 850, Total Steps: 300, Total Reward: -300\n",
            "Episode: 851, Total Steps: 300, Total Reward: -300\n",
            "Episode: 852, Total Steps: 300, Total Reward: -300\n",
            "Episode: 853, Total Steps: 300, Total Reward: -300\n",
            "Episode: 854, Total Steps: 300, Total Reward: -300\n",
            "Episode: 855, Total Steps: 300, Total Reward: -300\n",
            "Episode: 856, Total Steps: 300, Total Reward: -300\n",
            "Episode: 857, Total Steps: 300, Total Reward: -300\n",
            "Episode: 858, Total Steps: 300, Total Reward: -300\n",
            "Episode: 859, Total Steps: 300, Total Reward: -300\n",
            "Episode: 860, Total Steps: 300, Total Reward: -300\n",
            "Episode: 861, Total Steps: 300, Total Reward: -300\n",
            "Episode: 862, Total Steps: 300, Total Reward: -300\n",
            "Episode: 863, Total Steps: 300, Total Reward: -300\n",
            "Episode: 864, Total Steps: 300, Total Reward: -300\n",
            "Episode: 865, Total Steps: 300, Total Reward: -300\n",
            "Episode: 866, Total Steps: 300, Total Reward: -300\n",
            "Episode: 867, Total Steps: 300, Total Reward: -300\n",
            "Episode: 868, Total Steps: 300, Total Reward: -300\n",
            "Episode: 869, Total Steps: 300, Total Reward: -300\n",
            "Episode: 870, Total Steps: 300, Total Reward: -300\n",
            "Episode: 871, Total Steps: 300, Total Reward: -300\n",
            "Episode: 872, Total Steps: 300, Total Reward: -300\n",
            "Episode: 873, Total Steps: 300, Total Reward: -300\n",
            "Episode: 874, Total Steps: 300, Total Reward: -300\n",
            "Episode: 875, Total Steps: 300, Total Reward: -300\n",
            "Episode: 876, Total Steps: 300, Total Reward: -300\n",
            "Episode: 877, Total Steps: 300, Total Reward: -300\n",
            "Episode: 878, Total Steps: 300, Total Reward: -300\n",
            "Episode: 879, Total Steps: 300, Total Reward: -300\n",
            "Episode: 880, Total Steps: 300, Total Reward: -300\n",
            "Episode: 881, Total Steps: 300, Total Reward: -300\n",
            "Episode: 882, Total Steps: 300, Total Reward: -300\n",
            "Episode: 883, Total Steps: 300, Total Reward: -300\n",
            "Episode: 884, Total Steps: 300, Total Reward: -300\n",
            "Episode: 885, Total Steps: 300, Total Reward: -300\n",
            "Episode: 886, Total Steps: 300, Total Reward: -300\n",
            "Episode: 887, Total Steps: 300, Total Reward: -300\n",
            "Episode: 888, Total Steps: 300, Total Reward: -300\n",
            "Episode: 889, Total Steps: 300, Total Reward: -300\n",
            "Episode: 890, Total Steps: 300, Total Reward: -300\n",
            "Episode: 891, Total Steps: 300, Total Reward: -300\n",
            "Episode: 892, Total Steps: 300, Total Reward: -300\n",
            "Episode: 893, Total Steps: 300, Total Reward: -300\n",
            "Episode: 894, Total Steps: 300, Total Reward: -300\n",
            "Episode: 895, Total Steps: 300, Total Reward: -300\n",
            "Episode: 896, Total Steps: 300, Total Reward: -300\n",
            "Episode: 897, Total Steps: 300, Total Reward: -300\n",
            "Episode: 898, Total Steps: 300, Total Reward: -300\n",
            "Episode: 899, Total Steps: 300, Total Reward: -300\n",
            "Episode: 900, Total Steps: 300, Total Reward: -300\n",
            "Episode: 901, Total Steps: 300, Total Reward: -300\n",
            "Episode: 902, Total Steps: 300, Total Reward: -300\n",
            "Episode: 903, Total Steps: 300, Total Reward: -300\n",
            "Episode: 904, Total Steps: 300, Total Reward: -300\n",
            "Episode: 905, Total Steps: 300, Total Reward: -300\n",
            "Episode: 906, Total Steps: 300, Total Reward: -300\n",
            "Episode: 907, Total Steps: 300, Total Reward: -300\n",
            "Episode: 908, Total Steps: 300, Total Reward: -300\n",
            "Episode: 909, Total Steps: 300, Total Reward: -300\n",
            "Episode: 910, Total Steps: 300, Total Reward: -300\n",
            "Episode: 911, Total Steps: 300, Total Reward: -300\n",
            "Episode: 912, Total Steps: 300, Total Reward: -300\n",
            "Episode: 913, Total Steps: 300, Total Reward: -300\n",
            "Episode: 914, Total Steps: 300, Total Reward: -300\n",
            "Episode: 915, Total Steps: 300, Total Reward: -300\n",
            "Episode: 916, Total Steps: 300, Total Reward: -300\n",
            "Episode: 917, Total Steps: 300, Total Reward: -300\n",
            "Episode: 918, Total Steps: 300, Total Reward: -300\n",
            "Episode: 919, Total Steps: 300, Total Reward: -300\n",
            "Episode: 920, Total Steps: 300, Total Reward: -300\n",
            "Episode: 921, Total Steps: 300, Total Reward: -300\n",
            "Episode: 922, Total Steps: 300, Total Reward: -300\n",
            "Episode: 923, Total Steps: 300, Total Reward: -300\n",
            "Episode: 924, Total Steps: 300, Total Reward: -300\n",
            "Episode: 925, Total Steps: 300, Total Reward: -300\n",
            "Episode: 926, Total Steps: 300, Total Reward: -300\n",
            "Episode: 927, Total Steps: 300, Total Reward: -300\n",
            "Episode: 928, Total Steps: 300, Total Reward: -300\n",
            "Episode: 929, Total Steps: 300, Total Reward: -300\n",
            "Episode: 930, Total Steps: 300, Total Reward: -300\n",
            "Episode: 931, Total Steps: 300, Total Reward: -300\n",
            "Episode: 932, Total Steps: 300, Total Reward: -300\n",
            "Episode: 933, Total Steps: 300, Total Reward: -300\n",
            "Episode: 934, Total Steps: 300, Total Reward: -300\n",
            "Episode: 935, Total Steps: 300, Total Reward: -300\n",
            "Episode: 936, Total Steps: 300, Total Reward: -300\n",
            "Episode: 937, Total Steps: 300, Total Reward: -300\n",
            "Episode: 938, Total Steps: 300, Total Reward: -300\n",
            "Episode: 939, Total Steps: 300, Total Reward: -300\n",
            "Episode: 940, Total Steps: 300, Total Reward: -300\n",
            "Episode: 941, Total Steps: 300, Total Reward: -300\n",
            "Episode: 942, Total Steps: 300, Total Reward: -300\n",
            "Episode: 943, Total Steps: 300, Total Reward: -300\n",
            "Episode: 944, Total Steps: 300, Total Reward: -300\n",
            "Episode: 945, Total Steps: 300, Total Reward: -300\n",
            "Episode: 946, Total Steps: 300, Total Reward: -300\n",
            "Episode: 947, Total Steps: 300, Total Reward: -300\n",
            "Episode: 948, Total Steps: 300, Total Reward: -300\n",
            "Episode: 949, Total Steps: 300, Total Reward: -300\n",
            "Episode: 950, Total Steps: 300, Total Reward: -300\n",
            "Episode: 951, Total Steps: 300, Total Reward: -300\n",
            "Episode: 952, Total Steps: 300, Total Reward: -300\n",
            "Episode: 953, Total Steps: 300, Total Reward: -300\n",
            "Episode: 954, Total Steps: 300, Total Reward: -300\n",
            "Episode: 955, Total Steps: 300, Total Reward: -300\n",
            "Episode: 956, Total Steps: 300, Total Reward: -300\n",
            "Episode: 957, Total Steps: 300, Total Reward: -300\n",
            "Episode: 958, Total Steps: 300, Total Reward: -300\n",
            "Episode: 959, Total Steps: 300, Total Reward: -300\n",
            "Episode: 960, Total Steps: 300, Total Reward: -300\n",
            "Episode: 961, Total Steps: 300, Total Reward: -300\n",
            "Episode: 962, Total Steps: 300, Total Reward: -300\n",
            "Episode: 963, Total Steps: 300, Total Reward: -300\n",
            "Episode: 964, Total Steps: 300, Total Reward: -300\n",
            "Episode: 965, Total Steps: 300, Total Reward: -300\n",
            "Episode: 966, Total Steps: 300, Total Reward: -300\n",
            "Episode: 967, Total Steps: 300, Total Reward: -300\n",
            "Episode: 968, Total Steps: 300, Total Reward: -300\n",
            "Episode: 969, Total Steps: 300, Total Reward: -300\n",
            "Episode: 970, Total Steps: 300, Total Reward: -300\n",
            "Episode: 971, Total Steps: 300, Total Reward: -300\n",
            "Episode: 972, Total Steps: 300, Total Reward: -300\n",
            "Episode: 973, Total Steps: 300, Total Reward: -300\n",
            "Episode: 974, Total Steps: 300, Total Reward: -300\n",
            "Episode: 975, Total Steps: 300, Total Reward: -300\n",
            "Episode: 976, Total Steps: 300, Total Reward: -300\n",
            "Episode: 977, Total Steps: 300, Total Reward: -300\n",
            "Episode: 978, Total Steps: 300, Total Reward: -300\n",
            "Episode: 979, Total Steps: 300, Total Reward: -300\n",
            "Episode: 980, Total Steps: 300, Total Reward: -300\n",
            "Episode: 981, Total Steps: 300, Total Reward: -300\n",
            "Episode: 982, Total Steps: 300, Total Reward: -300\n",
            "Episode: 983, Total Steps: 300, Total Reward: -300\n",
            "Episode: 984, Total Steps: 300, Total Reward: -300\n",
            "Episode: 985, Total Steps: 300, Total Reward: -300\n",
            "Episode: 986, Total Steps: 300, Total Reward: -300\n",
            "Episode: 987, Total Steps: 300, Total Reward: -300\n",
            "Episode: 988, Total Steps: 300, Total Reward: -300\n",
            "Episode: 989, Total Steps: 300, Total Reward: -300\n",
            "Episode: 990, Total Steps: 300, Total Reward: -300\n",
            "Episode: 991, Total Steps: 300, Total Reward: -300\n",
            "Episode: 992, Total Steps: 300, Total Reward: -300\n",
            "Episode: 993, Total Steps: 300, Total Reward: -300\n",
            "Episode: 994, Total Steps: 300, Total Reward: -300\n",
            "Episode: 995, Total Steps: 300, Total Reward: -300\n",
            "Episode: 996, Total Steps: 300, Total Reward: -300\n",
            "Episode: 997, Total Steps: 300, Total Reward: -300\n",
            "Episode: 998, Total Steps: 300, Total Reward: -300\n",
            "Episode: 999, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1000, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1001, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1002, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1003, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1004, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1005, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1006, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1007, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1008, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1009, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1010, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1011, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1012, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1013, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1014, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1015, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1016, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1017, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1018, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1019, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1020, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1021, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1022, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1023, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1024, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1025, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1026, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1027, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1028, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1029, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1030, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1031, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1032, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1033, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1034, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1035, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1036, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1037, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1038, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1039, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1040, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1041, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1042, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1043, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1044, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1045, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1046, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1047, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1048, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1049, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1050, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1051, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1052, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1053, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1054, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1055, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1056, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1057, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1058, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1059, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1060, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1061, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1062, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1063, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1064, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1065, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1066, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1067, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1068, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1069, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1070, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1071, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1072, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1073, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1074, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1075, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1076, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1077, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1078, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1079, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1080, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1081, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1082, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1083, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1084, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1085, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1086, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1087, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1088, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1089, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1090, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1091, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1092, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1093, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1094, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1095, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1096, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1097, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1098, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1099, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1100, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1101, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1102, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1103, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1104, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1105, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1106, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1107, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1108, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1109, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1110, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1111, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1112, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1113, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1114, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1115, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1116, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1117, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1118, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1119, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1120, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1121, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1122, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1123, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1124, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1125, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1126, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1127, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1128, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1129, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1130, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1131, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1132, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1133, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1134, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1135, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1136, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1137, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1138, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1139, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1140, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1141, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1142, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1143, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1144, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1145, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1146, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1147, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1148, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1149, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1150, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1151, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1152, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1153, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1154, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1155, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1156, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1157, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1158, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1159, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1160, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1161, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1162, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1163, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1164, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1165, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1166, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1167, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1168, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1169, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1170, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1171, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1172, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1173, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1174, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1175, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1176, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1177, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1178, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1179, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1180, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1181, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1182, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1183, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1184, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1185, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1186, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1187, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1188, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1189, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1190, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1191, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1192, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1193, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1194, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1195, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1196, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1197, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1198, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1199, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1200, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1201, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1202, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1203, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1204, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1205, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1206, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1207, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1208, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1209, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1210, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1211, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1212, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1213, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1214, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1215, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1216, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1217, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1218, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1219, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1220, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1221, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1222, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1223, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1224, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1225, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1226, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1227, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1228, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1229, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1230, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1231, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1232, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1233, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1234, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1235, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1236, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1237, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1238, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1239, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1240, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1241, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1242, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1243, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1244, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1245, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1246, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1247, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1248, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1249, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1250, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1251, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1252, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1253, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1254, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1255, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1256, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1257, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1258, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1259, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1260, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1261, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1262, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1263, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1264, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1265, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1266, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1267, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1268, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1269, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1270, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1271, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1272, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1273, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1274, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1275, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1276, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1277, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1278, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1279, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1280, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1281, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1282, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1283, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1284, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1285, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1286, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1287, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1288, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1289, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1290, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1291, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1292, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1293, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1294, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1295, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1296, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1297, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1298, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1299, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1300, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1301, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1302, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1303, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1304, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1305, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1306, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1307, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1308, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1309, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1310, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1311, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1312, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1313, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1314, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1315, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1316, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1317, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1318, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1319, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1320, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1321, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1322, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1323, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1324, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1325, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1326, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1327, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1328, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1329, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1330, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1331, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1332, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1333, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1334, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1335, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1336, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1337, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1338, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1339, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1340, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1341, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1342, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1343, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1344, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1345, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1346, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1347, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1348, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1349, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1350, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1351, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1352, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1353, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1354, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1355, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1356, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1357, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1358, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1359, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1360, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1361, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1362, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1363, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1364, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1365, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1366, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1367, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1368, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1369, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1370, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1371, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1372, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1373, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1374, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1375, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1376, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1377, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1378, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1379, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1380, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1381, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1382, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1383, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1384, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1385, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1386, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1387, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1388, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1389, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1390, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1391, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1392, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1393, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1394, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1395, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1396, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1397, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1398, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1399, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1400, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1401, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1402, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1403, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1404, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1405, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1406, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1407, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1408, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1409, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1410, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1411, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1412, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1413, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1414, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1415, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1416, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1417, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1418, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1419, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1420, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1421, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1422, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1423, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1424, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1425, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1426, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1427, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1428, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1429, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1430, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1431, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1432, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1433, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1434, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1435, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1436, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1437, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1438, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1439, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1440, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1441, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1442, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1443, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1444, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1445, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1446, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1447, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1448, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1449, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1450, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1451, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1452, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1453, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1454, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1455, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1456, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1457, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1458, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1459, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1460, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1461, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1462, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1463, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1464, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1465, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1466, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1467, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1468, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1469, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1470, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1471, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1472, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1473, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1474, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1475, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1476, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1477, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1478, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1479, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1480, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1481, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1482, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1483, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1484, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1485, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1486, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1487, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1488, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1489, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1490, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1491, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1492, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1493, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1494, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1495, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1496, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1497, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1498, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1499, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1500, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1501, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1502, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1503, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1504, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1505, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1506, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1507, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1508, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1509, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1510, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1511, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1512, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1513, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1514, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1515, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1516, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1517, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1518, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1519, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1520, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1521, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1522, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1523, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1524, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1525, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1526, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1527, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1528, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1529, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1530, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1531, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1532, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1533, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1534, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1535, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1536, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1537, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1538, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1539, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1540, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1541, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1542, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1543, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1544, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1545, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1546, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1547, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1548, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1549, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1550, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1551, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1552, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1553, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1554, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1555, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1556, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1557, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1558, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1559, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1560, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1561, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1562, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1563, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1564, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1565, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1566, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1567, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1568, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1569, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1570, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1571, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1572, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1573, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1574, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1575, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1576, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1577, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1578, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1579, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1580, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1581, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1582, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1583, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1584, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1585, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1586, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1587, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1588, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1589, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1590, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1591, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1592, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1593, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1594, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1595, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1596, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1597, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1598, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1599, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1600, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1601, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1602, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1603, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1604, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1605, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1606, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1607, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1608, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1609, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1610, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1611, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1612, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1613, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1614, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1615, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1616, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1617, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1618, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1619, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1620, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1621, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1622, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1623, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1624, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1625, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1626, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1627, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1628, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1629, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1630, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1631, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1632, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1633, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1634, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1635, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1636, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1637, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1638, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1639, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1640, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1641, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1642, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1643, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1644, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1645, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1646, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1647, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1648, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1649, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1650, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1651, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1652, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1653, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1654, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1655, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1656, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1657, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1658, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1659, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1660, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1661, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1662, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1663, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1664, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1665, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1666, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1667, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1668, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1669, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1670, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1671, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1672, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1673, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1674, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1675, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1676, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1677, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1678, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1679, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1680, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1681, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1682, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1683, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1684, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1685, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1686, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1687, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1688, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1689, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1690, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1691, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1692, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1693, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1694, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1695, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1696, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1697, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1698, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1699, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1700, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1701, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1702, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1703, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1704, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1705, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1706, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1707, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1708, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1709, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1710, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1711, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1712, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1713, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1714, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1715, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1716, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1717, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1718, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1719, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1720, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1721, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1722, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1723, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1724, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1725, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1726, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1727, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1728, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1729, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1730, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1731, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1732, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1733, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1734, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1735, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1736, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1737, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1738, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1739, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1740, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1741, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1742, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1743, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1744, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1745, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1746, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1747, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1748, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1749, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1750, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1751, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1752, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1753, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1754, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1755, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1756, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1757, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1758, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1759, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1760, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1761, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1762, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1763, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1764, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1765, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1766, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1767, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1768, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1769, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1770, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1771, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1772, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1773, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1774, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1775, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1776, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1777, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1778, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1779, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1780, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1781, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1782, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1783, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1784, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1785, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1786, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1787, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1788, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1789, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1790, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1791, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1792, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1793, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1794, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1795, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1796, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1797, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1798, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1799, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1800, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1801, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1802, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1803, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1804, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1805, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1806, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1807, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1808, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1809, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1810, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1811, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1812, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1813, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1814, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1815, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1816, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1817, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1818, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1819, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1820, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1821, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1822, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1823, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1824, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1825, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1826, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1827, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1828, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1829, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1830, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1831, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1832, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1833, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1834, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1835, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1836, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1837, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1838, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1839, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1840, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1841, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1842, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1843, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1844, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1845, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1846, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1847, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1848, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1849, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1850, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1851, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1852, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1853, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1854, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1855, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1856, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1857, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1858, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1859, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1860, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1861, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1862, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1863, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1864, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1865, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1866, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1867, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1868, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1869, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1870, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1871, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1872, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1873, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1874, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1875, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1876, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1877, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1878, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1879, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1880, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1881, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1882, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1883, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1884, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1885, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1886, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1887, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1888, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1889, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1890, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1891, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1892, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1893, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1894, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1895, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1896, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1897, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1898, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1899, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1900, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1901, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1902, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1903, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1904, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1905, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1906, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1907, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1908, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1909, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1910, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1911, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1912, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1913, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1914, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1915, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1916, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1917, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1918, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1919, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1920, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1921, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1922, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1923, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1924, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1925, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1926, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1927, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1928, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1929, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1930, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1931, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1932, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1933, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1934, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1935, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1936, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1937, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1938, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1939, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1940, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1941, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1942, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1943, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1944, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1945, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1946, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1947, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1948, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1949, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1950, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1951, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1952, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1953, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1954, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1955, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1956, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1957, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1958, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1959, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1960, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1961, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1962, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1963, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1964, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1965, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1966, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1967, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1968, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1969, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1970, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1971, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1972, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1973, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1974, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1975, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1976, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1977, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1978, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1979, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1980, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1981, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1982, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1983, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1984, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1985, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1986, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1987, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1988, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1989, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1990, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1991, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1992, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1993, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1994, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1995, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1996, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1997, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1998, Total Steps: 300, Total Reward: -300\n",
            "Episode: 1999, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2000, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2001, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2002, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2003, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2004, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2005, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2006, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2007, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2008, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2009, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2010, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2011, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2012, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2013, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2014, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2015, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2016, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2017, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2018, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2019, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2020, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2021, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2022, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2023, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2024, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2025, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2026, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2027, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2028, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2029, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2030, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2031, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2032, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2033, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2034, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2035, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2036, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2037, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2038, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2039, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2040, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2041, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2042, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2043, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2044, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2045, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2046, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2047, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2048, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2049, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2050, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2051, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2052, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2053, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2054, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2055, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2056, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2057, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2058, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2059, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2060, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2061, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2062, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2063, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2064, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2065, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2066, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2067, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2068, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2069, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2070, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2071, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2072, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2073, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2074, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2075, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2076, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2077, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2078, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2079, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2080, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2081, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2082, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2083, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2084, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2085, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2086, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2087, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2088, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2089, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2090, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2091, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2092, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2093, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2094, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2095, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2096, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2097, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2098, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2099, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2100, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2101, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2102, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2103, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2104, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2105, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2106, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2107, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2108, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2109, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2110, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2111, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2112, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2113, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2114, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2115, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2116, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2117, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2118, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2119, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2120, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2121, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2122, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2123, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2124, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2125, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2126, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2127, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2128, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2129, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2130, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2131, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2132, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2133, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2134, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2135, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2136, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2137, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2138, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2139, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2140, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2141, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2142, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2143, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2144, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2145, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2146, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2147, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2148, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2149, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2150, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2151, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2152, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2153, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2154, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2155, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2156, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2157, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2158, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2159, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2160, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2161, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2162, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2163, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2164, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2165, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2166, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2167, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2168, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2169, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2170, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2171, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2172, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2173, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2174, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2175, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2176, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2177, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2178, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2179, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2180, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2181, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2182, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2183, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2184, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2185, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2186, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2187, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2188, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2189, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2190, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2191, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2192, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2193, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2194, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2195, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2196, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2197, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2198, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2199, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2200, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2201, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2202, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2203, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2204, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2205, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2206, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2207, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2208, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2209, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2210, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2211, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2212, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2213, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2214, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2215, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2216, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2217, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2218, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2219, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2220, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2221, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2222, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2223, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2224, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2225, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2226, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2227, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2228, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2229, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2230, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2231, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2232, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2233, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2234, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2235, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2236, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2237, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2238, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2239, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2240, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2241, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2242, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2243, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2244, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2245, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2246, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2247, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2248, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2249, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2250, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2251, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2252, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2253, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2254, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2255, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2256, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2257, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2258, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2259, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2260, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2261, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2262, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2263, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2264, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2265, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2266, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2267, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2268, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2269, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2270, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2271, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2272, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2273, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2274, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2275, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2276, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2277, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2278, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2279, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2280, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2281, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2282, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2283, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2284, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2285, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2286, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2287, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2288, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2289, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2290, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2291, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2292, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2293, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2294, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2295, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2296, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2297, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2298, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2299, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2300, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2301, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2302, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2303, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2304, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2305, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2306, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2307, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2308, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2309, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2310, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2311, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2312, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2313, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2314, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2315, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2316, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2317, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2318, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2319, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2320, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2321, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2322, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2323, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2324, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2325, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2326, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2327, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2328, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2329, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2330, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2331, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2332, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2333, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2334, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2335, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2336, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2337, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2338, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2339, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2340, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2341, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2342, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2343, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2344, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2345, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2346, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2347, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2348, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2349, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2350, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2351, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2352, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2353, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2354, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2355, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2356, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2357, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2358, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2359, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2360, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2361, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2362, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2363, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2364, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2365, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2366, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2367, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2368, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2369, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2370, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2371, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2372, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2373, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2374, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2375, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2376, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2377, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2378, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2379, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2380, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2381, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2382, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2383, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2384, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2385, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2386, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2387, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2388, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2389, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2390, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2391, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2392, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2393, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2394, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2395, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2396, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2397, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2398, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2399, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2400, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2401, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2402, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2403, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2404, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2405, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2406, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2407, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2408, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2409, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2410, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2411, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2412, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2413, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2414, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2415, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2416, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2417, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2418, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2419, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2420, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2421, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2422, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2423, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2424, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2425, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2426, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2427, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2428, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2429, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2430, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2431, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2432, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2433, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2434, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2435, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2436, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2437, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2438, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2439, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2440, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2441, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2442, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2443, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2444, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2445, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2446, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2447, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2448, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2449, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2450, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2451, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2452, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2453, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2454, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2455, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2456, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2457, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2458, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2459, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2460, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2461, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2462, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2463, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2464, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2465, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2466, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2467, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2468, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2469, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2470, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2471, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2472, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2473, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2474, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2475, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2476, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2477, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2478, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2479, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2480, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2481, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2482, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2483, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2484, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2485, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2486, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2487, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2488, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2489, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2490, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2491, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2492, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2493, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2494, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2495, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2496, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2497, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2498, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2499, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2500, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2501, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2502, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2503, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2504, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2505, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2506, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2507, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2508, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2509, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2510, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2511, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2512, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2513, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2514, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2515, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2516, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2517, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2518, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2519, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2520, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2521, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2522, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2523, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2524, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2525, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2526, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2527, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2528, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2529, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2530, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2531, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2532, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2533, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2534, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2535, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2536, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2537, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2538, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2539, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2540, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2541, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2542, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2543, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2544, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2545, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2546, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2547, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2548, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2549, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2550, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2551, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2552, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2553, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2554, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2555, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2556, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2557, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2558, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2559, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2560, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2561, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2562, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2563, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2564, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2565, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2566, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2567, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2568, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2569, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2570, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2571, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2572, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2573, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2574, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2575, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2576, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2577, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2578, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2579, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2580, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2581, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2582, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2583, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2584, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2585, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2586, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2587, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2588, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2589, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2590, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2591, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2592, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2593, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2594, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2595, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2596, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2597, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2598, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2599, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2600, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2601, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2602, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2603, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2604, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2605, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2606, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2607, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2608, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2609, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2610, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2611, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2612, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2613, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2614, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2615, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2616, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2617, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2618, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2619, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2620, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2621, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2622, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2623, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2624, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2625, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2626, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2627, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2628, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2629, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2630, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2631, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2632, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2633, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2634, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2635, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2636, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2637, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2638, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2639, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2640, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2641, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2642, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2643, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2644, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2645, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2646, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2647, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2648, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2649, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2650, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2651, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2652, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2653, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2654, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2655, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2656, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2657, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2658, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2659, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2660, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2661, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2662, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2663, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2664, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2665, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2666, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2667, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2668, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2669, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2670, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2671, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2672, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2673, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2674, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2675, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2676, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2677, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2678, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2679, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2680, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2681, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2682, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2683, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2684, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2685, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2686, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2687, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2688, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2689, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2690, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2691, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2692, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2693, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2694, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2695, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2696, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2697, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2698, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2699, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2700, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2701, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2702, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2703, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2704, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2705, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2706, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2707, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2708, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2709, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2710, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2711, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2712, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2713, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2714, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2715, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2716, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2717, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2718, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2719, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2720, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2721, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2722, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2723, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2724, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2725, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2726, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2727, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2728, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2729, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2730, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2731, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2732, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2733, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2734, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2735, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2736, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2737, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2738, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2739, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2740, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2741, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2742, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2743, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2744, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2745, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2746, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2747, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2748, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2749, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2750, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2751, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2752, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2753, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2754, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2755, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2756, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2757, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2758, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2759, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2760, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2761, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2762, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2763, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2764, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2765, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2766, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2767, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2768, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2769, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2770, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2771, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2772, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2773, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2774, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2775, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2776, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2777, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2778, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2779, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2780, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2781, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2782, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2783, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2784, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2785, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2786, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2787, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2788, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2789, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2790, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2791, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2792, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2793, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2794, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2795, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2796, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2797, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2798, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2799, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2800, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2801, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2802, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2803, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2804, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2805, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2806, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2807, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2808, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2809, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2810, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2811, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2812, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2813, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2814, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2815, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2816, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2817, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2818, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2819, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2820, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2821, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2822, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2823, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2824, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2825, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2826, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2827, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2828, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2829, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2830, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2831, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2832, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2833, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2834, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2835, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2836, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2837, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2838, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2839, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2840, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2841, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2842, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2843, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2844, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2845, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2846, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2847, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2848, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2849, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2850, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2851, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2852, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2853, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2854, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2855, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2856, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2857, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2858, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2859, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2860, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2861, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2862, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2863, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2864, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2865, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2866, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2867, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2868, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2869, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2870, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2871, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2872, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2873, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2874, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2875, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2876, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2877, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2878, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2879, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2880, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2881, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2882, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2883, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2884, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2885, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2886, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2887, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2888, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2889, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2890, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2891, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2892, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2893, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2894, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2895, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2896, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2897, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2898, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2899, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2900, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2901, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2902, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2903, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2904, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2905, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2906, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2907, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2908, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2909, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2910, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2911, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2912, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2913, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2914, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2915, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2916, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2917, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2918, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2919, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2920, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2921, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2922, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2923, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2924, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2925, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2926, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2927, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2928, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2929, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2930, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2931, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2932, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2933, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2934, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2935, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2936, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2937, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2938, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2939, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2940, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2941, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2942, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2943, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2944, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2945, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2946, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2947, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2948, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2949, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2950, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2951, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2952, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2953, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2954, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2955, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2956, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2957, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2958, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2959, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2960, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2961, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2962, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2963, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2964, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2965, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2966, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2967, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2968, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2969, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2970, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2971, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2972, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2973, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2974, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2975, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2976, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2977, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2978, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2979, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2980, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2981, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2982, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2983, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2984, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2985, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2986, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2987, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2988, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2989, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2990, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2991, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2992, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2993, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2994, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2995, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2996, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2997, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2998, Total Steps: 300, Total Reward: -300\n",
            "Episode: 2999, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3000, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3001, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3002, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3003, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3004, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3005, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3006, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3007, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3008, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3009, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3010, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3011, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3012, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3013, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3014, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3015, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3016, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3017, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3018, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3019, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3020, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3021, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3022, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3023, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3024, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3025, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3026, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3027, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3028, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3029, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3030, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3031, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3032, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3033, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3034, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3035, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3036, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3037, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3038, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3039, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3040, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3041, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3042, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3043, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3044, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3045, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3046, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3047, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3048, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3049, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3050, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3051, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3052, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3053, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3054, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3055, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3056, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3057, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3058, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3059, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3060, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3061, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3062, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3063, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3064, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3065, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3066, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3067, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3068, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3069, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3070, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3071, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3072, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3073, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3074, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3075, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3076, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3077, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3078, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3079, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3080, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3081, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3082, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3083, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3084, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3085, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3086, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3087, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3088, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3089, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3090, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3091, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3092, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3093, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3094, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3095, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3096, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3097, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3098, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3099, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3100, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3101, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3102, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3103, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3104, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3105, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3106, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3107, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3108, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3109, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3110, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3111, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3112, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3113, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3114, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3115, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3116, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3117, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3118, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3119, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3120, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3121, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3122, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3123, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3124, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3125, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3126, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3127, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3128, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3129, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3130, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3131, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3132, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3133, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3134, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3135, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3136, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3137, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3138, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3139, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3140, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3141, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3142, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3143, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3144, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3145, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3146, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3147, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3148, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3149, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3150, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3151, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3152, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3153, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3154, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3155, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3156, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3157, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3158, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3159, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3160, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3161, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3162, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3163, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3164, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3165, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3166, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3167, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3168, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3169, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3170, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3171, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3172, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3173, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3174, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3175, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3176, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3177, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3178, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3179, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3180, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3181, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3182, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3183, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3184, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3185, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3186, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3187, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3188, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3189, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3190, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3191, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3192, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3193, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3194, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3195, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3196, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3197, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3198, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3199, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3200, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3201, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3202, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3203, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3204, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3205, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3206, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3207, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3208, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3209, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3210, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3211, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3212, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3213, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3214, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3215, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3216, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3217, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3218, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3219, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3220, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3221, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3222, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3223, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3224, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3225, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3226, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3227, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3228, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3229, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3230, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3231, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3232, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3233, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3234, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3235, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3236, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3237, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3238, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3239, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3240, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3241, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3242, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3243, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3244, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3245, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3246, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3247, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3248, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3249, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3250, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3251, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3252, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3253, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3254, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3255, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3256, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3257, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3258, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3259, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3260, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3261, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3262, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3263, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3264, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3265, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3266, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3267, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3268, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3269, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3270, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3271, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3272, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3273, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3274, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3275, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3276, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3277, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3278, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3279, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3280, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3281, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3282, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3283, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3284, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3285, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3286, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3287, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3288, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3289, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3290, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3291, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3292, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3293, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3294, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3295, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3296, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3297, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3298, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3299, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3300, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3301, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3302, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3303, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3304, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3305, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3306, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3307, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3308, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3309, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3310, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3311, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3312, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3313, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3314, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3315, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3316, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3317, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3318, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3319, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3320, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3321, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3322, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3323, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3324, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3325, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3326, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3327, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3328, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3329, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3330, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3331, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3332, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3333, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3334, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3335, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3336, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3337, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3338, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3339, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3340, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3341, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3342, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3343, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3344, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3345, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3346, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3347, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3348, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3349, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3350, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3351, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3352, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3353, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3354, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3355, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3356, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3357, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3358, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3359, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3360, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3361, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3362, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3363, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3364, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3365, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3366, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3367, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3368, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3369, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3370, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3371, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3372, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3373, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3374, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3375, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3376, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3377, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3378, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3379, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3380, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3381, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3382, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3383, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3384, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3385, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3386, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3387, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3388, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3389, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3390, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3391, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3392, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3393, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3394, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3395, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3396, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3397, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3398, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3399, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3400, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3401, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3402, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3403, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3404, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3405, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3406, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3407, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3408, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3409, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3410, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3411, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3412, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3413, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3414, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3415, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3416, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3417, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3418, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3419, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3420, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3421, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3422, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3423, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3424, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3425, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3426, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3427, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3428, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3429, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3430, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3431, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3432, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3433, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3434, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3435, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3436, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3437, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3438, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3439, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3440, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3441, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3442, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3443, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3444, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3445, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3446, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3447, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3448, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3449, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3450, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3451, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3452, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3453, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3454, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3455, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3456, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3457, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3458, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3459, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3460, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3461, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3462, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3463, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3464, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3465, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3466, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3467, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3468, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3469, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3470, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3471, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3472, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3473, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3474, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3475, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3476, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3477, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3478, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3479, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3480, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3481, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3482, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3483, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3484, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3485, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3486, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3487, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3488, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3489, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3490, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3491, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3492, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3493, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3494, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3495, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3496, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3497, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3498, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3499, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3500, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3501, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3502, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3503, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3504, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3505, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3506, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3507, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3508, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3509, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3510, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3511, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3512, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3513, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3514, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3515, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3516, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3517, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3518, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3519, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3520, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3521, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3522, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3523, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3524, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3525, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3526, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3527, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3528, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3529, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3530, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3531, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3532, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3533, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3534, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3535, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3536, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3537, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3538, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3539, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3540, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3541, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3542, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3543, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3544, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3545, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3546, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3547, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3548, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3549, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3550, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3551, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3552, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3553, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3554, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3555, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3556, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3557, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3558, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3559, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3560, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3561, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3562, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3563, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3564, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3565, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3566, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3567, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3568, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3569, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3570, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3571, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3572, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3573, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3574, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3575, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3576, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3577, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3578, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3579, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3580, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3581, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3582, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3583, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3584, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3585, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3586, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3587, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3588, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3589, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3590, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3591, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3592, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3593, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3594, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3595, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3596, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3597, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3598, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3599, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3600, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3601, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3602, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3603, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3604, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3605, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3606, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3607, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3608, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3609, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3610, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3611, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3612, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3613, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3614, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3615, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3616, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3617, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3618, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3619, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3620, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3621, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3622, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3623, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3624, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3625, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3626, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3627, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3628, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3629, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3630, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3631, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3632, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3633, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3634, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3635, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3636, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3637, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3638, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3639, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3640, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3641, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3642, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3643, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3644, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3645, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3646, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3647, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3648, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3649, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3650, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3651, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3652, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3653, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3654, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3655, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3656, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3657, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3658, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3659, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3660, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3661, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3662, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3663, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3664, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3665, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3666, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3667, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3668, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3669, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3670, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3671, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3672, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3673, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3674, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3675, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3676, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3677, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3678, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3679, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3680, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3681, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3682, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3683, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3684, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3685, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3686, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3687, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3688, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3689, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3690, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3691, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3692, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3693, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3694, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3695, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3696, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3697, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3698, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3699, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3700, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3701, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3702, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3703, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3704, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3705, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3706, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3707, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3708, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3709, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3710, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3711, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3712, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3713, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3714, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3715, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3716, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3717, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3718, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3719, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3720, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3721, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3722, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3723, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3724, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3725, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3726, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3727, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3728, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3729, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3730, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3731, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3732, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3733, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3734, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3735, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3736, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3737, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3738, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3739, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3740, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3741, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3742, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3743, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3744, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3745, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3746, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3747, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3748, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3749, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3750, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3751, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3752, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3753, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3754, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3755, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3756, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3757, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3758, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3759, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3760, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3761, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3762, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3763, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3764, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3765, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3766, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3767, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3768, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3769, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3770, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3771, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3772, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3773, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3774, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3775, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3776, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3777, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3778, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3779, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3780, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3781, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3782, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3783, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3784, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3785, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3786, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3787, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3788, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3789, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3790, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3791, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3792, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3793, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3794, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3795, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3796, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3797, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3798, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3799, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3800, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3801, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3802, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3803, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3804, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3805, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3806, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3807, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3808, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3809, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3810, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3811, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3812, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3813, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3814, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3815, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3816, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3817, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3818, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3819, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3820, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3821, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3822, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3823, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3824, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3825, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3826, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3827, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3828, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3829, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3830, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3831, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3832, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3833, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3834, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3835, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3836, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3837, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3838, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3839, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3840, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3841, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3842, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3843, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3844, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3845, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3846, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3847, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3848, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3849, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3850, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3851, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3852, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3853, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3854, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3855, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3856, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3857, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3858, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3859, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3860, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3861, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3862, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3863, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3864, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3865, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3866, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3867, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3868, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3869, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3870, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3871, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3872, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3873, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3874, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3875, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3876, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3877, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3878, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3879, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3880, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3881, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3882, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3883, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3884, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3885, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3886, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3887, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3888, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3889, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3890, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3891, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3892, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3893, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3894, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3895, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3896, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3897, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3898, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3899, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3900, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3901, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3902, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3903, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3904, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3905, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3906, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3907, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3908, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3909, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3910, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3911, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3912, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3913, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3914, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3915, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3916, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3917, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3918, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3919, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3920, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3921, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3922, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3923, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3924, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3925, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3926, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3927, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3928, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3929, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3930, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3931, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3932, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3933, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3934, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3935, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3936, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3937, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3938, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3939, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3940, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3941, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3942, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3943, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3944, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3945, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3946, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3947, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3948, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3949, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3950, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3951, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3952, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3953, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3954, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3955, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3956, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3957, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3958, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3959, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3960, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3961, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3962, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3963, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3964, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3965, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3966, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3967, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3968, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3969, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3970, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3971, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3972, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3973, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3974, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3975, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3976, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3977, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3978, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3979, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3980, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3981, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3982, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3983, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3984, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3985, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3986, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3987, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3988, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3989, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3990, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3991, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3992, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3993, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3994, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3995, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3996, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3997, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3998, Total Steps: 300, Total Reward: -300\n",
            "Episode: 3999, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4000, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4001, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4002, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4003, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4004, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4005, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4006, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4007, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4008, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4009, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4010, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4011, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4012, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4013, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4014, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4015, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4016, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4017, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4018, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4019, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4020, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4021, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4022, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4023, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4024, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4025, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4026, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4027, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4028, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4029, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4030, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4031, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4032, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4033, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4034, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4035, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4036, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4037, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4038, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4039, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4040, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4041, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4042, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4043, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4044, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4045, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4046, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4047, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4048, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4049, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4050, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4051, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4052, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4053, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4054, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4055, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4056, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4057, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4058, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4059, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4060, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4061, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4062, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4063, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4064, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4065, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4066, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4067, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4068, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4069, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4070, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4071, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4072, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4073, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4074, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4075, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4076, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4077, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4078, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4079, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4080, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4081, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4082, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4083, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4084, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4085, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4086, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4087, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4088, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4089, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4090, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4091, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4092, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4093, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4094, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4095, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4096, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4097, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4098, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4099, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4100, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4101, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4102, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4103, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4104, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4105, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4106, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4107, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4108, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4109, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4110, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4111, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4112, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4113, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4114, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4115, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4116, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4117, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4118, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4119, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4120, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4121, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4122, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4123, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4124, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4125, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4126, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4127, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4128, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4129, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4130, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4131, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4132, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4133, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4134, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4135, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4136, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4137, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4138, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4139, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4140, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4141, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4142, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4143, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4144, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4145, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4146, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4147, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4148, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4149, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4150, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4151, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4152, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4153, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4154, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4155, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4156, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4157, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4158, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4159, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4160, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4161, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4162, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4163, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4164, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4165, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4166, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4167, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4168, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4169, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4170, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4171, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4172, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4173, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4174, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4175, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4176, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4177, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4178, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4179, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4180, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4181, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4182, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4183, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4184, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4185, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4186, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4187, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4188, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4189, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4190, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4191, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4192, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4193, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4194, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4195, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4196, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4197, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4198, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4199, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4200, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4201, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4202, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4203, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4204, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4205, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4206, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4207, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4208, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4209, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4210, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4211, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4212, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4213, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4214, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4215, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4216, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4217, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4218, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4219, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4220, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4221, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4222, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4223, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4224, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4225, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4226, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4227, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4228, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4229, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4230, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4231, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4232, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4233, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4234, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4235, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4236, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4237, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4238, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4239, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4240, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4241, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4242, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4243, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4244, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4245, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4246, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4247, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4248, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4249, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4250, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4251, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4252, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4253, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4254, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4255, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4256, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4257, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4258, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4259, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4260, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4261, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4262, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4263, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4264, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4265, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4266, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4267, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4268, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4269, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4270, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4271, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4272, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4273, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4274, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4275, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4276, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4277, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4278, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4279, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4280, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4281, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4282, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4283, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4284, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4285, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4286, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4287, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4288, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4289, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4290, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4291, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4292, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4293, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4294, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4295, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4296, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4297, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4298, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4299, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4300, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4301, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4302, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4303, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4304, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4305, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4306, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4307, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4308, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4309, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4310, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4311, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4312, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4313, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4314, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4315, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4316, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4317, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4318, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4319, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4320, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4321, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4322, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4323, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4324, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4325, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4326, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4327, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4328, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4329, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4330, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4331, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4332, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4333, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4334, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4335, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4336, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4337, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4338, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4339, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4340, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4341, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4342, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4343, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4344, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4345, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4346, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4347, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4348, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4349, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4350, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4351, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4352, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4353, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4354, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4355, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4356, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4357, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4358, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4359, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4360, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4361, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4362, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4363, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4364, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4365, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4366, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4367, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4368, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4369, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4370, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4371, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4372, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4373, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4374, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4375, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4376, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4377, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4378, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4379, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4380, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4381, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4382, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4383, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4384, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4385, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4386, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4387, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4388, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4389, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4390, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4391, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4392, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4393, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4394, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4395, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4396, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4397, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4398, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4399, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4400, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4401, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4402, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4403, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4404, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4405, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4406, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4407, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4408, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4409, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4410, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4411, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4412, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4413, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4414, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4415, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4416, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4417, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4418, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4419, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4420, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4421, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4422, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4423, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4424, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4425, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4426, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4427, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4428, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4429, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4430, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4431, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4432, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4433, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4434, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4435, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4436, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4437, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4438, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4439, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4440, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4441, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4442, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4443, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4444, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4445, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4446, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4447, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4448, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4449, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4450, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4451, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4452, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4453, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4454, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4455, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4456, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4457, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4458, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4459, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4460, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4461, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4462, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4463, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4464, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4465, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4466, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4467, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4468, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4469, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4470, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4471, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4472, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4473, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4474, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4475, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4476, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4477, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4478, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4479, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4480, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4481, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4482, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4483, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4484, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4485, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4486, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4487, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4488, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4489, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4490, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4491, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4492, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4493, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4494, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4495, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4496, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4497, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4498, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4499, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4500, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4501, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4502, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4503, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4504, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4505, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4506, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4507, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4508, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4509, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4510, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4511, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4512, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4513, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4514, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4515, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4516, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4517, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4518, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4519, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4520, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4521, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4522, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4523, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4524, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4525, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4526, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4527, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4528, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4529, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4530, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4531, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4532, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4533, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4534, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4535, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4536, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4537, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4538, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4539, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4540, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4541, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4542, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4543, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4544, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4545, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4546, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4547, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4548, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4549, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4550, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4551, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4552, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4553, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4554, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4555, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4556, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4557, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4558, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4559, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4560, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4561, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4562, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4563, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4564, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4565, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4566, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4567, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4568, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4569, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4570, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4571, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4572, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4573, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4574, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4575, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4576, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4577, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4578, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4579, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4580, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4581, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4582, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4583, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4584, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4585, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4586, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4587, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4588, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4589, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4590, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4591, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4592, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4593, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4594, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4595, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4596, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4597, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4598, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4599, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4600, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4601, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4602, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4603, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4604, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4605, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4606, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4607, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4608, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4609, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4610, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4611, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4612, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4613, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4614, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4615, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4616, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4617, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4618, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4619, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4620, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4621, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4622, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4623, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4624, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4625, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4626, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4627, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4628, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4629, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4630, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4631, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4632, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4633, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4634, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4635, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4636, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4637, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4638, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4639, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4640, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4641, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4642, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4643, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4644, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4645, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4646, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4647, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4648, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4649, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4650, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4651, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4652, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4653, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4654, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4655, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4656, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4657, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4658, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4659, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4660, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4661, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4662, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4663, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4664, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4665, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4666, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4667, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4668, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4669, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4670, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4671, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4672, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4673, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4674, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4675, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4676, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4677, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4678, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4679, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4680, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4681, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4682, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4683, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4684, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4685, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4686, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4687, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4688, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4689, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4690, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4691, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4692, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4693, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4694, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4695, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4696, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4697, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4698, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4699, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4700, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4701, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4702, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4703, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4704, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4705, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4706, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4707, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4708, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4709, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4710, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4711, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4712, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4713, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4714, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4715, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4716, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4717, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4718, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4719, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4720, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4721, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4722, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4723, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4724, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4725, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4726, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4727, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4728, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4729, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4730, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4731, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4732, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4733, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4734, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4735, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4736, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4737, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4738, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4739, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4740, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4741, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4742, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4743, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4744, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4745, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4746, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4747, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4748, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4749, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4750, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4751, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4752, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4753, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4754, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4755, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4756, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4757, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4758, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4759, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4760, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4761, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4762, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4763, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4764, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4765, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4766, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4767, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4768, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4769, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4770, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4771, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4772, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4773, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4774, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4775, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4776, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4777, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4778, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4779, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4780, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4781, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4782, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4783, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4784, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4785, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4786, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4787, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4788, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4789, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4790, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4791, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4792, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4793, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4794, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4795, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4796, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4797, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4798, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4799, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4800, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4801, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4802, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4803, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4804, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4805, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4806, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4807, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4808, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4809, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4810, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4811, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4812, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4813, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4814, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4815, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4816, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4817, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4818, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4819, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4820, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4821, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4822, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4823, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4824, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4825, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4826, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4827, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4828, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4829, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4830, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4831, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4832, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4833, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4834, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4835, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4836, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4837, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4838, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4839, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4840, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4841, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4842, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4843, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4844, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4845, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4846, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4847, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4848, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4849, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4850, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4851, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4852, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4853, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4854, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4855, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4856, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4857, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4858, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4859, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4860, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4861, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4862, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4863, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4864, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4865, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4866, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4867, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4868, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4869, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4870, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4871, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4872, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4873, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4874, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4875, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4876, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4877, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4878, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4879, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4880, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4881, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4882, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4883, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4884, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4885, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4886, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4887, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4888, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4889, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4890, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4891, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4892, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4893, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4894, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4895, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4896, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4897, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4898, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4899, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4900, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4901, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4902, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4903, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4904, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4905, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4906, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4907, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4908, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4909, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4910, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4911, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4912, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4913, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4914, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4915, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4916, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4917, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4918, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4919, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4920, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4921, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4922, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4923, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4924, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4925, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4926, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4927, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4928, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4929, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4930, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4931, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4932, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4933, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4934, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4935, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4936, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4937, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4938, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4939, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4940, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4941, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4942, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4943, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4944, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4945, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4946, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4947, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4948, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4949, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4950, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4951, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4952, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4953, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4954, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4955, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4956, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4957, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4958, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4959, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4960, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4961, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4962, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4963, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4964, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4965, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4966, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4967, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4968, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4969, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4970, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4971, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4972, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4973, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4974, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4975, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4976, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4977, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4978, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4979, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4980, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4981, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4982, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4983, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4984, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4985, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4986, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4987, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4988, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4989, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4990, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4991, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4992, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4993, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4994, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4995, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4996, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4997, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4998, Total Steps: 300, Total Reward: -300\n",
            "Episode: 4999, Total Steps: 300, Total Reward: -300\n",
            "Episode: 5000, Total Steps: 300, Total Reward: -300\n",
            "First Episode Path\n",
            "               \n",
            "               \n",
            "S X            \n",
            "               \n",
            "               \n",
            "               \n",
            "              G\n",
            "               \n",
            "\n",
            "Last Episode Path\n",
            "               \n",
            "               \n",
            "S X            \n",
            "  X X          \n",
            "               \n",
            "               \n",
            "              G\n",
            "               \n",
            "\n"
          ]
        }
      ],
      "source": [
        "class GridWorldEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        # GridWorld 환경 초기화\n",
        "        super(GridWorldEnv, self).__init__()\n",
        "        self.grid_size = 8  # 그리드 크기 정의\n",
        "        self.action_space = spaces.Discrete(4)  # 행동 공간: 4개의 가능한 행동\n",
        "        self.observation_space = spaces.Box(low=0, high=self.grid_size-1, shape=(2,), dtype=np.int32)  # 관찰 공간 정의\n",
        "        self.maze = [\n",
        "            [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "            [1, 0, 0, 0, 0, 0, 0, 1],\n",
        "            [0, 0, 1, 1, 0, 1, 0, 1],\n",
        "            [1, 0, 0, 1, 1, 0, 0, 1],\n",
        "            [1, 1, 0, 0, 1, 0, 1, 1],\n",
        "            [1, 0, 1, 0, 1, 0, 0, 1],\n",
        "            [1, 0, 0, 0, 0, 1, 0, 0],\n",
        "            [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "        ]  # 1은 벽, 0은 자유 공간\n",
        "        self.reset()  # 환경 초기화\n",
        "\n",
        "    def step(self, action):\n",
        "        # 행동 실행\n",
        "        if action == 0:\n",
        "            self.move_left()\n",
        "        elif action == 1:\n",
        "            self.move_up()\n",
        "        elif action == 2:\n",
        "            self.move_right()\n",
        "        elif action == 3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1  # 에이전트가 움직일 때 보상은 -1\n",
        "        done = self.is_done()  # 에피소드 종료 여부 확인\n",
        "        return np.array([self.x, self.y], dtype=np.int32), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        # 에이전트 위치를 시작점으로 초기화\n",
        "        self.x = 2\n",
        "        self.y = 0\n",
        "        return np.array([self.x, self.y], dtype=np.int32)\n",
        "\n",
        "    def move_right(self):\n",
        "        # 에이전트를 오른쪽으로 이동\n",
        "        if self.y < self.grid_size - 1 and self.maze[self.x][self.y + 1] == 0:\n",
        "            self.y += 1\n",
        "\n",
        "    def move_left(self):\n",
        "        # 에이전트를 왼쪽으로 이동\n",
        "        if self.y > 0 and self.maze[self.x][self.y - 1] == 0:\n",
        "            self.y -= 1\n",
        "\n",
        "    def move_up(self):\n",
        "        # 에이전트를 위로 이동\n",
        "        if self.x > 0 and self.maze[self.x - 1][self.y] == 0:\n",
        "            self.x -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        # 에이전트를 아래로 이동\n",
        "        if self.x < self.grid_size - 1 and self.maze[self.x + 1][self.y] == 0:\n",
        "            self.x += 1\n",
        "\n",
        "    def is_done(self):\n",
        "        # 에이전트가 목표에 도달했는지 확인\n",
        "        return self.x == 6 and self.y == 7\n",
        "\n",
        "# GridWorld 환경 초기화\n",
        "env = GridWorldEnv()\n",
        "\n",
        "# DQN 모델 구축\n",
        "model = DQN('MlpPolicy', env, verbose=0, exploration_fraction=0.5, exploration_final_eps=0.01, learning_rate=0.01)\n",
        "\n",
        "# DQN 에이전트 훈련\n",
        "episode_rewards = []  # 각 에피소드의 보상을 저장할 리스트\n",
        "first_episode_path = []  # 첫 번째 에피소드의 경로를 저장할 리스트\n",
        "last_episode_path = []  # 마지막 에피소드의 경로를 저장할 리스트\n",
        "\n",
        "max_steps_per_episode = 300  # 에피소드당 최대 단계 수\n",
        "num_episodes = 5000  # 총 에피소드 수\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    obs = env.reset()  # 각 에피소드 시작 시 환경 초기화\n",
        "    total_rewards = 0  # 에피소드 동안의 총 보상 초기화\n",
        "    done = False  # done 플래그 초기화\n",
        "    action_count = 0  # 에피소드 동안의 행동 수 초기화\n",
        "    episode_path = [tuple(obs)]  # 에피소드 경로 초기화\n",
        "\n",
        "    while not done and action_count < max_steps_per_episode:\n",
        "        action, _ = model.predict(obs, deterministic=False)  # DQN 모델을 사용하여 다음 행동 예측\n",
        "        obs, reward, done, _ = env.step(action)  # 환경에서 행동 실행\n",
        "        total_rewards += reward  # 보상 누적\n",
        "        action_count += 1  # 행동 수 증가\n",
        "        episode_path.append(tuple(obs))  # 현재 위치를 경로에 추가\n",
        "    print(f\"Episode: {episode + 1}, Total Steps: {action_count}, Total Reward: {total_rewards}\")\n",
        "\n",
        "    # 각 에피소드의 총 보상 저장\n",
        "    episode_rewards.append(total_rewards)\n",
        "\n",
        "    # 첫 번째 에피소드의 경로 저장\n",
        "    if episode == 0:\n",
        "        first_episode_path = episode_path\n",
        "\n",
        "    # 마지막 에피소드의 경로 저장\n",
        "    if episode == num_episodes - 1:\n",
        "        last_episode_path = episode_path\n",
        "\n",
        "    # 각 에피소드 후 모델 업데이트\n",
        "    model.learn(total_timesteps=200)\n",
        "\n",
        "# 에피소드 경로를 시각화하는 함수\n",
        "def plot_episode_path(path, title):\n",
        "    grid = [[' ' for _ in range(env.grid_size)] for _ in range(env.grid_size)]  # 빈 그리드 초기화\n",
        "    grid[2][0] = 'S'  # 시작 위치 표시\n",
        "    grid[6][7] = 'G'  # 목표 위치 표시\n",
        "    for (x, y) in path:\n",
        "        if (x, y) != (2, 0) and (x, y) != (6, 7):\n",
        "            grid[x][y] = 'X'  # 경로 위치 표시\n",
        "\n",
        "    # 그리드 출력\n",
        "    print(title)\n",
        "    for row in grid:\n",
        "        print(' '.join(row))\n",
        "    print()\n",
        "\n",
        "# 첫 번째와 마지막 에피소드의 경로 시각화\n",
        "plot_episode_path(first_episode_path, 'First Episode Path')\n",
        "plot_episode_path(last_episode_path, 'Last Episode Path')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O26fGmMFKHRe",
        "outputId": "0bdabbac-fbda-4d5b-b396-bb0eb6e9d054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "VacCLuZZkS6B",
        "outputId": "856f30f3-1bbb-4c7a-85e6-28d2c86637ba"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8c2ff49fc0e5>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mlast_episode_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepisode_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_episode_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/dqn/dqn.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     ) -> SelfDQN:\n\u001b[0;32m--> 267\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             rollout = self.collect_rollouts(\n\u001b[0m\u001b[1;32m    329\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mtrain_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \"\"\"\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Switch to eval mode (this affects batch norm / dropout)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_training_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mnum_collected_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_collected_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/dqn/policies.py\u001b[0m in \u001b[0;36mset_training_mode\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \"\"\"\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_training_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mset_training_mode\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \"\"\"\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_vectorized_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2429\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2430\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2431\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2429\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2430\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2431\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training mode is expected to be boolean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2428\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2429\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1754\u001b[0m                 \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m                 \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_buffers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "from stable_baselines3 import DQN\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class GridWorldEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(GridWorldEnv, self).__init__()\n",
        "        self.grid_size = 8\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        self.observation_space = spaces.Box(low=0, high=self.grid_size-1, shape=(2,), dtype=np.int32)\n",
        "        self.maze = [\n",
        "            [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "            [1, 0, 0, 0, 0, 0, 0, 1],\n",
        "            [0, 0, 1, 1, 0, 1, 0, 1],\n",
        "            [1, 0, 0, 1, 1, 0, 0, 1],\n",
        "            [1, 1, 0, 0, 1, 0, 1, 1],\n",
        "            [1, 0, 1, 0, 1, 0, 0, 1],\n",
        "            [1, 0, 0, 0, 0, 1, 0, 0],\n",
        "            [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "        ]\n",
        "        self.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 0:\n",
        "            self.move_left()\n",
        "        elif action == 1:\n",
        "            self.move_up()\n",
        "        elif action == 2:\n",
        "            self.move_right()\n",
        "        elif action == 3:\n",
        "            self.move_down()\n",
        "\n",
        "        done = self.is_done()\n",
        "        reward = -1 if not done else 100\n",
        "        return np.array([self.x, self.y], dtype=np.int32), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = 2\n",
        "        self.y = 0\n",
        "        return np.array([self.x, self.y], dtype=np.int32)\n",
        "\n",
        "    def move_right(self):\n",
        "        if self.y < self.grid_size - 1 and self.maze[self.x][self.y + 1] == 0:\n",
        "            self.y += 1\n",
        "\n",
        "    def move_left(self):\n",
        "        if self.y > 0 and self.maze[self.x][self.y - 1] == 0:\n",
        "            self.y -= 1\n",
        "\n",
        "    def move_up(self):\n",
        "        if self.x > 0 and self.maze[self.x - 1][self.y] == 0:\n",
        "            self.x -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        if self.x < self.grid_size - 1 and self.maze[self.x + 1][self.y] == 0:\n",
        "            self.x += 1\n",
        "\n",
        "    def is_done(self):\n",
        "        return self.x == 6 and self.y == 7\n",
        "\n",
        "env = GridWorldEnv()\n",
        "model = DQN('MlpPolicy', env, verbose=0, exploration_fraction=0.2, exploration_final_eps=0.02, learning_rate=0.005)\n",
        "\n",
        "episode_rewards = []\n",
        "first_episode_path = []\n",
        "last_episode_path = []\n",
        "\n",
        "max_steps_per_episode = 200\n",
        "num_episodes = 1500\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    obs = env.reset()\n",
        "    total_rewards = 0\n",
        "    done = False\n",
        "    action_count = 0\n",
        "    episode_path = [tuple(obs)]\n",
        "\n",
        "    while not done and action_count < max_steps_per_episode:\n",
        "        action, _ = model.predict(obs, deterministic=False)\n",
        "        obs, reward, done, _ = env.step(action)\n",
        "        total_rewards += reward\n",
        "        action_count += 1\n",
        "        episode_path.append(tuple(obs))\n",
        "\n",
        "    episode_rewards.append(total_rewards)\n",
        "\n",
        "    if episode == 0:\n",
        "        first_episode_path = episode_path\n",
        "\n",
        "    if episode == num_episodes - 1:\n",
        "        last_episode_path = episode_path\n",
        "\n",
        "    model.learn(total_timesteps=500, reset_num_timesteps=False)\n",
        "\n",
        "def plot_episode_path(path, title):\n",
        "    grid = [[' ' for _ in range(env.grid_size)] for _ in range(env.grid_size)]\n",
        "    grid[2][0] = 'S'\n",
        "    grid[6][7] = 'G'\n",
        "    for (x, y) in path:\n",
        "        if (x, y) != (2, 0) and (x, y) != (6, 7):\n",
        "            grid[x][y] = 'X'\n",
        "\n",
        "    print(title)\n",
        "    for row in grid:\n",
        "        print(' '.join(row))\n",
        "    print()\n",
        "\n",
        "plot_episode_path(first_episode_path, 'First Episode Path')\n",
        "plot_episode_path(last_episode_path, 'Last Episode Path')\n",
        "\n",
        "plt.plot(episode_rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.title('Total Reward per Episode')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "hhdOKstyxbwu",
        "outputId": "33820e71-16a6-4bc6-f03f-3fbf666da93d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3128b4eee83f>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mlast_episode_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepisode_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_episode_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/dqn/dqn.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     ) -> SelfDQN:\n\u001b[0;32m--> 267\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             rollout = self.collect_rollouts(\n\u001b[0m\u001b[1;32m    329\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mtrain_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;31m# Select action randomly or according to policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_starts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;31m# Rescale and perform action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36m_sample_action\u001b[0;34m(self, learning_starts, action_noise, n_envs)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;31m# We use non-deterministic action in the case of SAC, for TD3, it does not matter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"self._last_obs was not set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0munscaled_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Rescale the action from [low, high] to [-1, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/dqn/dqn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    363\u001b[0m             )\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mobs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mobs_to_tensor\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mis_image_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;31m# Handle the different cases for images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;31m# as PyTorch use channel first format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/preprocessing.py\u001b[0m in \u001b[0;36mis_image_space\u001b[0;34m(observation_space, check_channels, normalized_image)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m def is_image_space(\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mobservation_space\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mcheck_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "from stable_baselines3 import DQN\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class GridWorldEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(GridWorldEnv, self).__init__()\n",
        "        self.grid_size = 8\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        self.observation_space = spaces.Box(low=0, high=self.grid_size-1, shape=(2,), dtype=np.int32)\n",
        "        self.maze = [\n",
        "            [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "            [1, 0, 0, 0, 0, 0, 0, 1],\n",
        "            [0, 0, 1, 1, 0, 1, 0, 1],\n",
        "            [1, 0, 0, 1, 1, 0, 0, 1],\n",
        "            [1, 1, 0, 0, 1, 0, 1, 1],\n",
        "            [1, 0, 1, 0, 1, 0, 0, 1],\n",
        "            [1, 0, 0, 0, 0, 1, 0, 0],\n",
        "            [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "        ]\n",
        "        self.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "        prev_x, prev_y = self.x, self.y\n",
        "\n",
        "        if action == 0:\n",
        "            self.move_left()\n",
        "        elif action == 1:\n",
        "            self.move_up()\n",
        "        elif action == 2:\n",
        "            self.move_right()\n",
        "        elif action == 3:\n",
        "            self.move_down()\n",
        "\n",
        "        done = self.is_done()\n",
        "        if done:\n",
        "            reward = 100\n",
        "        elif (self.x, self.y) == (prev_x, prev_y):\n",
        "            reward = -10  # 벽에 부딪히면 패널티\n",
        "        else:\n",
        "            reward = -1  # 이동마다 패널티\n",
        "\n",
        "        return np.array([self.x, self.y], dtype=np.int32), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = 2\n",
        "        self.y = 0\n",
        "        return np.array([self.x, self.y], dtype=np.int32)\n",
        "\n",
        "    def move_right(self):\n",
        "        if self.y < self.grid_size - 1 and self.maze[self.x][self.y + 1] == 0:\n",
        "            self.y += 1\n",
        "\n",
        "    def move_left(self):\n",
        "        if self.y > 0 and self.maze[self.x][self.y - 1] == 0:\n",
        "            self.y -= 1\n",
        "\n",
        "    def move_up(self):\n",
        "        if self.x > 0 and self.maze[self.x - 1][self.y] == 0:\n",
        "            self.x -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        if self.x < self.grid_size - 1 and self.maze[self.x + 1][self.y] == 0:\n",
        "            self.x += 1\n",
        "\n",
        "    def is_done(self):\n",
        "        return self.x == 6 and self.y == 7\n",
        "\n",
        "env = GridWorldEnv()\n",
        "model = DQN('MlpPolicy', env, verbose=0, exploration_fraction=0.4, exploration_final_eps=0.1, learning_rate=0.001)\n",
        "\n",
        "episode_rewards = []\n",
        "first_episode_path = []\n",
        "last_episode_path = []\n",
        "\n",
        "max_steps_per_episode = 200\n",
        "num_episodes = 3000\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    obs = env.reset()\n",
        "    total_rewards = 0\n",
        "    done = False\n",
        "    action_count = 0\n",
        "    episode_path = [tuple(obs)]\n",
        "\n",
        "    while not done and action_count < max_steps_per_episode:\n",
        "        action, _ = model.predict(obs, deterministic=False)\n",
        "        obs, reward, done, _ = env.step(action)\n",
        "        total_rewards += reward\n",
        "        action_count += 1\n",
        "        episode_path.append(tuple(obs))\n",
        "\n",
        "    episode_rewards.append(total_rewards)\n",
        "\n",
        "    if episode == 0:\n",
        "        first_episode_path = episode_path\n",
        "\n",
        "    if episode == num_episodes - 1:\n",
        "        last_episode_path = episode_path\n",
        "\n",
        "    model.learn(total_timesteps=300000, reset_num_timesteps=False)\n",
        "\n",
        "def plot_episode_path(path, title):\n",
        "    grid = [[' ' for _ in range(env.grid_size)] for _ in range(env.grid_size)]\n",
        "    grid[2][0] = 'S'\n",
        "    grid[6][7] = 'G'\n",
        "    for (x, y) in path:\n",
        "        if (x, y) != (2, 0) and (x, y) != (6, 7):\n",
        "            grid[x][y] = 'X'\n",
        "\n",
        "    print(title)\n",
        "    for row in grid:\n",
        "        print(' '.join(row))\n",
        "    print()\n",
        "\n",
        "plot_episode_path(first_episode_path, 'First Episode Path')\n",
        "plot_episode_path(last_episode_path, 'Last Episode Path')\n",
        "\n",
        "plt.plot(episode_rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.title('Total Reward per Episode')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u_p99Sfv4k9",
        "outputId": "b24e2a8c-e75f-4376-cf80-0be1c5cb75ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gym tensorflow tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrE_scWx-7_b",
        "outputId": "3134127c-7579-4f09-c0bd-2ed90c30e05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQOaRh7L5pD9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d13d1a56-03d6-4452-af5c-5259d66dcee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3176     |\n",
            "|    fps              | 729      |\n",
            "|    time_elapsed     | 382      |\n",
            "|    total_timesteps  | 278991   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.33e-05 |\n",
            "|    n_updates        | 69722    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3180     |\n",
            "|    fps              | 729      |\n",
            "|    time_elapsed     | 382      |\n",
            "|    total_timesteps  | 279052   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.09e-05 |\n",
            "|    n_updates        | 69737    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3184     |\n",
            "|    fps              | 729      |\n",
            "|    time_elapsed     | 382      |\n",
            "|    total_timesteps  | 279114   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000332 |\n",
            "|    n_updates        | 69753    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3188     |\n",
            "|    fps              | 729      |\n",
            "|    time_elapsed     | 382      |\n",
            "|    total_timesteps  | 279181   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000329 |\n",
            "|    n_updates        | 69770    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3192     |\n",
            "|    fps              | 729      |\n",
            "|    time_elapsed     | 382      |\n",
            "|    total_timesteps  | 279242   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000941 |\n",
            "|    n_updates        | 69785    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3196     |\n",
            "|    fps              | 729      |\n",
            "|    time_elapsed     | 382      |\n",
            "|    total_timesteps  | 279307   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.44e-05 |\n",
            "|    n_updates        | 69801    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3200     |\n",
            "|    fps              | 729      |\n",
            "|    time_elapsed     | 383      |\n",
            "|    total_timesteps  | 279371   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.83e-05 |\n",
            "|    n_updates        | 69817    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3204     |\n",
            "|    fps              | 729      |\n",
            "|    time_elapsed     | 383      |\n",
            "|    total_timesteps  | 279434   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.55e-05 |\n",
            "|    n_updates        | 69833    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3208     |\n",
            "|    fps              | 729      |\n",
            "|    time_elapsed     | 383      |\n",
            "|    total_timesteps  | 279496   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.89e-05 |\n",
            "|    n_updates        | 69848    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3212     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 383      |\n",
            "|    total_timesteps  | 279561   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.27e-05 |\n",
            "|    n_updates        | 69865    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3216     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 383      |\n",
            "|    total_timesteps  | 279622   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.19e-05 |\n",
            "|    n_updates        | 69880    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3220     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 383      |\n",
            "|    total_timesteps  | 279685   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.64e-05 |\n",
            "|    n_updates        | 69896    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3224     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 383      |\n",
            "|    total_timesteps  | 279751   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.75e-06 |\n",
            "|    n_updates        | 69912    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3228     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 383      |\n",
            "|    total_timesteps  | 279813   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000147 |\n",
            "|    n_updates        | 69928    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3232     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 384      |\n",
            "|    total_timesteps  | 279878   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000426 |\n",
            "|    n_updates        | 69944    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3236     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 384      |\n",
            "|    total_timesteps  | 279945   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.69e-05 |\n",
            "|    n_updates        | 69961    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3240     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 384      |\n",
            "|    total_timesteps  | 280005   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.385    |\n",
            "|    n_updates        | 69976    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3244     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 384      |\n",
            "|    total_timesteps  | 280070   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0859   |\n",
            "|    n_updates        | 69992    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3248     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 384      |\n",
            "|    total_timesteps  | 280139   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0509   |\n",
            "|    n_updates        | 70009    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3252     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 384      |\n",
            "|    total_timesteps  | 280203   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0119   |\n",
            "|    n_updates        | 70025    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3256     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 384      |\n",
            "|    total_timesteps  | 280265   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0153   |\n",
            "|    n_updates        | 70041    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3260     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 384      |\n",
            "|    total_timesteps  | 280329   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00797  |\n",
            "|    n_updates        | 70057    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3264     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 385      |\n",
            "|    total_timesteps  | 280389   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0115   |\n",
            "|    n_updates        | 70072    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3268     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 385      |\n",
            "|    total_timesteps  | 280450   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00451  |\n",
            "|    n_updates        | 70087    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3272     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 385      |\n",
            "|    total_timesteps  | 280510   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0138   |\n",
            "|    n_updates        | 70102    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3276     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 385      |\n",
            "|    total_timesteps  | 280574   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0132   |\n",
            "|    n_updates        | 70118    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3280     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 385      |\n",
            "|    total_timesteps  | 280637   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00455  |\n",
            "|    n_updates        | 70134    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3284     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 385      |\n",
            "|    total_timesteps  | 280700   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00591  |\n",
            "|    n_updates        | 70149    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3288     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 385      |\n",
            "|    total_timesteps  | 280765   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000908 |\n",
            "|    n_updates        | 70166    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3292     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 385      |\n",
            "|    total_timesteps  | 280827   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00238  |\n",
            "|    n_updates        | 70181    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3296     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 385      |\n",
            "|    total_timesteps  | 280892   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00354  |\n",
            "|    n_updates        | 70197    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3300     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 385      |\n",
            "|    total_timesteps  | 280955   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00425  |\n",
            "|    n_updates        | 70213    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3304     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 385      |\n",
            "|    total_timesteps  | 281020   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00514  |\n",
            "|    n_updates        | 70229    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3308     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 386      |\n",
            "|    total_timesteps  | 281089   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00406  |\n",
            "|    n_updates        | 70247    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3312     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 386      |\n",
            "|    total_timesteps  | 281150   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00128  |\n",
            "|    n_updates        | 70262    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3316     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 386      |\n",
            "|    total_timesteps  | 281211   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00187  |\n",
            "|    n_updates        | 70277    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3320     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 386      |\n",
            "|    total_timesteps  | 281273   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00261  |\n",
            "|    n_updates        | 70293    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3324     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 386      |\n",
            "|    total_timesteps  | 281339   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00331  |\n",
            "|    n_updates        | 70309    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3328     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 386      |\n",
            "|    total_timesteps  | 281401   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00573  |\n",
            "|    n_updates        | 70325    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3332     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 386      |\n",
            "|    total_timesteps  | 281461   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00231  |\n",
            "|    n_updates        | 70340    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3336     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 386      |\n",
            "|    total_timesteps  | 281524   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00185  |\n",
            "|    n_updates        | 70355    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3340     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 386      |\n",
            "|    total_timesteps  | 281587   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00209  |\n",
            "|    n_updates        | 70371    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3344     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 386      |\n",
            "|    total_timesteps  | 281649   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000592 |\n",
            "|    n_updates        | 70387    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3348     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 386      |\n",
            "|    total_timesteps  | 281715   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00328  |\n",
            "|    n_updates        | 70403    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3352     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 281778   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00127  |\n",
            "|    n_updates        | 70419    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3356     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 281838   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000348 |\n",
            "|    n_updates        | 70434    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3360     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 281903   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00127  |\n",
            "|    n_updates        | 70450    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3364     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 281969   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00279  |\n",
            "|    n_updates        | 70467    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3368     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 282032   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00567  |\n",
            "|    n_updates        | 70482    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3372     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 282094   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000764 |\n",
            "|    n_updates        | 70498    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3376     |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 282159   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000207 |\n",
            "|    n_updates        | 70514    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3380     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 282226   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000775 |\n",
            "|    n_updates        | 70531    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3384     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 282292   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000246 |\n",
            "|    n_updates        | 70547    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3388     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 282353   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000979 |\n",
            "|    n_updates        | 70563    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3392     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 282417   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000999 |\n",
            "|    n_updates        | 70579    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3396     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 388      |\n",
            "|    total_timesteps  | 282481   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000622 |\n",
            "|    n_updates        | 70595    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3400     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 388      |\n",
            "|    total_timesteps  | 282542   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000662 |\n",
            "|    n_updates        | 70610    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3404     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 388      |\n",
            "|    total_timesteps  | 282603   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00239  |\n",
            "|    n_updates        | 70625    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3408     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 388      |\n",
            "|    total_timesteps  | 282668   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00137  |\n",
            "|    n_updates        | 70641    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3412     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 388      |\n",
            "|    total_timesteps  | 282733   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0003   |\n",
            "|    n_updates        | 70658    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3416     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 388      |\n",
            "|    total_timesteps  | 282800   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000588 |\n",
            "|    n_updates        | 70674    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3420     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 388      |\n",
            "|    total_timesteps  | 282866   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00063  |\n",
            "|    n_updates        | 70691    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3424     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 388      |\n",
            "|    total_timesteps  | 282927   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000261 |\n",
            "|    n_updates        | 70706    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3428     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 388      |\n",
            "|    total_timesteps  | 282992   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00101  |\n",
            "|    n_updates        | 70722    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3432     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 388      |\n",
            "|    total_timesteps  | 283054   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000702 |\n",
            "|    n_updates        | 70738    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3436     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 388      |\n",
            "|    total_timesteps  | 283116   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000793 |\n",
            "|    n_updates        | 70753    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3440     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 283178   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000709 |\n",
            "|    n_updates        | 70769    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3444     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 283241   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000542 |\n",
            "|    n_updates        | 70785    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3448     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 283305   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000531 |\n",
            "|    n_updates        | 70801    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3452     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 283367   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000186 |\n",
            "|    n_updates        | 70816    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3456     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 283436   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000234 |\n",
            "|    n_updates        | 70833    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3460     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 283498   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00146  |\n",
            "|    n_updates        | 70849    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3464     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 283566   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000426 |\n",
            "|    n_updates        | 70866    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3468     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 283632   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000151 |\n",
            "|    n_updates        | 70882    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3472     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 283693   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00148  |\n",
            "|    n_updates        | 70898    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3476     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 283755   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000873 |\n",
            "|    n_updates        | 70913    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3480     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 283821   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000494 |\n",
            "|    n_updates        | 70930    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3484     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 390      |\n",
            "|    total_timesteps  | 283888   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000168 |\n",
            "|    n_updates        | 70946    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3488     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 390      |\n",
            "|    total_timesteps  | 283950   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000109 |\n",
            "|    n_updates        | 70962    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3492     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 390      |\n",
            "|    total_timesteps  | 284013   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.16e-05 |\n",
            "|    n_updates        | 70978    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3496     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 390      |\n",
            "|    total_timesteps  | 284077   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.45e-05 |\n",
            "|    n_updates        | 70994    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3500     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 390      |\n",
            "|    total_timesteps  | 284138   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00115  |\n",
            "|    n_updates        | 71009    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3504     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 390      |\n",
            "|    total_timesteps  | 284200   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00022  |\n",
            "|    n_updates        | 71024    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3508     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 390      |\n",
            "|    total_timesteps  | 284262   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00201  |\n",
            "|    n_updates        | 71040    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3512     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 390      |\n",
            "|    total_timesteps  | 284325   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000143 |\n",
            "|    n_updates        | 71056    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3516     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 390      |\n",
            "|    total_timesteps  | 284389   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.57e-05 |\n",
            "|    n_updates        | 71072    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3520     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 390      |\n",
            "|    total_timesteps  | 284451   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.27e-05 |\n",
            "|    n_updates        | 71087    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3524     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 390      |\n",
            "|    total_timesteps  | 284511   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000711 |\n",
            "|    n_updates        | 71102    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3528     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 391      |\n",
            "|    total_timesteps  | 284577   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000422 |\n",
            "|    n_updates        | 71119    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3532     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 391      |\n",
            "|    total_timesteps  | 284638   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.4e-05  |\n",
            "|    n_updates        | 71134    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3536     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 391      |\n",
            "|    total_timesteps  | 284701   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000142 |\n",
            "|    n_updates        | 71150    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3540     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 391      |\n",
            "|    total_timesteps  | 284762   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000104 |\n",
            "|    n_updates        | 71165    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3544     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 391      |\n",
            "|    total_timesteps  | 284822   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000103 |\n",
            "|    n_updates        | 71180    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3548     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 391      |\n",
            "|    total_timesteps  | 284886   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.36e-05 |\n",
            "|    n_updates        | 71196    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3552     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 391      |\n",
            "|    total_timesteps  | 284950   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00146  |\n",
            "|    n_updates        | 71212    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3556     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 391      |\n",
            "|    total_timesteps  | 285021   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000353 |\n",
            "|    n_updates        | 71230    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3560     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 391      |\n",
            "|    total_timesteps  | 285082   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.79e-05 |\n",
            "|    n_updates        | 71245    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3564     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 391      |\n",
            "|    total_timesteps  | 285145   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.92e-05 |\n",
            "|    n_updates        | 71261    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3568     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 391      |\n",
            "|    total_timesteps  | 285208   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00179  |\n",
            "|    n_updates        | 71276    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3572     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 391      |\n",
            "|    total_timesteps  | 285271   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.17e-05 |\n",
            "|    n_updates        | 71292    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3576     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 392      |\n",
            "|    total_timesteps  | 285333   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0015   |\n",
            "|    n_updates        | 71308    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3580     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 392      |\n",
            "|    total_timesteps  | 285396   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000104 |\n",
            "|    n_updates        | 71323    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3584     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 392      |\n",
            "|    total_timesteps  | 285458   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0023   |\n",
            "|    n_updates        | 71339    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3588     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 392      |\n",
            "|    total_timesteps  | 285518   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.39e-05 |\n",
            "|    n_updates        | 71354    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3592     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 392      |\n",
            "|    total_timesteps  | 285582   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.92e-05 |\n",
            "|    n_updates        | 71370    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3596     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 392      |\n",
            "|    total_timesteps  | 285645   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.83e-05 |\n",
            "|    n_updates        | 71386    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3600     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 392      |\n",
            "|    total_timesteps  | 285708   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0009   |\n",
            "|    n_updates        | 71401    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3604     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 392      |\n",
            "|    total_timesteps  | 285768   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.58e-05 |\n",
            "|    n_updates        | 71416    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3608     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 392      |\n",
            "|    total_timesteps  | 285830   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00137  |\n",
            "|    n_updates        | 71432    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3612     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 392      |\n",
            "|    total_timesteps  | 285892   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.14e-05 |\n",
            "|    n_updates        | 71447    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3616     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 392      |\n",
            "|    total_timesteps  | 285954   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.97e-05 |\n",
            "|    n_updates        | 71463    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3620     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 393      |\n",
            "|    total_timesteps  | 286015   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000353 |\n",
            "|    n_updates        | 71478    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3624     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 393      |\n",
            "|    total_timesteps  | 286078   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.06e-05 |\n",
            "|    n_updates        | 71494    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3628     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 393      |\n",
            "|    total_timesteps  | 286138   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.42e-05 |\n",
            "|    n_updates        | 71509    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3632     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 393      |\n",
            "|    total_timesteps  | 286198   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000145 |\n",
            "|    n_updates        | 71524    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3636     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 393      |\n",
            "|    total_timesteps  | 286261   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.33e-05 |\n",
            "|    n_updates        | 71540    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3640     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 393      |\n",
            "|    total_timesteps  | 286322   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.77e-05 |\n",
            "|    n_updates        | 71555    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3644     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 393      |\n",
            "|    total_timesteps  | 286385   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.08e-05 |\n",
            "|    n_updates        | 71571    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3648     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 393      |\n",
            "|    total_timesteps  | 286447   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000405 |\n",
            "|    n_updates        | 71586    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3652     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 393      |\n",
            "|    total_timesteps  | 286514   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.36e-05 |\n",
            "|    n_updates        | 71603    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3656     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 393      |\n",
            "|    total_timesteps  | 286577   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.22e-05 |\n",
            "|    n_updates        | 71619    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3660     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 393      |\n",
            "|    total_timesteps  | 286637   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.39e-05 |\n",
            "|    n_updates        | 71634    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3664     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 393      |\n",
            "|    total_timesteps  | 286700   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.34e-05 |\n",
            "|    n_updates        | 71649    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3668     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 394      |\n",
            "|    total_timesteps  | 286765   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000121 |\n",
            "|    n_updates        | 71666    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3672     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 394      |\n",
            "|    total_timesteps  | 286831   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.5e-05  |\n",
            "|    n_updates        | 71682    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3676     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 394      |\n",
            "|    total_timesteps  | 286900   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.81e-05 |\n",
            "|    n_updates        | 71699    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3680     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 394      |\n",
            "|    total_timesteps  | 286963   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.12e-05 |\n",
            "|    n_updates        | 71715    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3684     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 394      |\n",
            "|    total_timesteps  | 287029   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000321 |\n",
            "|    n_updates        | 71732    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3688     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 394      |\n",
            "|    total_timesteps  | 287089   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.92e-05 |\n",
            "|    n_updates        | 71747    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3692     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 394      |\n",
            "|    total_timesteps  | 287153   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.74e-05 |\n",
            "|    n_updates        | 71763    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3696     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 394      |\n",
            "|    total_timesteps  | 287216   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.28e-05 |\n",
            "|    n_updates        | 71778    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3700     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 394      |\n",
            "|    total_timesteps  | 287280   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.83e-05 |\n",
            "|    n_updates        | 71794    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3704     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 394      |\n",
            "|    total_timesteps  | 287341   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.46e-06 |\n",
            "|    n_updates        | 71810    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3708     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 395      |\n",
            "|    total_timesteps  | 287404   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.93e-05 |\n",
            "|    n_updates        | 71825    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3712     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 395      |\n",
            "|    total_timesteps  | 287466   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.57e-06 |\n",
            "|    n_updates        | 71841    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3716     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 395      |\n",
            "|    total_timesteps  | 287528   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.6e-05  |\n",
            "|    n_updates        | 71856    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3720     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 395      |\n",
            "|    total_timesteps  | 287591   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.93e-05 |\n",
            "|    n_updates        | 71872    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3724     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 395      |\n",
            "|    total_timesteps  | 287656   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6e-05    |\n",
            "|    n_updates        | 71888    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3728     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 395      |\n",
            "|    total_timesteps  | 287721   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.08e-05 |\n",
            "|    n_updates        | 71905    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3732     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 395      |\n",
            "|    total_timesteps  | 287781   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000222 |\n",
            "|    n_updates        | 71920    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3736     |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 395      |\n",
            "|    total_timesteps  | 287841   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.95e-05 |\n",
            "|    n_updates        | 71935    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3740     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 396      |\n",
            "|    total_timesteps  | 287903   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.64e-05 |\n",
            "|    n_updates        | 71950    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3744     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 396      |\n",
            "|    total_timesteps  | 287964   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.16e-05 |\n",
            "|    n_updates        | 71965    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3748     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 396      |\n",
            "|    total_timesteps  | 288025   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.83e-05 |\n",
            "|    n_updates        | 71981    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3752     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 396      |\n",
            "|    total_timesteps  | 288094   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.99e-06 |\n",
            "|    n_updates        | 71998    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3756     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 396      |\n",
            "|    total_timesteps  | 288157   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.43e-05 |\n",
            "|    n_updates        | 72014    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3760     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 396      |\n",
            "|    total_timesteps  | 288224   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.94e-05 |\n",
            "|    n_updates        | 72030    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3764     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 396      |\n",
            "|    total_timesteps  | 288293   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.79e-05 |\n",
            "|    n_updates        | 72048    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3768     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 396      |\n",
            "|    total_timesteps  | 288355   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.47e-06 |\n",
            "|    n_updates        | 72063    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3772     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 397      |\n",
            "|    total_timesteps  | 288420   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.58e-05 |\n",
            "|    n_updates        | 72079    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3776     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 397      |\n",
            "|    total_timesteps  | 288481   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.67e-05 |\n",
            "|    n_updates        | 72095    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3780     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 397      |\n",
            "|    total_timesteps  | 288541   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.89e-05 |\n",
            "|    n_updates        | 72110    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3784     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 397      |\n",
            "|    total_timesteps  | 288604   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00046  |\n",
            "|    n_updates        | 72125    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3788     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 397      |\n",
            "|    total_timesteps  | 288670   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.27e-06 |\n",
            "|    n_updates        | 72142    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3792     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 397      |\n",
            "|    total_timesteps  | 288731   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.56e-06 |\n",
            "|    n_updates        | 72157    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3796     |\n",
            "|    fps              | 726      |\n",
            "|    time_elapsed     | 397      |\n",
            "|    total_timesteps  | 288793   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.13e-05 |\n",
            "|    n_updates        | 72173    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3800     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 397      |\n",
            "|    total_timesteps  | 288854   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.67e-05 |\n",
            "|    n_updates        | 72188    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3804     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 398      |\n",
            "|    total_timesteps  | 288922   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.34e-05 |\n",
            "|    n_updates        | 72205    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3808     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 398      |\n",
            "|    total_timesteps  | 288987   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.69e-06 |\n",
            "|    n_updates        | 72221    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3812     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 398      |\n",
            "|    total_timesteps  | 289049   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.8e-05  |\n",
            "|    n_updates        | 72237    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3816     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 398      |\n",
            "|    total_timesteps  | 289115   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.05e-05 |\n",
            "|    n_updates        | 72253    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3820     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 398      |\n",
            "|    total_timesteps  | 289181   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.98e-06 |\n",
            "|    n_updates        | 72270    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3824     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 398      |\n",
            "|    total_timesteps  | 289243   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000735 |\n",
            "|    n_updates        | 72285    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3828     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 398      |\n",
            "|    total_timesteps  | 289306   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000137 |\n",
            "|    n_updates        | 72301    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3832     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 398      |\n",
            "|    total_timesteps  | 289366   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.58e-06 |\n",
            "|    n_updates        | 72316    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3836     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 398      |\n",
            "|    total_timesteps  | 289427   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000126 |\n",
            "|    n_updates        | 72331    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3840     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 398      |\n",
            "|    total_timesteps  | 289491   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.4e-05  |\n",
            "|    n_updates        | 72347    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3844     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 289552   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.25e-05 |\n",
            "|    n_updates        | 72362    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3848     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 289616   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.55e-05 |\n",
            "|    n_updates        | 72378    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3852     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 289676   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.38e-05 |\n",
            "|    n_updates        | 72393    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3856     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 289742   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000792 |\n",
            "|    n_updates        | 72410    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3860     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 289804   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.99e-06 |\n",
            "|    n_updates        | 72425    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3864     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 289869   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.74e-05 |\n",
            "|    n_updates        | 72442    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3868     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 289933   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.39e-05 |\n",
            "|    n_updates        | 72458    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3872     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 289999   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000328 |\n",
            "|    n_updates        | 72474    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3876     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 290062   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0894   |\n",
            "|    n_updates        | 72490    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3880     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 290124   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0441   |\n",
            "|    n_updates        | 72505    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3884     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 290185   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0207   |\n",
            "|    n_updates        | 72521    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3888     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 400      |\n",
            "|    total_timesteps  | 290251   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00636  |\n",
            "|    n_updates        | 72537    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3892     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 400      |\n",
            "|    total_timesteps  | 290311   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0106   |\n",
            "|    n_updates        | 72552    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3896     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 400      |\n",
            "|    total_timesteps  | 290374   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00453  |\n",
            "|    n_updates        | 72568    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3900     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 400      |\n",
            "|    total_timesteps  | 290440   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.024    |\n",
            "|    n_updates        | 72584    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3904     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 400      |\n",
            "|    total_timesteps  | 290503   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0114   |\n",
            "|    n_updates        | 72600    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3908     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 400      |\n",
            "|    total_timesteps  | 290567   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00235  |\n",
            "|    n_updates        | 72616    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3912     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 400      |\n",
            "|    total_timesteps  | 290635   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00429  |\n",
            "|    n_updates        | 72633    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3916     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 400      |\n",
            "|    total_timesteps  | 290699   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0158   |\n",
            "|    n_updates        | 72649    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3920     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 400      |\n",
            "|    total_timesteps  | 290767   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00921  |\n",
            "|    n_updates        | 72666    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3924     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 400      |\n",
            "|    total_timesteps  | 290830   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00556  |\n",
            "|    n_updates        | 72682    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3928     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 400      |\n",
            "|    total_timesteps  | 290897   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00498  |\n",
            "|    n_updates        | 72699    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3932     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 401      |\n",
            "|    total_timesteps  | 290959   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00235  |\n",
            "|    n_updates        | 72714    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3936     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 401      |\n",
            "|    total_timesteps  | 291024   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00454  |\n",
            "|    n_updates        | 72730    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3940     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 401      |\n",
            "|    total_timesteps  | 291088   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00336  |\n",
            "|    n_updates        | 72746    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3944     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 401      |\n",
            "|    total_timesteps  | 291149   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00342  |\n",
            "|    n_updates        | 72762    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3948     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 401      |\n",
            "|    total_timesteps  | 291213   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00156  |\n",
            "|    n_updates        | 72778    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3952     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 401      |\n",
            "|    total_timesteps  | 291275   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00111  |\n",
            "|    n_updates        | 72793    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3956     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 401      |\n",
            "|    total_timesteps  | 291335   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00325  |\n",
            "|    n_updates        | 72808    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3960     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 401      |\n",
            "|    total_timesteps  | 291398   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00144  |\n",
            "|    n_updates        | 72824    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3964     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 401      |\n",
            "|    total_timesteps  | 291462   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00189  |\n",
            "|    n_updates        | 72840    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3968     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 401      |\n",
            "|    total_timesteps  | 291526   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00287  |\n",
            "|    n_updates        | 72856    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3972     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 401      |\n",
            "|    total_timesteps  | 291588   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00103  |\n",
            "|    n_updates        | 72871    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3976     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 402      |\n",
            "|    total_timesteps  | 291650   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0015   |\n",
            "|    n_updates        | 72887    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3980     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 402      |\n",
            "|    total_timesteps  | 291714   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00285  |\n",
            "|    n_updates        | 72903    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3984     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 402      |\n",
            "|    total_timesteps  | 291774   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00126  |\n",
            "|    n_updates        | 72918    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3988     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 402      |\n",
            "|    total_timesteps  | 291836   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000717 |\n",
            "|    n_updates        | 72933    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3992     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 402      |\n",
            "|    total_timesteps  | 291900   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0108   |\n",
            "|    n_updates        | 72949    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3996     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 402      |\n",
            "|    total_timesteps  | 291963   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00123  |\n",
            "|    n_updates        | 72965    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4000     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 402      |\n",
            "|    total_timesteps  | 292025   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000462 |\n",
            "|    n_updates        | 72981    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4004     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 402      |\n",
            "|    total_timesteps  | 292087   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00221  |\n",
            "|    n_updates        | 72996    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4008     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 402      |\n",
            "|    total_timesteps  | 292149   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000277 |\n",
            "|    n_updates        | 73012    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4012     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 402      |\n",
            "|    total_timesteps  | 292210   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00126  |\n",
            "|    n_updates        | 73027    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4016     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 402      |\n",
            "|    total_timesteps  | 292275   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00448  |\n",
            "|    n_updates        | 73043    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4020     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 403      |\n",
            "|    total_timesteps  | 292340   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00453  |\n",
            "|    n_updates        | 73059    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4024     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 403      |\n",
            "|    total_timesteps  | 292403   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0011   |\n",
            "|    n_updates        | 73075    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4028     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 403      |\n",
            "|    total_timesteps  | 292472   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000538 |\n",
            "|    n_updates        | 73092    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4032     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 403      |\n",
            "|    total_timesteps  | 292532   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000318 |\n",
            "|    n_updates        | 73107    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4036     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 403      |\n",
            "|    total_timesteps  | 292593   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00208  |\n",
            "|    n_updates        | 73123    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4040     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 403      |\n",
            "|    total_timesteps  | 292656   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00416  |\n",
            "|    n_updates        | 73138    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4044     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 403      |\n",
            "|    total_timesteps  | 292718   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000978 |\n",
            "|    n_updates        | 73154    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4048     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 403      |\n",
            "|    total_timesteps  | 292781   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00623  |\n",
            "|    n_updates        | 73170    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4052     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 403      |\n",
            "|    total_timesteps  | 292841   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000547 |\n",
            "|    n_updates        | 73185    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4056     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 403      |\n",
            "|    total_timesteps  | 292903   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000602 |\n",
            "|    n_updates        | 73200    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4060     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 403      |\n",
            "|    total_timesteps  | 292964   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000598 |\n",
            "|    n_updates        | 73215    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4064     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 404      |\n",
            "|    total_timesteps  | 293033   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000446 |\n",
            "|    n_updates        | 73233    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4068     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 404      |\n",
            "|    total_timesteps  | 293095   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000378 |\n",
            "|    n_updates        | 73248    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4072     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 404      |\n",
            "|    total_timesteps  | 293160   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000348 |\n",
            "|    n_updates        | 73264    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4076     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 404      |\n",
            "|    total_timesteps  | 293222   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000807 |\n",
            "|    n_updates        | 73280    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4080     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 404      |\n",
            "|    total_timesteps  | 293284   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000984 |\n",
            "|    n_updates        | 73295    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4084     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 404      |\n",
            "|    total_timesteps  | 293345   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00167  |\n",
            "|    n_updates        | 73311    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4088     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 404      |\n",
            "|    total_timesteps  | 293410   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000841 |\n",
            "|    n_updates        | 73327    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4092     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 404      |\n",
            "|    total_timesteps  | 293472   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00019  |\n",
            "|    n_updates        | 73342    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4096     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 404      |\n",
            "|    total_timesteps  | 293535   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000102 |\n",
            "|    n_updates        | 73358    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4100     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 404      |\n",
            "|    total_timesteps  | 293598   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00024  |\n",
            "|    n_updates        | 73374    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4104     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 404      |\n",
            "|    total_timesteps  | 293663   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000746 |\n",
            "|    n_updates        | 73390    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4108     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 293728   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000227 |\n",
            "|    n_updates        | 73406    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4112     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 293793   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000147 |\n",
            "|    n_updates        | 73423    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4116     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 293855   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.7e-05  |\n",
            "|    n_updates        | 73438    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4120     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 293915   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.1e-05  |\n",
            "|    n_updates        | 73453    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4124     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 293976   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000757 |\n",
            "|    n_updates        | 73468    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4128     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 294036   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000354 |\n",
            "|    n_updates        | 73483    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.6     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4132     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 294096   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00133  |\n",
            "|    n_updates        | 73498    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4136     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 294162   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000217 |\n",
            "|    n_updates        | 73515    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4140     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 294225   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000256 |\n",
            "|    n_updates        | 73531    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4144     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 294290   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00595  |\n",
            "|    n_updates        | 73547    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4148     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 294356   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000127 |\n",
            "|    n_updates        | 73563    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4152     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 294416   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000152 |\n",
            "|    n_updates        | 73578    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4156     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 406      |\n",
            "|    total_timesteps  | 294476   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000155 |\n",
            "|    n_updates        | 73593    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4160     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 406      |\n",
            "|    total_timesteps  | 294542   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000133 |\n",
            "|    n_updates        | 73610    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4164     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 406      |\n",
            "|    total_timesteps  | 294609   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000273 |\n",
            "|    n_updates        | 73627    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.7     |\n",
            "|    ep_rew_mean      | -15.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4168     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 406      |\n",
            "|    total_timesteps  | 294669   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000174 |\n",
            "|    n_updates        | 73642    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4172     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 406      |\n",
            "|    total_timesteps  | 294738   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.6e-05  |\n",
            "|    n_updates        | 73659    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4176     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 406      |\n",
            "|    total_timesteps  | 294810   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00527  |\n",
            "|    n_updates        | 73677    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4180     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 406      |\n",
            "|    total_timesteps  | 294870   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000566 |\n",
            "|    n_updates        | 73692    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4184     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 406      |\n",
            "|    total_timesteps  | 294933   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000129 |\n",
            "|    n_updates        | 73708    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4188     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 406      |\n",
            "|    total_timesteps  | 294995   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.9e-05  |\n",
            "|    n_updates        | 73723    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4192     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 406      |\n",
            "|    total_timesteps  | 295056   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000284 |\n",
            "|    n_updates        | 73738    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4196     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 406      |\n",
            "|    total_timesteps  | 295118   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.85e-05 |\n",
            "|    n_updates        | 73754    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4200     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 407      |\n",
            "|    total_timesteps  | 295182   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000259 |\n",
            "|    n_updates        | 73770    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4204     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 407      |\n",
            "|    total_timesteps  | 295244   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.85e-05 |\n",
            "|    n_updates        | 73785    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4208     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 407      |\n",
            "|    total_timesteps  | 295313   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00456  |\n",
            "|    n_updates        | 73803    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4212     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 407      |\n",
            "|    total_timesteps  | 295375   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00445  |\n",
            "|    n_updates        | 73818    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4216     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 407      |\n",
            "|    total_timesteps  | 295437   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.03e-05 |\n",
            "|    n_updates        | 73834    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4220     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 407      |\n",
            "|    total_timesteps  | 295500   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00102  |\n",
            "|    n_updates        | 73849    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4224     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 407      |\n",
            "|    total_timesteps  | 295562   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000976 |\n",
            "|    n_updates        | 73865    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4228     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 407      |\n",
            "|    total_timesteps  | 295627   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.43e-05 |\n",
            "|    n_updates        | 73881    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4232     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 407      |\n",
            "|    total_timesteps  | 295694   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0002   |\n",
            "|    n_updates        | 73898    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4236     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 407      |\n",
            "|    total_timesteps  | 295754   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000402 |\n",
            "|    n_updates        | 73913    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4240     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 407      |\n",
            "|    total_timesteps  | 295815   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000499 |\n",
            "|    n_updates        | 73928    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4244     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 408      |\n",
            "|    total_timesteps  | 295877   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.6e-05  |\n",
            "|    n_updates        | 73944    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4248     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 408      |\n",
            "|    total_timesteps  | 295941   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.74e-05 |\n",
            "|    n_updates        | 73960    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4252     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 408      |\n",
            "|    total_timesteps  | 296001   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000934 |\n",
            "|    n_updates        | 73975    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4256     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 408      |\n",
            "|    total_timesteps  | 296070   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000313 |\n",
            "|    n_updates        | 73992    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4260     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 408      |\n",
            "|    total_timesteps  | 296131   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000768 |\n",
            "|    n_updates        | 74007    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4264     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 408      |\n",
            "|    total_timesteps  | 296196   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.58e-05 |\n",
            "|    n_updates        | 74023    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4268     |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 408      |\n",
            "|    total_timesteps  | 296259   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.11e-05 |\n",
            "|    n_updates        | 74039    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4272     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 408      |\n",
            "|    total_timesteps  | 296323   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000696 |\n",
            "|    n_updates        | 74055    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4276     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 408      |\n",
            "|    total_timesteps  | 296389   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000269 |\n",
            "|    n_updates        | 74072    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4280     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 408      |\n",
            "|    total_timesteps  | 296450   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.24e-05 |\n",
            "|    n_updates        | 74087    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4284     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 409      |\n",
            "|    total_timesteps  | 296513   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000357 |\n",
            "|    n_updates        | 74103    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4288     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 409      |\n",
            "|    total_timesteps  | 296577   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.75e-05 |\n",
            "|    n_updates        | 74119    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4292     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 409      |\n",
            "|    total_timesteps  | 296643   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.19e-05 |\n",
            "|    n_updates        | 74135    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4296     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 409      |\n",
            "|    total_timesteps  | 296707   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.72e-05 |\n",
            "|    n_updates        | 74151    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4300     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 409      |\n",
            "|    total_timesteps  | 296772   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.66e-05 |\n",
            "|    n_updates        | 74167    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4304     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 409      |\n",
            "|    total_timesteps  | 296835   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000343 |\n",
            "|    n_updates        | 74183    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4308     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 409      |\n",
            "|    total_timesteps  | 296898   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.05e-05 |\n",
            "|    n_updates        | 74199    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4312     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 409      |\n",
            "|    total_timesteps  | 296962   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.29e-06 |\n",
            "|    n_updates        | 74215    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4316     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 410      |\n",
            "|    total_timesteps  | 297023   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.66e-05 |\n",
            "|    n_updates        | 74230    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4320     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 410      |\n",
            "|    total_timesteps  | 297088   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000442 |\n",
            "|    n_updates        | 74246    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4324     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 410      |\n",
            "|    total_timesteps  | 297151   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00276  |\n",
            "|    n_updates        | 74262    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4328     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 410      |\n",
            "|    total_timesteps  | 297217   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000158 |\n",
            "|    n_updates        | 74279    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4332     |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 410      |\n",
            "|    total_timesteps  | 297285   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.32e-05 |\n",
            "|    n_updates        | 74296    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4336     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 410      |\n",
            "|    total_timesteps  | 297347   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000137 |\n",
            "|    n_updates        | 74311    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4340     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 410      |\n",
            "|    total_timesteps  | 297410   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.48e-05 |\n",
            "|    n_updates        | 74327    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4344     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 410      |\n",
            "|    total_timesteps  | 297473   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000478 |\n",
            "|    n_updates        | 74343    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4348     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 411      |\n",
            "|    total_timesteps  | 297534   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.48e-05 |\n",
            "|    n_updates        | 74358    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4352     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 411      |\n",
            "|    total_timesteps  | 297595   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000328 |\n",
            "|    n_updates        | 74373    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4356     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 411      |\n",
            "|    total_timesteps  | 297657   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.49e-05 |\n",
            "|    n_updates        | 74389    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4360     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 411      |\n",
            "|    total_timesteps  | 297721   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.37e-05 |\n",
            "|    n_updates        | 74405    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4364     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 411      |\n",
            "|    total_timesteps  | 297786   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.46e-05 |\n",
            "|    n_updates        | 74421    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4368     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 411      |\n",
            "|    total_timesteps  | 297849   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.1e-05  |\n",
            "|    n_updates        | 74437    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4372     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 411      |\n",
            "|    total_timesteps  | 297913   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.14e-05 |\n",
            "|    n_updates        | 74453    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4376     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 297978   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000455 |\n",
            "|    n_updates        | 74469    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4380     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 298042   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.52e-05 |\n",
            "|    n_updates        | 74485    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4384     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 298106   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.55e-05 |\n",
            "|    n_updates        | 74501    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4388     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 298174   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.51e-05 |\n",
            "|    n_updates        | 74518    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4392     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 298235   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00223  |\n",
            "|    n_updates        | 74533    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4396     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 298297   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00211  |\n",
            "|    n_updates        | 74549    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4400     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 298358   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00226  |\n",
            "|    n_updates        | 74564    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4404     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 298421   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.57e-05 |\n",
            "|    n_updates        | 74580    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4408     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 298484   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00202  |\n",
            "|    n_updates        | 74595    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4412     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 298548   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00176  |\n",
            "|    n_updates        | 74611    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4416     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 298610   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.23e-05 |\n",
            "|    n_updates        | 74627    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4420     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 413      |\n",
            "|    total_timesteps  | 298671   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000419 |\n",
            "|    n_updates        | 74642    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4424     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 413      |\n",
            "|    total_timesteps  | 298738   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000126 |\n",
            "|    n_updates        | 74659    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4428     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 413      |\n",
            "|    total_timesteps  | 298799   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.63e-05 |\n",
            "|    n_updates        | 74674    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4432     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 413      |\n",
            "|    total_timesteps  | 298862   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.96e-05 |\n",
            "|    n_updates        | 74690    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4436     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 413      |\n",
            "|    total_timesteps  | 298929   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000238 |\n",
            "|    n_updates        | 74707    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4440     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 413      |\n",
            "|    total_timesteps  | 298992   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.61e-05 |\n",
            "|    n_updates        | 74722    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4444     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 413      |\n",
            "|    total_timesteps  | 299062   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000179 |\n",
            "|    n_updates        | 74740    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4448     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 413      |\n",
            "|    total_timesteps  | 299124   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.53e-05 |\n",
            "|    n_updates        | 74755    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4452     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 413      |\n",
            "|    total_timesteps  | 299189   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.93e-06 |\n",
            "|    n_updates        | 74772    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4456     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 413      |\n",
            "|    total_timesteps  | 299251   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000426 |\n",
            "|    n_updates        | 74787    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4460     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 413      |\n",
            "|    total_timesteps  | 299316   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0021   |\n",
            "|    n_updates        | 74803    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4464     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 414      |\n",
            "|    total_timesteps  | 299378   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.25e-05 |\n",
            "|    n_updates        | 74819    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4468     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 414      |\n",
            "|    total_timesteps  | 299439   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.79e-05 |\n",
            "|    n_updates        | 74834    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4472     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 414      |\n",
            "|    total_timesteps  | 299500   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000205 |\n",
            "|    n_updates        | 74849    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4476     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 414      |\n",
            "|    total_timesteps  | 299560   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000154 |\n",
            "|    n_updates        | 74864    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4480     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 414      |\n",
            "|    total_timesteps  | 299624   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.98e-06 |\n",
            "|    n_updates        | 74880    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4484     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 414      |\n",
            "|    total_timesteps  | 299688   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.75e-05 |\n",
            "|    n_updates        | 74896    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4488     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 414      |\n",
            "|    total_timesteps  | 299754   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.42e-05 |\n",
            "|    n_updates        | 74913    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4492     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 414      |\n",
            "|    total_timesteps  | 299819   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000131 |\n",
            "|    n_updates        | 74929    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -15.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4496     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 414      |\n",
            "|    total_timesteps  | 299883   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.17e-05 |\n",
            "|    n_updates        | 74945    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4500     |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 414      |\n",
            "|    total_timesteps  | 299943   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.62e-05 |\n",
            "|    n_updates        | 74960    |\n",
            "----------------------------------\n",
            "First Episode Path\n",
            "                \n",
            "  X X X X X X   \n",
            "S X         X   \n",
            "          X X   \n",
            "          X     \n",
            "          X X   \n",
            "            X G \n",
            "                \n",
            "First Episode Path\n",
            "\n",
            "Last Episode Path\n",
            "                \n",
            "  X X X X X X   \n",
            "S X         X   \n",
            "          X X   \n",
            "          X     \n",
            "          X X   \n",
            "            X G \n",
            "                \n",
            "Last Episode Path\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import DQN\n",
        "\n",
        "\n",
        "class CustomMazeEnv(gym.Env):\n",
        "    def __init__(self, maze):\n",
        "        super(CustomMazeEnv, self).__init__()\n",
        "\n",
        "        self.maze = np.array(maze)\n",
        "        self.size = self.maze.shape[0]\n",
        "        self.start_pos = (2, 0)  # 시작 위치 (내부 좌표)\n",
        "        self.end_pos = (6, 7)    # 목표 위치 (내부 좌표)\n",
        "\n",
        "        self.action_space = gym.spaces.Discrete(4)  # 북, 남, 서, 동\n",
        "        self.observation_space = gym.spaces.Discrete(self.size * self.size)\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_pos = self.start_pos\n",
        "        self.state = self._pos_to_state(self.agent_pos)\n",
        "        return self.state\n",
        "\n",
        "    def _pos_to_state(self, pos):\n",
        "        return pos[0] * self.size + pos[1]\n",
        "\n",
        "    def step(self, action):\n",
        "        next_pos = np.array(self.agent_pos)\n",
        "\n",
        "        if action == 0 and self.agent_pos[0] > 0:  # 북\n",
        "            next_pos[0] -= 1\n",
        "        elif action == 1 and self.agent_pos[0] < self.size - 1:  # 남\n",
        "            next_pos[0] += 1\n",
        "        elif action == 2 and self.agent_pos[1] > 0:  # 서\n",
        "            next_pos[1] -= 1\n",
        "        elif action == 3 and self.agent_pos[1] < self.size - 1:  # 동\n",
        "            next_pos[1] += 1\n",
        "\n",
        "        # 에이전트가 이동할 수 있는 길인지 확인\n",
        "        if self.maze[tuple(next_pos)] == 1:\n",
        "            self.agent_pos = tuple(next_pos)\n",
        "\n",
        "        self.state = self._pos_to_state(self.agent_pos)\n",
        "        reward = -1  # 각 단계마다 보상 -1\n",
        "        done = self.agent_pos == self.end_pos\n",
        "\n",
        "        return self.state, reward, done, {}\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        maze_copy = np.array(self.maze)  # 미로의 복사본을 만듭니다.\n",
        "        maze_copy[self.agent_pos] = 2  # 에이전트의 위치를 2로 표시합니다.\n",
        "\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(maze_copy, cmap='gray', origin='upper')\n",
        "\n",
        "        # 에이전트의 위치를 표시합니다.\n",
        "        plt.text(self.agent_pos[1], self.agent_pos[0], 'A', ha='center', va='center', fontsize=12, color='red')\n",
        "\n",
        "        # 목표 위치를 표시합니다.\n",
        "        plt.text(self.end_pos[1], self.end_pos[0], 'G', ha='center', va='center', fontsize=12, color='blue')\n",
        "\n",
        "        # 미로의 경계선을 그립니다.\n",
        "        for i in range(self.size + 1):\n",
        "            plt.axhline(i - 0.5, color='black', linewidth=2)\n",
        "            plt.axvline(i - 0.5, color='black', linewidth=2)\n",
        "\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title('Maze')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# 미로 정의\n",
        "maze = [\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 1., 1., 1., 1., 1., 1., 0.],\n",
        "    [1., 1., 0., 0., 1., 0., 1., 0.],\n",
        "    [0., 1., 1., 0., 0., 1., 1., 0.],\n",
        "    [0., 0., 1., 1., 0., 1., 0., 0.],\n",
        "    [0., 1., 0., 1., 0., 1., 1., 0.],\n",
        "    [0., 1., 1., 1., 1., 0., 1., 1.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.]\n",
        "]\n",
        "\n",
        "# 환경 생성\n",
        "env = CustomMazeEnv(maze)\n",
        "\n",
        "# DQN 모델 생성 및 학습\n",
        "model = DQN('MlpPolicy', env, verbose=1)\n",
        "model.learn(total_timesteps=300000)\n",
        "\n",
        "# 경로를 저장할 리스트\n",
        "first_episode_path = []\n",
        "last_episode_path = []\n",
        "\n",
        "# 첫 번째 에피소드 기록\n",
        "obs = env.reset()\n",
        "first_episode_path.append(env.agent_pos)\n",
        "while True:\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, _ = env.step(action)\n",
        "    first_episode_path.append(env.agent_pos)\n",
        "    if dones:\n",
        "        break\n",
        "\n",
        "# 학습된 모델 테스트 및 마지막 에피소드 기록\n",
        "obs = env.reset()\n",
        "last_episode_path.append(env.agent_pos)\n",
        "while True:\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, _ = env.step(action)\n",
        "    last_episode_path.append(env.agent_pos)\n",
        "    if dones:\n",
        "        break\n",
        "\n",
        "# 경로 출력 함수\n",
        "def print_path(maze, path, title):\n",
        "    path_set = set(path)\n",
        "    for i in range(len(maze)):\n",
        "        for j in range(len(maze[i])):\n",
        "            if (i, j) == env.start_pos:\n",
        "                print('S', end=' ')\n",
        "            elif (i, j) == env.end_pos:\n",
        "                print('G', end=' ')\n",
        "            elif (i, j) in path_set:\n",
        "                print('X', end=' ')\n",
        "            else:\n",
        "                print(' ', end=' ')\n",
        "        print()\n",
        "    print(title)\n",
        "    print()\n",
        "\n",
        "# 첫 번째 에피소드 경로 출력\n",
        "print(\"First Episode Path\")\n",
        "print_path(maze, first_episode_path, \"First Episode Path\")\n",
        "\n",
        "# 마지막 에피소드 경로 출력\n",
        "print(\"Last Episode Path\")\n",
        "print_path(maze, last_episode_path, \"Last Episode Path\")\n",
        "\n",
        "\n",
        "\n",
        "# 각 에피소드의 리워드 그래프 시각화\n",
        "plt.plot(episode_rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.title('Total Reward per Episode')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard --logdir ./dqn_maze_tensorboard/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "HAaZmYOh6_Ax",
        "outputId": "d1b8e417-a895-48a9-b708-328e9e4205ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-6-9d31e5dc4fb0>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-9d31e5dc4fb0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir ./dqn_maze_tensorboard/\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "class CustomMazeEnv(gym.Env):\n",
        "    def __init__(self, maze):\n",
        "        super(CustomMazeEnv, self).__init__()\n",
        "\n",
        "        self.maze = np.array(maze)\n",
        "        self.size = self.maze.shape[0]\n",
        "        self.start_pos = (0, 0)  # 시작 위치\n",
        "        self.end_pos = (5, 5)    # 목표 위치\n",
        "\n",
        "        self.action_space = gym.spaces.Discrete(4)  # 북, 남, 서, 동\n",
        "        self.observation_space = gym.spaces.Box(low=np.array([0, 0]), high=np.array([self.size - 1, self.size - 1]), dtype=np.int32)\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_pos = self.start_pos\n",
        "        return np.array(self.agent_pos, dtype=np.int32)\n",
        "\n",
        "    def step(self, action):\n",
        "        next_pos = np.array(self.agent_pos)\n",
        "\n",
        "        if action == 0 and self.agent_pos[0] > 0:  # 북\n",
        "            next_pos[0] -= 1\n",
        "        elif action == 1 and self.agent_pos[0] < self.size - 1:  # 남\n",
        "            next_pos[0] += 1\n",
        "        elif action == 2 and self.agent_pos[1] > 0:  # 서\n",
        "            next_pos[1] -= 1\n",
        "        elif action == 3 and self.agent_pos[1] < self.size - 1:  # 동\n",
        "            next_pos[1] += 1\n",
        "\n",
        "        # 에이전트가 이동할 수 있는 길인지 확인\n",
        "        if self.maze[tuple(next_pos)] == 0 or tuple(next_pos) == self.end_pos:\n",
        "            self.agent_pos = tuple(next_pos)\n",
        "\n",
        "        reward = -1  # 각 단계마다 보상 -1\n",
        "        done = False\n",
        "\n",
        "        if self.agent_pos == self.end_pos:\n",
        "            reward = 100  # 목표에 도달하면 보상 100\n",
        "            done = True\n",
        "        elif self.maze[self.agent_pos] == 1:\n",
        "            reward = -100  # 함정에 빠지면 보상 -100\n",
        "            done = True\n",
        "\n",
        "        return np.array(self.agent_pos, dtype=np.int32), reward, done, {}\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        maze_copy = np.array(self.maze, dtype=np.int32)  # 미로의 복사본을 만듭니다.\n",
        "        maze_copy[self.agent_pos] = 2  # 에이전트의 위치를 2로 표시합니다.\n",
        "\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(maze_copy, cmap='gray', origin='upper')\n",
        "\n",
        "        # 에이전트의 위치를 표시합니다.\n",
        "        plt.text(self.agent_pos[1], self.agent_pos[0], 'A', ha='center', va='center', fontsize=12, color='red')\n",
        "\n",
        "        # 목표 위치를 표시합니다.\n",
        "        plt.text(self.end_pos[1], self.end_pos[0], 'G', ha='center', va='center', fontsize=12, color='blue')\n",
        "\n",
        "        # 미로의 경계선을 그립니다.\n",
        "        for i in range(self.size + 1):\n",
        "            plt.axhline(i - 0.5, color='black', linewidth=2)\n",
        "            plt.axvline(i - 0.5, color='black', linewidth=2)\n",
        "\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title('Maze')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# 미로 정의\n",
        "maze = [\n",
        "    [0, 0, 0, 0, 0, 1],\n",
        "    [0, 1, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 1, 1, 0],\n",
        "    [0, 1, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0],\n",
        "    [1, 0, 0, 0, 1, 0],\n",
        "]\n",
        "\n",
        "# 환경 생성\n",
        "env = DummyVecEnv([lambda: Monitor(CustomMazeEnv(maze))])\n",
        "\n",
        "# TensorBoard를 위한 평가 콜백 설정\n",
        "eval_callback = EvalCallback(env, best_model_save_path='./logs/best_model',\n",
        "                             log_path='./logs/', eval_freq=500,\n",
        "                             deterministic=True, render=False)\n",
        "\n",
        "# DQN 모델 생성 및 학습\n",
        "model = DQN('MlpPolicy', env, verbose=1, tensorboard_log=\"./dqn_maze_tensorboard/\")\n",
        "model.learn(total_timesteps=300000, callback=eval_callback)\n",
        "\n",
        "# 경로를 저장할 리스트\n",
        "first_episode_path = []\n",
        "last_episode_path = []\n",
        "\n",
        "# 첫 번째 에피소드 기록\n",
        "obs = env.reset()\n",
        "first_episode_path.append((0, 0))\n",
        "while True:\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, _ = env.step(action)\n",
        "    first_episode_path.append((env.envs[0].envs[0].agent_pos))\n",
        "    if dones:\n",
        "        break\n",
        "\n",
        "# 학습된 모델 테스트 및 마지막 에피소드 기록\n",
        "obs = env.reset()\n",
        "last_episode_path.append((0, 0))\n",
        "while True:\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, _ = env.step(action)\n",
        "    last_episode_path.append((env.envs[0].envs[0].agent_pos))\n",
        "    if dones:\n",
        "        break\n",
        "\n",
        "# 경로 출력 함수\n",
        "def print_path(maze, path, title):\n",
        "    path_set = set(path)\n",
        "    for i in range(len(maze)):\n",
        "        for j in range(len(maze[i])):\n",
        "            if (i, j) == (0, 0):\n",
        "                print('S', end=' ')\n",
        "            elif (i, j) == (5, 5):\n",
        "                print('G', end=' ')\n",
        "            elif (i, j) in path_set:\n",
        "                print('X', end=' ')\n",
        "            elif maze[i][j] == 1:\n",
        "                print('F', end=' ')\n",
        "            else:\n",
        "                print(' ', end=' ')\n",
        "        print()\n",
        "    print(title)\n",
        "    print()\n",
        "\n",
        "# 첫 번째 에피소드 경로 출력\n",
        "print(\"First Episode Path\")\n",
        "print_path(maze, first_episode_path, \"First Episode Path\")\n",
        "\n",
        "# 마지막 에피소드 경로 출력\n",
        "print(\"Last Episode Path\")\n",
        "print_path(maze, last_episode_path, \"Last Episode Path\")\n"
      ],
      "metadata": {
        "id": "ZUTnrb0uLCJm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "1654b30f-6feb-4746-c125-89776b9eb5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "The algorithm only supports (<class 'gymnasium.spaces.discrete.Discrete'>,) as action spaces but Discrete(4) was provided",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-49c523726928>\u001b[0m in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# DQN 모델 생성 및 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MlpPolicy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./dqn_maze_tensorboard/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/dqn/dqn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, target_update_interval, exploration_fraction, exploration_initial_eps, exploration_final_eps, max_grad_norm, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     ) -> None:\n\u001b[0;32m--> 104\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, use_sde_at_warmup, sde_support, supported_action_spaces)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0msupported_action_spaces\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     ):\n\u001b[0;32m--> 110\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msupported_action_spaces\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 assert isinstance(self.action_space, supported_action_spaces), (\n\u001b[0m\u001b[1;32m    181\u001b[0m                     \u001b[0;34mf\"The algorithm only supports {supported_action_spaces} as action spaces \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0;34mf\"but {self.action_space} was provided\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: The algorithm only supports (<class 'gymnasium.spaces.discrete.Discrete'>,) as action spaces but Discrete(4) was provided"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import gym\n",
        "from gym import spaces\n",
        "from collections import deque\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "class MazeEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(MazeEnv, self).__init__()\n",
        "        self.maze = [\n",
        "            [0, 0, 0, 0, 0, 1],\n",
        "            [0, 1, 0, 0, 0, 0],\n",
        "            [0, 0, 0, 1, 1, 0],\n",
        "            [0, 1, 0, 0, 0, 0],\n",
        "            [0, 0, 0, 0, 0, 0],\n",
        "            [1, 0, 0, 0, 1, 0],\n",
        "        ]\n",
        "        self.start = (0, 0)\n",
        "        self.goal = (5, 5)\n",
        "        self.state = self.start\n",
        "\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(6, 6), dtype=np.int32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = self.start\n",
        "        return self._get_obs()\n",
        "\n",
        "    def step(self, action):\n",
        "        x, y = self.state\n",
        "        if action == 0:   # N\n",
        "            x -= 1\n",
        "        elif action == 1: # E\n",
        "            y += 1\n",
        "        elif action == 2: # S\n",
        "            x += 1\n",
        "        elif action == 3: # W\n",
        "            y -= 1\n",
        "\n",
        "        new_state = (x, y)\n",
        "        if x < 0 or x >= 6 or y < 0 or y >= 6 or self.maze[x][y] == 1:\n",
        "            return self._get_obs(), -100, True, {}\n",
        "\n",
        "        self.state = new_state\n",
        "        reward = -1\n",
        "        done = False\n",
        "        if new_state == self.goal:\n",
        "            reward = 100\n",
        "            done = True\n",
        "\n",
        "        return self._get_obs(), reward, done, {}\n",
        "\n",
        "    def _get_obs(self):\n",
        "        obs = np.zeros((6, 6), dtype=np.int32)\n",
        "        x, y = self.state\n",
        "        obs[x, y] = 1\n",
        "        return obs\n",
        "\n",
        "    def render(self):\n",
        "        maze = np.array(self.maze)\n",
        "        x, y = self.state\n",
        "        maze[x, y] = 2\n",
        "        print(maze)\n",
        "\n",
        "env = MazeEnv()\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_shape, action_size):\n",
        "        self.state_shape = state_shape\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.001\n",
        "        self.model = self._build_model()\n",
        "\n",
        "        self.log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        self.tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=self.log_dir, histogram_freq=1)\n",
        "\n",
        "    def _build_model(self):\n",
        "        model = keras.Sequential()\n",
        "        model.add(layers.Flatten(input_shape=self.state_shape))\n",
        "        model.add(layers.Dense(24, activation='relu'))\n",
        "        model.add(layers.Dense(24, activation='relu'))\n",
        "        model.add(layers.Dense(self.action_size, activation='linear'))\n",
        "        model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        act_values = self.model.predict(state)\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
        "            target_f = self.model.predict(state)\n",
        "            target_f[0][action] = target\n",
        "            self.model.fit(state, target_f, epochs=1, verbose=0, callbacks=[self.tensorboard_callback])\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)\n",
        "\n",
        "state_shape = (6, 6)\n",
        "action_size = env.action_space.n\n",
        "agent = DQNAgent(state_shape, action_size)\n",
        "\n",
        "done = False\n",
        "batch_size = 32\n",
        "EPISODES = 1000\n",
        "\n",
        "for e in range(EPISODES):\n",
        "    state = env.reset()\n",
        "    state = np.reshape(state, [1, 6, 6])\n",
        "    for time in range(500):\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        next_state = np.reshape(next_state, [1, 6, 6])\n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        if done:\n",
        "            print(f\"Episode: {e}/{EPISODES}, score: {time}, e: {agent.epsilon:.2}\")\n",
        "            break\n",
        "        if len(agent.memory) > batch_size:\n",
        "            agent.replay(batch_size)\n",
        "\n",
        "agent.save(\"dqn_maze.h5\")\n",
        "\n",
        "# Start TensorBoard in the background\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/fit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MkpIWRyr5yTG",
        "outputId": "b43681f4-57c5-49a8-e367-ddc6364773f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Episode: 83/1000, score: 2, e: 0.5\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Episode: 84/1000, score: 1, e: 0.49\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Episode: 85/1000, score: 1, e: 0.49\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Episode: 86/1000, score: 8, e: 0.47\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 87/1000, score: 3, e: 0.46\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Episode: 88/1000, score: 1, e: 0.46\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Episode: 89/1000, score: 4, e: 0.45\n",
            "Episode: 90/1000, score: 0, e: 0.45\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Episode: 91/1000, score: 3, e: 0.45\n",
            "Episode: 92/1000, score: 0, e: 0.45\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Episode: 93/1000, score: 8, e: 0.43\n",
            "Episode: 94/1000, score: 0, e: 0.43\n",
            "Episode: 95/1000, score: 0, e: 0.43\n",
            "Episode: 96/1000, score: 0, e: 0.43\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Episode: 97/1000, score: 4, e: 0.42\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Episode: 98/1000, score: 2, e: 0.42\n",
            "Episode: 99/1000, score: 0, e: 0.42\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Episode: 100/1000, score: 4, e: 0.41\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Episode: 101/1000, score: 4, e: 0.4\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Episode: 102/1000, score: 4, e: 0.39\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Episode: 103/1000, score: 1, e: 0.39\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Episode: 104/1000, score: 4, e: 0.38\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Episode: 105/1000, score: 1, e: 0.38\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Episode: 106/1000, score: 7, e: 0.37\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Episode: 107/1000, score: 8, e: 0.35\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Episode: 108/1000, score: 4, e: 0.35\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 109/1000, score: 17, e: 0.32\n",
            "Episode: 110/1000, score: 0, e: 0.32\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-185b299a4360>\u001b[0m in \u001b[0;36m<cell line: 130>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dqn_maze.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-185b299a4360>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mtarget_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mtarget_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2649\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m             \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2652\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m             \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 706\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    743\u001b[0m             self._flat_output_types)\n\u001b[1;32m    744\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3420\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3421\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3422\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3423\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Stable Baseline 3\n",
        "!pip install stable-baselines3[extra]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo5w8WOmKSJn",
        "outputId": "d8c31f25-dda2-4994-c627-c8f430f8a01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.8.0.76)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.6.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.15.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.7.1)\n",
            "Requirement already satisfied: shimmy[atari]~=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (9.4.0)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.6.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]~=1.3.0->stable-baselines3[extra]) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3[extra]) (12.5.82)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.16.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]) (6.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z33TRZkmH7kQ",
        "outputId": "e5eecab9-b35e-480e-d42c-7e29b8e94296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from gymnasium import spaces\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.logger import configure\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "class TensorboardCallback(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super(TensorboardCallback, self).__init__(verbose)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        self.logger.record('reward', self.locals['rewards'])\n",
        "        return True\n",
        "\n",
        "class MazeEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(MazeEnv, self).__init__()\n",
        "        self.grid_size = 6\n",
        "        self.start_state = (0, 0)\n",
        "        self.goal_state = (5, 5)\n",
        "        self.current_state = self.start_state\n",
        "        self.previous_state = self.current_state\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(self.grid_size, self.grid_size), dtype=np.float32)\n",
        "\n",
        "        self.maze = np.array([\n",
        "            [0, 0, 0, 0, 0, 1],\n",
        "            [0, 1, 0, 0, 0, 0],\n",
        "            [0, 0, 0, 1, 1, 0],\n",
        "            [0, 1, 0, 0, 0, 0],\n",
        "            [0, 0, 0, 0, 0, 0],\n",
        "            [1, 0, 0, 0, 1, 0],\n",
        "        ])\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_state = self.start_state\n",
        "        self.previous_state = self.current_state\n",
        "        return self._get_observation(), {}\n",
        "\n",
        "    def _get_observation(self):\n",
        "        obs = np.zeros((self.grid_size, self.grid_size))\n",
        "        obs[self.current_state] = 1\n",
        "        return obs\n",
        "\n",
        "    def step(self, action):\n",
        "        x, y = self.current_state\n",
        "        if action == 0:\n",
        "            y -= 1\n",
        "        elif action == 1:\n",
        "            x -= 1\n",
        "        elif action == 2:\n",
        "            y += 1\n",
        "        elif action == 3:\n",
        "            x += 1\n",
        "\n",
        "        new_state = (x, y)\n",
        "        if x < 0 or x >= self.grid_size or y < 0 or y >= self.grid_size or self.maze[new_state] == 1:\n",
        "            new_state = self.current_state\n",
        "\n",
        "        self.previous_state = self.current_state\n",
        "        self.current_state = new_state\n",
        "\n",
        "        reward = -1\n",
        "        done = False\n",
        "\n",
        "        if new_state == self.goal_state:\n",
        "            reward = 100\n",
        "            done = True\n",
        "        elif new_state == self.previous_state:\n",
        "            reward = -10\n",
        "        elif self.maze[new_state] == 1:\n",
        "            done = True\n",
        "\n",
        "        return self._get_observation(), reward, done, {}\n",
        "\n",
        "    def render(self):\n",
        "        plt.clf()\n",
        "        plt.imshow(self.maze, cmap='gray_r')\n",
        "        plt.scatter(self.current_state[1], self.current_state[0], c='red', marker='o')\n",
        "        plt.scatter(self.goal_state[1], self.goal_state[0], c='blue', marker='x')\n",
        "        plt.pause(0.1)\n",
        "        plt.draw()\n",
        "\n",
        "env = MazeEnv()\n",
        "\n",
        "log_dir = \"./dqn_maze_tensorboard/\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "model = DQN('MlpPolicy', env, verbose=0, tensorboard_log=log_dir, exploration_fraction=0.4, exploration_final_eps=0.05, learning_rate=0.0001)\n",
        "model.learn(total_timesteps=100000, callback=TensorboardCallback())\n",
        "obs, _ = env.reset()\n",
        "cumulative_reward = 0\n",
        "steps = 0\n",
        "path = []\n",
        "\n",
        "done = False\n",
        "while not (done and reward == 100):\n",
        "    action = model.predict(obs, deterministic=True)[0]\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "    cumulative_reward += reward\n",
        "    steps += 1\n",
        "    path.append(env.current_state)\n",
        "    print(f\"Action: {action}, State: {env.current_state}, Reward: {reward}, Done: {done}\")\n",
        "    print(f\"Total steps: {steps}, Cumulative reward: {cumulative_reward}\")\n",
        "    print(f\"Path: {path}\")\n",
        "    env.render()\n",
        "    if done:\n",
        "        print(\"Goal reached!\")\n",
        "        print(f\"Total steps: {steps}, Cumulative reward: {cumulative_reward}\")\n",
        "        print(f\"Path: {path}\")\n",
        "\n",
        "plt.close()\n",
        "\n",
        "model.learn(total_timesteps=200000, callback=TensorboardCallback())\n",
        "obs, _ = env.reset()\n",
        "cumulative_reward = 0\n",
        "steps = 0\n",
        "path = []\n",
        "\n",
        "done = False\n",
        "while not (done and reward == 100):\n",
        "    action = model.predict(obs, deterministic=True)[0]\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "    cumulative_reward += reward\n",
        "    steps += 1\n",
        "    path.append(env.current_state)\n",
        "    print(f\"Action: {action}, State: {env.current_state}, Reward: {reward}, Done: {done}\")\n",
        "    print(f\"Total steps: {steps}, Cumulative reward: {cumulative_reward}\")\n",
        "    print(f\"Path: {path}\")\n",
        "    env.render()\n",
        "    if done:\n",
        "        print(\"Goal reached!\")\n",
        "        print(f\"Total steps: {steps}, Cumulative reward: {cumulative_reward}\")\n",
        "        print(f\"Path: {path}\")\n",
        "\n",
        "plt.close()\n",
        "\n",
        "model.learn(total_timesteps=300000, callback=TensorboardCallback())\n",
        "obs, _ = env.reset()\n",
        "cumulative_reward = 0\n",
        "steps = 0\n",
        "path = []\n",
        "\n",
        "done = False\n",
        "while not (done and reward == 100):\n",
        "    action = model.predict(obs, deterministic=True)[0]\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "    cumulative_reward += reward\n",
        "    steps += 1\n",
        "    path.append(env.current_state)\n",
        "    print(f\"Action: {action}, State: {env.current_state}, Reward: {reward}, Done: {done}\")\n",
        "    print(f\"Total steps: {steps}, Cumulative reward: {cumulative_reward}\")\n",
        "    print(f\"Path: {path}\")\n",
        "    env.render()\n",
        "    if done:\n",
        "        print(\"Goal reached!\")\n",
        "        print(f\"Total steps: {steps}, Cumulative reward: {cumulative_reward}\")\n",
        "        print(f\"Path: {path}\")\n",
        "\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "UqrVPiCG_Hg7",
        "outputId": "f3b226f2-6e88-4f95-edba-691eabbc48d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 5, got 4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-5e8b88eafccd>\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MlpPolicy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration_final_eps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mcumulative_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/dqn/dqn.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     ) -> SelfDQN:\n\u001b[0;32m--> 267\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             rollout = self.collect_rollouts(\n\u001b[0m\u001b[1;32m    329\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mtrain_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;31m# Rescale and perform action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \"\"\"\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tQz3OLrEHCgc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}